

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Operations &mdash; Apache Kafka 4.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Apache Kafka 4.0.0 documentation" href="../index.html"/>
        <link rel="up" title="Apache Kafka Documentation" href="index.html"/>
        <link rel="prev" title="Implementation" href="implementation.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Apache Kafka
          

          
          </a>

          
            
            
              <div class="version">
                4.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uses.html">Use Cases</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Apache Kafka Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html">Kafka APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="design.html">Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="implementation.html">Implementation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-kafka-operations">6.1 Basic Kafka Operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#adding-and-removing-topics">Adding and removing topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#modifying-topics">Modifying topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#graceful-shutdown">Graceful shutdown</a></li>
<li class="toctree-l4"><a class="reference internal" href="#balancing-leadership">Balancing leadership</a></li>
<li class="toctree-l4"><a class="reference internal" href="#balancing-replicas-across-racks">Balancing Replicas Across Racks</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mirroring-data-between-clusters">Mirroring data between clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#checking-consumer-position">Checking consumer position</a></li>
<li class="toctree-l4"><a class="reference internal" href="#managing-consumer-groups">Managing Consumer Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="#expanding-your-cluster">Expanding your cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decommissioning-brokers">Decommissioning brokers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#increasing-replication-factor">Increasing replication factor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#limiting-bandwidth-usage-during-data-migration">Limiting Bandwidth Usage during Data Migration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#setting-quotas">Setting quotas</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#datacenters">6.2 Datacenters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kafka-configuration">6.3 Kafka Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#important-client-configurations">Important Client Configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#a-production-server-config">A Production Server Config</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#java-version">6.4 Java Version</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hardware-and-os">6.5 Hardware and OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#os">OS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#disks-and-filesystem">Disks and Filesystem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#application-vs-os-flush-management">Application vs. OS Flush Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="#understanding-linux-os-flush-behavior">Understanding Linux OS Flush Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="#filesystem-selection">Filesystem Selection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#monitoring">6.6 Monitoring</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#common-monitoring-metrics-for-producer-consumer-connect-streams">Common monitoring metrics for producer/consumer/connect/streams</a></li>
<li class="toctree-l4"><a class="reference internal" href="#common-per-broker-metrics-for-producer-consumer-connect-streams">Common Per-broker metrics for producer/consumer/connect/streams</a></li>
<li class="toctree-l4"><a class="reference internal" href="#producer-monitoring">Producer monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="#new-consumer-monitoring">New consumer monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="#connect-monitoring">Connect Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="#streams-monitoring">Streams Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="#others">Others</a></li>
<li class="toctree-l4"><a class="reference internal" href="#audit">Audit</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#zookeeper">6.7 ZooKeeper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#stable-version">Stable version</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operationalizing-zookeeper">Operationalizing ZooKeeper</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Apache Kafka</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Apache Kafka Documentation</a> &raquo;</li>
        
      <li>Operations</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/documentation/ops.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="operations">
<h1>Operations<a class="headerlink" href="#operations" title="Permalink to this headline">Â¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#basic-kafka-operations" id="id7">6.1 Basic Kafka Operations</a><ul>
<li><a class="reference internal" href="#adding-and-removing-topics" id="id8">Adding and removing topics</a></li>
<li><a class="reference internal" href="#modifying-topics" id="id9">Modifying topics</a></li>
<li><a class="reference internal" href="#graceful-shutdown" id="id10">Graceful shutdown</a></li>
<li><a class="reference internal" href="#balancing-leadership" id="id11">Balancing leadership</a></li>
<li><a class="reference internal" href="#balancing-replicas-across-racks" id="id12">Balancing Replicas Across Racks</a></li>
<li><a class="reference internal" href="#mirroring-data-between-clusters" id="id13">Mirroring data between clusters</a></li>
<li><a class="reference internal" href="#checking-consumer-position" id="id14">Checking consumer position</a></li>
<li><a class="reference internal" href="#managing-consumer-groups" id="id15">Managing Consumer Groups</a></li>
<li><a class="reference internal" href="#expanding-your-cluster" id="id16">Expanding your cluster</a><ul>
<li><a class="reference internal" href="#automatically-migrating-data-to-new-machines" id="id17">Automatically migrating data to new machines</a></li>
<li><a class="reference internal" href="#custom-partition-assignment-and-migration" id="id18">Custom partition assignment and migration</a></li>
</ul>
</li>
<li><a class="reference internal" href="#decommissioning-brokers" id="id19">Decommissioning brokers</a></li>
<li><a class="reference internal" href="#increasing-replication-factor" id="id20">Increasing replication factor</a></li>
<li><a class="reference internal" href="#limiting-bandwidth-usage-during-data-migration" id="id21">Limiting Bandwidth Usage during Data Migration</a><ul>
<li><a class="reference internal" href="#safe-usage-of-throttled-replication" id="id22">Safe usage of throttled replication</a></li>
</ul>
</li>
<li><a class="reference internal" href="#setting-quotas" id="id23">Setting quotas</a></li>
</ul>
</li>
<li><a class="reference internal" href="#datacenters" id="id24">6.2 Datacenters</a></li>
<li><a class="reference internal" href="#kafka-configuration" id="id25">6.3 Kafka Configuration</a><ul>
<li><a class="reference internal" href="#important-client-configurations" id="id26">Important Client Configurations</a></li>
<li><a class="reference internal" href="#a-production-server-config" id="id27">A Production Server Config</a></li>
</ul>
</li>
<li><a class="reference internal" href="#java-version" id="id28">6.4 Java Version</a></li>
<li><a class="reference internal" href="#hardware-and-os" id="id29">6.5 Hardware and OS</a><ul>
<li><a class="reference internal" href="#os" id="id30">OS</a></li>
<li><a class="reference internal" href="#disks-and-filesystem" id="id31">Disks and Filesystem</a></li>
<li><a class="reference internal" href="#application-vs-os-flush-management" id="id32">Application vs. OS Flush Management</a></li>
<li><a class="reference internal" href="#understanding-linux-os-flush-behavior" id="id33">Understanding Linux OS Flush Behavior</a></li>
<li><a class="reference internal" href="#filesystem-selection" id="id34">Filesystem Selection</a><ul>
<li><a class="reference internal" href="#general-filesystem-notes" id="id35">General Filesystem Notes</a></li>
<li><a class="reference internal" href="#xfs-notes" id="id36">XFS Notes</a></li>
<li><a class="reference internal" href="#ext4-notes" id="id37">EXT4 Notes</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#monitoring" id="id38">6.6 Monitoring</a><ul>
<li><a class="reference internal" href="#common-monitoring-metrics-for-producer-consumer-connect-streams" id="id39">Common monitoring metrics for producer/consumer/connect/streams</a></li>
<li><a class="reference internal" href="#common-per-broker-metrics-for-producer-consumer-connect-streams" id="id40">Common Per-broker metrics for producer/consumer/connect/streams</a></li>
<li><a class="reference internal" href="#producer-monitoring" id="id41">Producer monitoring</a><ul>
<li><a class="reference internal" href="#producer-sender-metrics" id="id42">Producer Sender Metrics</a></li>
</ul>
</li>
<li><a class="reference internal" href="#new-consumer-monitoring" id="id43">New consumer monitoring</a><ul>
<li><a class="reference internal" href="#consumer-group-metrics" id="id44">Consumer Group Metrics</a></li>
<li><a class="reference internal" href="#consumer-fetch-metrics" id="id45">Consumer Fetch Metrics</a></li>
</ul>
</li>
<li><a class="reference internal" href="#connect-monitoring" id="id46">Connect Monitoring</a></li>
<li><a class="reference internal" href="#streams-monitoring" id="id47">Streams Monitoring</a><ul>
<li><a class="reference internal" href="#thread-metrics" id="id48">Thread Metrics</a></li>
<li><a class="reference internal" href="#task-metrics" id="id49">Task Metrics</a></li>
<li><a class="reference internal" href="#processor-node-metrics" id="id50">Processor Node Metrics</a></li>
<li><a class="reference internal" href="#state-store-metrics" id="id51">State Store Metrics</a></li>
<li><a class="reference internal" href="#record-cache-metrics" id="id52">Record Cache Metrics</a></li>
</ul>
</li>
<li><a class="reference internal" href="#others" id="id53">Others</a></li>
<li><a class="reference internal" href="#audit" id="id54">Audit</a></li>
</ul>
</li>
<li><a class="reference internal" href="#zookeeper" id="id55">6.7 ZooKeeper</a><ul>
<li><a class="reference internal" href="#stable-version" id="id56">Stable version</a></li>
<li><a class="reference internal" href="#operationalizing-zookeeper" id="id57">Operationalizing ZooKeeper</a></li>
</ul>
</li>
</ul>
</div>
<p>Here is some information on actually running Kafka as a production
system based on usage and experience at LinkedIn. Please send us any
additional tips you know of.</p>
<div class="section" id="basic-kafka-operations">
<h2><a class="reference external" href="#basic_ops">6.1 Basic Kafka Operations</a><a class="headerlink" href="#basic-kafka-operations" title="Permalink to this headline">Â¶</a></h2>
<p>This section will review the most common operations you will perform on
your Kafka cluster. All of the tools reviewed in this section are
available under the <code class="docutils literal"><span class="pre">bin/</span></code> directory of the Kafka distribution and
each tool will print details on all possible commandline options if it
is run with no arguments.</p>
<div class="section" id="adding-and-removing-topics">
<h3><a class="reference external" href="#basic_ops_add_topic">Adding and removing topics</a><a class="headerlink" href="#adding-and-removing-topics" title="Permalink to this headline">Â¶</a></h3>
<p>You have the option of either adding topics manually or having them be
created automatically when data is first published to a non-existent
topic. If topics are auto-created then you may want to tune the default
<a class="reference external" href="#topicconfigs">topic configurations</a> used for auto-created topics.</p>
<p>Topics are added and modified using the topic tool:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">topics</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">zk_host</span><span class="p">:</span><span class="n">port</span><span class="o">/</span><span class="n">chroot</span> <span class="o">--</span><span class="n">create</span> <span class="o">--</span><span class="n">topic</span> <span class="n">my_topic_name</span>
      <span class="o">--</span><span class="n">partitions</span> <span class="mi">20</span> <span class="o">--</span><span class="n">replication</span><span class="o">-</span><span class="n">factor</span> <span class="mi">3</span> <span class="o">--</span><span class="n">config</span> <span class="n">x</span><span class="o">=</span><span class="n">y</span>
</pre></div>
</div>
<p>The replication factor controls how many servers will replicate each
message that is written. If you have a replication factor of 3 then up
to 2 servers can fail before you will lose access to your data. We
recommend you use a replication factor of 2 or 3 so that you can
transparently bounce machines without interrupting data consumption.</p>
<p>The partition count controls how many logs the topic will be sharded
into. There are several impacts of the partition count. First each
partition must fit entirely on a single server. So if you have 20
partitions the full data set (and read and write load) will be handled
by no more than 20 servers (not counting replicas). Finally the
partition count impacts the maximum parallelism of your consumers. This
is discussed in greater detail in the <a class="reference external" href="#intro_consumers">concepts
section</a>.</p>
<p>Each sharded partition log is placed into its own folder under the Kafka
log directory. The name of such folders consists of the topic name,
appended by a dash (-) and the partition id. Since a typical folder name
can not be over 255 characters long, there will be a limitation on the
length of topic names. We assume the number of partitions will not ever
be above 100,000. Therefore, topic names cannot be longer than 249
characters. This leaves just enough room in the folder name for a dash
and a potentially 5 digit long partition id.</p>
<p>The configurations added on the command line override the default
settings the server has for things like the length of time data should
be retained. The complete set of per-topic configurations is documented
<a class="reference external" href="#topicconfigs">here</a>.</p>
</div>
<div class="section" id="modifying-topics">
<h3><a class="reference external" href="#basic_ops_modify_topic">Modifying topics</a><a class="headerlink" href="#modifying-topics" title="Permalink to this headline">Â¶</a></h3>
<p>You can change the configuration or partitioning of a topic using the
same topic tool.</p>
<p>To add partitions you can do</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">topics</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">zk_host</span><span class="p">:</span><span class="n">port</span><span class="o">/</span><span class="n">chroot</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">topic</span> <span class="n">my_topic_name</span>
      <span class="o">--</span><span class="n">partitions</span> <span class="mi">40</span>
</pre></div>
</div>
<p>Be aware that one use case for partitions is to semantically partition
data, and adding partitions doesn&#8217;t change the partitioning of existing
data so this may disturb consumers if they rely on that partition. That
is if data is partitioned by <code class="docutils literal"><span class="pre">hash(key)</span> <span class="pre">%</span> <span class="pre">number_of_partitions</span></code> then
this partitioning will potentially be shuffled by adding partitions but
Kafka will not attempt to automatically redistribute data in any way.</p>
<p>To add configs:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">zk_host</span><span class="p">:</span><span class="n">port</span><span class="o">/</span><span class="n">chroot</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">topics</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">my_topic_name</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="n">x</span><span class="o">=</span><span class="n">y</span>
</pre></div>
</div>
<p>To remove a config:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">zk_host</span><span class="p">:</span><span class="n">port</span><span class="o">/</span><span class="n">chroot</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">topics</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">my_topic_name</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">delete</span><span class="o">-</span><span class="n">config</span> <span class="n">x</span>
</pre></div>
</div>
<p>And finally deleting a topic:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">topics</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">zk_host</span><span class="p">:</span><span class="n">port</span><span class="o">/</span><span class="n">chroot</span> <span class="o">--</span><span class="n">delete</span> <span class="o">--</span><span class="n">topic</span> <span class="n">my_topic_name</span>
</pre></div>
</div>
<p>Kafka does not currently support reducing the number of partitions for a
topic.</p>
<p>Instructions for changing the replication factor of a topic can be found
<a class="reference external" href="#basic_ops_increase_replication_factor">here</a>.</p>
</div>
<div class="section" id="graceful-shutdown">
<h3><a class="reference external" href="#basic_ops_restarting">Graceful shutdown</a><a class="headerlink" href="#graceful-shutdown" title="Permalink to this headline">Â¶</a></h3>
<p>The Kafka cluster will automatically detect any broker shutdown or
failure and elect new leaders for the partitions on that machine. This
will occur whether a server fails or it is brought down intentionally
for maintenance or configuration changes. For the latter cases Kafka
supports a more graceful mechanism for stopping a server than just
killing it. When a server is stopped gracefully it has two optimizations
it will take advantage of:</p>
<ol class="arabic simple">
<li>It will sync all its logs to disk to avoid needing to do any log
recovery when it restarts (i.e. validating the checksum for all
messages in the tail of the log). Log recovery takes time so this
speeds up intentional restarts.</li>
<li>It will migrate any partitions the server is the leader for to other
replicas prior to shutting down. This will make the leadership
transfer faster and minimize the time each partition is unavailable
to a few milliseconds.</li>
</ol>
<p>Syncing the logs will happen automatically whenever the server is
stopped other than by a hard kill, but the controlled leadership
migration requires using a special setting:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">controlled</span><span class="o">.</span><span class="n">shutdown</span><span class="o">.</span><span class="n">enable</span><span class="o">=</span><span class="n">true</span>
</pre></div>
</div>
<p>Note that controlled shutdown will only succeed if <em>all</em> the partitions
hosted on the broker have replicas (i.e. the replication factor is
greater than 1 <em>and</em> at least one of these replicas is alive). This is
generally what you want since shutting down the last replica would make
that topic partition unavailable.</p>
</div>
<div class="section" id="balancing-leadership">
<h3><a class="reference external" href="#basic_ops_leader_balancing">Balancing leadership</a><a class="headerlink" href="#balancing-leadership" title="Permalink to this headline">Â¶</a></h3>
<p>Whenever a broker stops or crashes leadership for that broker&#8217;s
partitions transfers to other replicas. This means that by default when
the broker is restarted it will only be a follower for all its
partitions, meaning it will not be used for client reads and writes.</p>
<p>To avoid this imbalance, Kafka has a notion of preferred replicas. If
the list of replicas for a partition is 1,5,9 then node 1 is preferred
as the leader to either node 5 or 9 because it is earlier in the replica
list. You can have the Kafka cluster try to restore leadership to the
restored replicas by running the command:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">preferred</span><span class="o">-</span><span class="n">replica</span><span class="o">-</span><span class="n">election</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">zk_host</span><span class="p">:</span><span class="n">port</span><span class="o">/</span><span class="n">chroot</span>
</pre></div>
</div>
<p>Since running this command can be tedious you can also configure Kafka
to do this automatically by setting the following configuration:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">auto</span><span class="o">.</span><span class="n">leader</span><span class="o">.</span><span class="n">rebalance</span><span class="o">.</span><span class="n">enable</span><span class="o">=</span><span class="n">true</span>
</pre></div>
</div>
</div>
<div class="section" id="balancing-replicas-across-racks">
<h3><a class="reference external" href="#basic_ops_racks">Balancing Replicas Across Racks</a><a class="headerlink" href="#balancing-replicas-across-racks" title="Permalink to this headline">Â¶</a></h3>
<p>The rack awareness feature spreads replicas of the same partition across
different racks. This extends the guarantees Kafka provides for
broker-failure to cover rack-failure, limiting the risk of data loss
should all the brokers on a rack fail at once. The feature can also be
applied to other broker groupings such as availability zones in EC2.</p>
<p>You can specify that a broker belongs to a particular rack by adding a
property to the broker config:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">broker</span><span class="o">.</span><span class="n">rack</span><span class="o">=</span><span class="n">my</span><span class="o">-</span><span class="n">rack</span><span class="o">-</span><span class="nb">id</span>
</pre></div>
</div>
<p>When a topic is <a class="reference external" href="#basic_ops_add_topic">created</a>,
<a class="reference external" href="#basic_ops_modify_topic">modified</a> or replicas are
<a class="reference external" href="#basic_ops_cluster_expansion">redistributed</a>, the rack constraint
will be honoured, ensuring replicas span as many racks as they can (a
partition will span min(#racks, replication-factor) different racks).</p>
<p>The algorithm used to assign replicas to brokers ensures that the number
of leaders per broker will be constant, regardless of how brokers are
distributed across racks. This ensures balanced throughput.</p>
<p>However if racks are assigned different numbers of brokers, the
assignment of replicas will not be even. Racks with fewer brokers will
get more replicas, meaning they will use more storage and put more
resources into replication. Hence it is sensible to configure an equal
number of brokers per rack.</p>
</div>
<div class="section" id="mirroring-data-between-clusters">
<h3><a class="reference external" href="#basic_ops_mirror_maker">Mirroring data between clusters</a><a class="headerlink" href="#mirroring-data-between-clusters" title="Permalink to this headline">Â¶</a></h3>
<p>We refer to the process of replicating data <em>between</em> Kafka clusters
&#8220;mirroring&#8221; to avoid confusion with the replication that happens amongst
the nodes in a single cluster. Kafka comes with a tool for mirroring
data between Kafka clusters. The tool consumes from a source cluster and
produces to a destination cluster. A common use case for this kind of
mirroring is to provide a replica in another datacenter. This scenario
will be discussed in more detail in the next section.</p>
<p>You can run many such mirroring processes to increase throughput and for
fault-tolerance (if one process dies, the others will take overs the
additional load).</p>
<p>Data will be read from topics in the source cluster and written to a
topic with the same name in the destination cluster. In fact the mirror
maker is little more than a Kafka consumer and producer hooked together.</p>
<p>The source and destination clusters are completely independent entities:
they can have different numbers of partitions and the offsets will not
be the same. For this reason the mirror cluster is not really intended
as a fault-tolerance mechanism (as the consumer position will be
different); for that we recommend using normal in-cluster replication.
The mirror maker process will, however, retain and use the message key
for partitioning so order is preserved on a per-key basis.</p>
<p>Here is an example showing how to mirror a single topic (named
<em>my-topic</em>) from an input cluster:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">mirror</span><span class="o">-</span><span class="n">maker</span><span class="o">.</span><span class="n">sh</span>
      <span class="o">--</span><span class="n">consumer</span><span class="o">.</span><span class="n">config</span> <span class="n">consumer</span><span class="o">.</span><span class="n">properties</span>
      <span class="o">--</span><span class="n">producer</span><span class="o">.</span><span class="n">config</span> <span class="n">producer</span><span class="o">.</span><span class="n">properties</span> <span class="o">--</span><span class="n">whitelist</span> <span class="n">my</span><span class="o">-</span><span class="n">topic</span>
</pre></div>
</div>
<p>Note that we specify the list of topics with the <code class="docutils literal"><span class="pre">--whitelist</span></code> option.
This option allows any regular expression using <a class="reference external" href="http://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html">Java-style regular
expressions</a>.
So you could mirror two topics named <em>A</em> and <em>B</em> using
<code class="docutils literal"><span class="pre">--whitelist</span> <span class="pre">'A|B'</span></code>. Or you could mirror <em>all</em> topics using
<code class="docutils literal"><span class="pre">--whitelist</span> <span class="pre">'*'</span></code>. Make sure to quote any regular expression to ensure
the shell doesn&#8217;t try to expand it as a file path. For convenience we
allow the use of &#8216;,&#8217; instead of &#8216;|&#8217; to specify a list of topics.</p>
<p>Sometimes it is easier to say what it is that you <em>don&#8217;t</em> want. Instead
of using <code class="docutils literal"><span class="pre">--whitelist</span></code> to say what you want to mirror you can use
<code class="docutils literal"><span class="pre">--blacklist</span></code> to say what to exclude. This also takes a regular
expression argument. However, <code class="docutils literal"><span class="pre">--blacklist</span></code> is not supported when the
new consumer has been enabled (i.e. when <code class="docutils literal"><span class="pre">bootstrap.servers</span></code> has been
defined in the consumer configuration).</p>
<p>Combining mirroring with the configuration
<code class="docutils literal"><span class="pre">auto.create.topics.enable=true</span></code> makes it possible to have a replica
cluster that will automatically create and replicate all data in a
source cluster even as new topics are added.</p>
</div>
<div class="section" id="checking-consumer-position">
<h3><a class="reference external" href="#basic_ops_consumer_lag">Checking consumer position</a><a class="headerlink" href="#checking-consumer-position" title="Permalink to this headline">Â¶</a></h3>
<p>Sometimes it&#8217;s useful to see the position of your consumers. We have a
tool that will show the position of all consumers in a consumer group as
well as how far behind the end of the log they are. To run this tool on
a consumer group named <em>my-group</em> consuming a topic named <em>my-topic</em>
would look like this:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">group</span> <span class="n">my</span><span class="o">-</span><span class="n">group</span>

<span class="n">Note</span><span class="p">:</span> <span class="n">This</span> <span class="n">will</span> <span class="n">only</span> <span class="n">show</span> <span class="n">information</span> <span class="n">about</span> <span class="n">consumers</span> <span class="n">that</span> <span class="n">use</span> <span class="n">the</span> <span class="n">Java</span> <span class="n">consumer</span> <span class="n">API</span> <span class="p">(</span><span class="n">non</span><span class="o">-</span><span class="n">ZooKeeper</span><span class="o">-</span><span class="n">based</span> <span class="n">consumers</span><span class="p">)</span><span class="o">.</span>

<span class="n">TOPIC</span>                          <span class="n">PARTITION</span>  <span class="n">CURRENT</span><span class="o">-</span><span class="n">OFFSET</span>  <span class="n">LOG</span><span class="o">-</span><span class="n">END</span><span class="o">-</span><span class="n">OFFSET</span>  <span class="n">LAG</span>        <span class="n">CONSUMER</span><span class="o">-</span><span class="n">ID</span>                                       <span class="n">HOST</span>                           <span class="n">CLIENT</span><span class="o">-</span><span class="n">ID</span>
<span class="n">my</span><span class="o">-</span><span class="n">topic</span>                       <span class="mi">0</span>          <span class="mi">2</span>               <span class="mi">4</span>               <span class="mi">2</span>          <span class="n">consumer</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">029</span><span class="n">af89c</span><span class="o">-</span><span class="mi">873</span><span class="n">c</span><span class="o">-</span><span class="mi">4751</span><span class="o">-</span><span class="n">a720</span><span class="o">-</span><span class="n">cefd41a669d6</span>   <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>                     <span class="n">consumer</span><span class="o">-</span><span class="mi">1</span>
<span class="n">my</span><span class="o">-</span><span class="n">topic</span>                       <span class="mi">1</span>          <span class="mi">2</span>               <span class="mi">3</span>               <span class="mi">1</span>          <span class="n">consumer</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">029</span><span class="n">af89c</span><span class="o">-</span><span class="mi">873</span><span class="n">c</span><span class="o">-</span><span class="mi">4751</span><span class="o">-</span><span class="n">a720</span><span class="o">-</span><span class="n">cefd41a669d6</span>   <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>                     <span class="n">consumer</span><span class="o">-</span><span class="mi">1</span>
<span class="n">my</span><span class="o">-</span><span class="n">topic</span>                       <span class="mi">2</span>          <span class="mi">2</span>               <span class="mi">3</span>               <span class="mi">1</span>          <span class="n">consumer</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="mi">42</span><span class="n">c1abd4</span><span class="o">-</span><span class="n">e3b2</span><span class="o">-</span><span class="mi">425</span><span class="n">d</span><span class="o">-</span><span class="n">a8bb</span><span class="o">-</span><span class="n">e1ea49b29bb2</span>   <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>                     <span class="n">consumer</span><span class="o">-</span><span class="mi">2</span>
</pre></div>
</div>
<p>This tool also works with ZooKeeper-based consumers:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">group</span> <span class="n">my</span><span class="o">-</span><span class="n">group</span>

<span class="n">Note</span><span class="p">:</span> <span class="n">This</span> <span class="n">will</span> <span class="n">only</span> <span class="n">show</span> <span class="n">information</span> <span class="n">about</span> <span class="n">consumers</span> <span class="n">that</span> <span class="n">use</span> <span class="n">ZooKeeper</span> <span class="p">(</span><span class="ow">not</span> <span class="n">those</span> <span class="n">using</span> <span class="n">the</span> <span class="n">Java</span> <span class="n">consumer</span> <span class="n">API</span><span class="p">)</span><span class="o">.</span>

<span class="n">TOPIC</span>                          <span class="n">PARTITION</span>  <span class="n">CURRENT</span><span class="o">-</span><span class="n">OFFSET</span>  <span class="n">LOG</span><span class="o">-</span><span class="n">END</span><span class="o">-</span><span class="n">OFFSET</span>  <span class="n">LAG</span>        <span class="n">CONSUMER</span><span class="o">-</span><span class="n">ID</span>
<span class="n">my</span><span class="o">-</span><span class="n">topic</span>                       <span class="mi">0</span>          <span class="mi">2</span>               <span class="mi">4</span>               <span class="mi">2</span>          <span class="n">my</span><span class="o">-</span><span class="n">group_consumer</span><span class="o">-</span><span class="mi">1</span>
<span class="n">my</span><span class="o">-</span><span class="n">topic</span>                       <span class="mi">1</span>          <span class="mi">2</span>               <span class="mi">3</span>               <span class="mi">1</span>          <span class="n">my</span><span class="o">-</span><span class="n">group_consumer</span><span class="o">-</span><span class="mi">1</span>
<span class="n">my</span><span class="o">-</span><span class="n">topic</span>                       <span class="mi">2</span>          <span class="mi">2</span>               <span class="mi">3</span>               <span class="mi">1</span>          <span class="n">my</span><span class="o">-</span><span class="n">group_consumer</span><span class="o">-</span><span class="mi">2</span>
</pre></div>
</div>
</div>
<div class="section" id="managing-consumer-groups">
<h3><a class="reference external" href="#basic_ops_consumer_group">Managing Consumer Groups</a><a class="headerlink" href="#managing-consumer-groups" title="Permalink to this headline">Â¶</a></h3>
<p>With the ConsumerGroupCommand tool, we can list, describe, or delete
consumer groups. Note that deletion is only available when the group
metadata is stored in ZooKeeper. When using the <a class="reference external" href="http://kafka.apache.org/documentation.html#newconsumerapi">new consumer
API</a>
(where the broker handles coordination of partition handling and
rebalance), the group is deleted when the last committed offset for that
group expires. For example, to list all consumer groups across all
topics:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="nb">list</span>

<span class="n">test</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">group</span>
</pre></div>
</div>
<p>To view offsets, as mentioned earlier, we &#8220;describe&#8221; the consumer group
like this:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">group</span> <span class="n">my</span><span class="o">-</span><span class="n">group</span>

<span class="n">TOPIC</span>           <span class="n">PARTITION</span>  <span class="n">CURRENT</span><span class="o">-</span><span class="n">OFFSET</span>  <span class="n">LOG</span><span class="o">-</span><span class="n">END</span><span class="o">-</span><span class="n">OFFSET</span>  <span class="n">LAG</span>             <span class="n">CONSUMER</span><span class="o">-</span><span class="n">ID</span>                                    <span class="n">HOST</span>            <span class="n">CLIENT</span><span class="o">-</span><span class="n">ID</span>
<span class="n">topic3</span>          <span class="mi">0</span>          <span class="mi">241019</span>          <span class="mi">395308</span>          <span class="mi">154289</span>          <span class="n">consumer2</span><span class="o">-</span><span class="n">e76ea8c3</span><span class="o">-</span><span class="mi">5</span><span class="n">d30</span><span class="o">-</span><span class="mi">4299</span><span class="o">-</span><span class="mi">9005</span><span class="o">-</span><span class="mi">47</span><span class="n">eb41f3d3c4</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer2</span>
<span class="n">topic2</span>          <span class="mi">1</span>          <span class="mi">520678</span>          <span class="mi">803288</span>          <span class="mi">282610</span>          <span class="n">consumer2</span><span class="o">-</span><span class="n">e76ea8c3</span><span class="o">-</span><span class="mi">5</span><span class="n">d30</span><span class="o">-</span><span class="mi">4299</span><span class="o">-</span><span class="mi">9005</span><span class="o">-</span><span class="mi">47</span><span class="n">eb41f3d3c4</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer2</span>
<span class="n">topic3</span>          <span class="mi">1</span>          <span class="mi">241018</span>          <span class="mi">398817</span>          <span class="mi">157799</span>          <span class="n">consumer2</span><span class="o">-</span><span class="n">e76ea8c3</span><span class="o">-</span><span class="mi">5</span><span class="n">d30</span><span class="o">-</span><span class="mi">4299</span><span class="o">-</span><span class="mi">9005</span><span class="o">-</span><span class="mi">47</span><span class="n">eb41f3d3c4</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer2</span>
<span class="n">topic1</span>          <span class="mi">0</span>          <span class="mi">854144</span>          <span class="mi">855809</span>          <span class="mi">1665</span>            <span class="n">consumer1</span><span class="o">-</span><span class="mi">3</span><span class="n">fc8d6f1</span><span class="o">-</span><span class="mi">581</span><span class="n">a</span><span class="o">-</span><span class="mi">4472</span><span class="o">-</span><span class="n">bdf3</span><span class="o">-</span><span class="mi">3515</span><span class="n">b4aee8c1</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer1</span>
<span class="n">topic2</span>          <span class="mi">0</span>          <span class="mi">460537</span>          <span class="mi">803290</span>          <span class="mi">342753</span>          <span class="n">consumer1</span><span class="o">-</span><span class="mi">3</span><span class="n">fc8d6f1</span><span class="o">-</span><span class="mi">581</span><span class="n">a</span><span class="o">-</span><span class="mi">4472</span><span class="o">-</span><span class="n">bdf3</span><span class="o">-</span><span class="mi">3515</span><span class="n">b4aee8c1</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer1</span>
<span class="n">topic3</span>          <span class="mi">2</span>          <span class="mi">243655</span>          <span class="mi">398812</span>          <span class="mi">155157</span>          <span class="n">consumer4</span><span class="o">-</span><span class="mi">117</span><span class="n">fe4d3</span><span class="o">-</span><span class="n">c6c1</span><span class="o">-</span><span class="mi">4178</span><span class="o">-</span><span class="mi">8</span><span class="n">ee9</span><span class="o">-</span><span class="n">eb4a3954bee0</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer4</span>
</pre></div>
</div>
<p>There are a number of additional &#8220;describe&#8221; options that can be used to
provide more detailed information about a consumer group that uses the
new consumer API:</p>
<ul>
<li><p class="first">&#8211;members: This option provides the list of all active members in the
consumer group.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">group</span> <span class="n">my</span><span class="o">-</span><span class="n">group</span> <span class="o">--</span><span class="n">members</span>

<span class="n">CONSUMER</span><span class="o">-</span><span class="n">ID</span>                                    <span class="n">HOST</span>            <span class="n">CLIENT</span><span class="o">-</span><span class="n">ID</span>       <span class="c1">#PARTITIONS</span>
<span class="n">consumer1</span><span class="o">-</span><span class="mi">3</span><span class="n">fc8d6f1</span><span class="o">-</span><span class="mi">581</span><span class="n">a</span><span class="o">-</span><span class="mi">4472</span><span class="o">-</span><span class="n">bdf3</span><span class="o">-</span><span class="mi">3515</span><span class="n">b4aee8c1</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer1</span>       <span class="mi">2</span>
<span class="n">consumer4</span><span class="o">-</span><span class="mi">117</span><span class="n">fe4d3</span><span class="o">-</span><span class="n">c6c1</span><span class="o">-</span><span class="mi">4178</span><span class="o">-</span><span class="mi">8</span><span class="n">ee9</span><span class="o">-</span><span class="n">eb4a3954bee0</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer4</span>       <span class="mi">1</span>
<span class="n">consumer2</span><span class="o">-</span><span class="n">e76ea8c3</span><span class="o">-</span><span class="mi">5</span><span class="n">d30</span><span class="o">-</span><span class="mi">4299</span><span class="o">-</span><span class="mi">9005</span><span class="o">-</span><span class="mi">47</span><span class="n">eb41f3d3c4</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer2</span>       <span class="mi">3</span>
<span class="n">consumer3</span><span class="o">-</span><span class="n">ecea43e4</span><span class="o">-</span><span class="mi">1</span><span class="n">f01</span><span class="o">-</span><span class="mi">479</span><span class="n">f</span><span class="o">-</span><span class="mi">8349</span><span class="o">-</span><span class="n">f9130b75d8ee</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer3</span>       <span class="mi">0</span>
</pre></div>
</div>
</li>
<li><p class="first">&#8211;members &#8211;verbose: On top of the information reported by the
&#8220;&#8211;members&#8221; options above, this option also provides the partitions
assigned to each member.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">group</span> <span class="n">my</span><span class="o">-</span><span class="n">group</span> <span class="o">--</span><span class="n">members</span> <span class="o">--</span><span class="n">verbose</span>

<span class="n">CONSUMER</span><span class="o">-</span><span class="n">ID</span>                                    <span class="n">HOST</span>            <span class="n">CLIENT</span><span class="o">-</span><span class="n">ID</span>       <span class="c1">#PARTITIONS     ASSIGNMENT</span>
<span class="n">consumer1</span><span class="o">-</span><span class="mi">3</span><span class="n">fc8d6f1</span><span class="o">-</span><span class="mi">581</span><span class="n">a</span><span class="o">-</span><span class="mi">4472</span><span class="o">-</span><span class="n">bdf3</span><span class="o">-</span><span class="mi">3515</span><span class="n">b4aee8c1</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer1</span>       <span class="mi">2</span>               <span class="n">topic1</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">topic2</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">consumer4</span><span class="o">-</span><span class="mi">117</span><span class="n">fe4d3</span><span class="o">-</span><span class="n">c6c1</span><span class="o">-</span><span class="mi">4178</span><span class="o">-</span><span class="mi">8</span><span class="n">ee9</span><span class="o">-</span><span class="n">eb4a3954bee0</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer4</span>       <span class="mi">1</span>               <span class="n">topic3</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">consumer2</span><span class="o">-</span><span class="n">e76ea8c3</span><span class="o">-</span><span class="mi">5</span><span class="n">d30</span><span class="o">-</span><span class="mi">4299</span><span class="o">-</span><span class="mi">9005</span><span class="o">-</span><span class="mi">47</span><span class="n">eb41f3d3c4</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer2</span>       <span class="mi">3</span>               <span class="n">topic2</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">topic3</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">consumer3</span><span class="o">-</span><span class="n">ecea43e4</span><span class="o">-</span><span class="mi">1</span><span class="n">f01</span><span class="o">-</span><span class="mi">479</span><span class="n">f</span><span class="o">-</span><span class="mi">8349</span><span class="o">-</span><span class="n">f9130b75d8ee</span> <span class="o">/</span><span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>      <span class="n">consumer3</span>       <span class="mi">0</span>               <span class="o">-</span>
</pre></div>
</div>
</li>
<li><p class="first">&#8211;offsets: This is the default describe option and provides the same
output as the &#8220;&#8211;describe&#8221; option.</p>
</li>
<li><p class="first">&#8211;state: This option provides useful group-level information.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">group</span> <span class="n">my</span><span class="o">-</span><span class="n">group</span> <span class="o">--</span><span class="n">state</span>

<span class="n">COORDINATOR</span> <span class="p">(</span><span class="n">ID</span><span class="p">)</span>          <span class="n">ASSIGNMENT</span><span class="o">-</span><span class="n">STRATEGY</span>       <span class="n">STATE</span>                <span class="c1">#MEMBERS</span>
<span class="n">localhost</span><span class="p">:</span><span class="mi">9092</span> <span class="p">(</span><span class="mi">0</span><span class="p">)</span>        <span class="nb">range</span>                     <span class="n">Stable</span>               <span class="mi">4</span>
</pre></div>
</div>
</li>
</ul>
<p>If you are using the old high-level consumer and storing the group
metadata in ZooKeeper (i.e. <code class="docutils literal"><span class="pre">offsets.storage=zookeeper</span></code>), pass
<code class="docutils literal"><span class="pre">--zookeeper</span></code> instead of <code class="docutils literal"><span class="pre">bootstrap-server</span></code>:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">consumer</span><span class="o">-</span><span class="n">groups</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="nb">list</span>
</pre></div>
</div>
</div>
<div class="section" id="expanding-your-cluster">
<h3><a class="reference external" href="#basic_ops_cluster_expansion">Expanding your cluster</a><a class="headerlink" href="#expanding-your-cluster" title="Permalink to this headline">Â¶</a></h3>
<p>Adding servers to a Kafka cluster is easy, just assign them a unique
broker id and start up Kafka on your new servers. However these new
servers will not automatically be assigned any data partitions, so
unless partitions are moved to them they won&#8217;t be doing any work until
new topics are created. So usually when you add machines to your cluster
you will want to migrate some existing data to these machines.</p>
<p>The process of migrating data is manually initiated but fully automated.
Under the covers what happens is that Kafka will add the new server as a
follower of the partition it is migrating and allow it to fully
replicate the existing data in that partition. When the new server has
fully replicated the contents of this partition and joined the in-sync
replica one of the existing replicas will delete their partition&#8217;s data.</p>
<p>The partition reassignment tool can be used to move partitions across
brokers. An ideal partition distribution would ensure even data load and
partition sizes across all brokers. The partition reassignment tool does
not have the capability to automatically study the data distribution in
a Kafka cluster and move partitions around to attain an even load
distribution. As such, the admin has to figure out which topics or
partitions should be moved around.</p>
<p>The partition reassignment tool can run in 3 mutually exclusive modes:</p>
<ul class="simple">
<li>&#8211;generate: In this mode, given a list of topics and a list of
brokers, the tool generates a candidate reassignment to move all
partitions of the specified topics to the new brokers. This option
merely provides a convenient way to generate a partition reassignment
plan given a list of topics and target brokers.</li>
<li>&#8211;execute: In this mode, the tool kicks off the reassignment of
partitions based on the user provided reassignment plan. (using the
&#8211;reassignment-json-file option). This can either be a custom
reassignment plan hand crafted by the admin or provided by using the
&#8211;generate option</li>
<li>&#8211;verify: In this mode, the tool verifies the status of the
reassignment for all partitions listed during the last &#8211;execute. The
status can be either of successfully completed, failed or in progress</li>
</ul>
<div class="section" id="automatically-migrating-data-to-new-machines">
<h4><a class="reference external" href="#basic_ops_automigrate">Automatically migrating data to new machines</a><a class="headerlink" href="#automatically-migrating-data-to-new-machines" title="Permalink to this headline">Â¶</a></h4>
<p>The partition reassignment tool can be used to move some topics off of
the current set of brokers to the newly added brokers. This is typically
useful while expanding an existing cluster since it is easier to move
entire topics to the new set of brokers, than moving one partition at a
time. When used to do this, the user should provide a list of topics
that should be moved to the new set of brokers and a target list of new
brokers. The tool then evenly distributes all partitions for the given
list of topics across the new set of brokers. During this move, the
replication factor of the topic is kept constant. Effectively the
replicas for all partitions for the input list of topics are moved from
the old set of brokers to the newly added brokers.</p>
<p>For instance, the following example will move all partitions for topics
foo1,foo2 to the new set of brokers 5,6. At the end of this move, all
partitions for topics foo1 and foo2 will <em>only</em> exist on brokers 5,6.</p>
<p>Since the tool accepts the input list of topics as a json file, you
first need to identify the topics you want to move and create the json
file as follows:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">cat</span> <span class="n">topics</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">move</span><span class="o">.</span><span class="n">json</span>
<span class="p">{</span><span class="s2">&quot;topics&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;foo1&quot;</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span> <span class="s2">&quot;foo2&quot;</span><span class="p">}],</span>
<span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Once the json file is ready, use the partition reassignment tool to
generate a candidate assignment:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">topics</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">move</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">topics</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">move</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">broker</span><span class="o">-</span><span class="nb">list</span> <span class="s2">&quot;5,6&quot;</span> <span class="o">--</span><span class="n">generate</span>
<span class="n">Current</span> <span class="n">partition</span> <span class="n">replica</span> <span class="n">assignment</span>

<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]}]</span>
<span class="p">}</span>

<span class="n">Proposed</span> <span class="n">partition</span> <span class="n">reassignment</span> <span class="n">configuration</span>

<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]}]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The tool generates a candidate assignment that will move all partitions
from topics foo1,foo2 to brokers 5,6. Note, however, that at this point,
the partition movement has not started, it merely tells you the current
assignment and the proposed new assignment. The current assignment
should be saved in case you want to rollback to it. The new assignment
should be saved in a json file (e.g. expand-cluster-reassignment.json)
to be input to the tool with the &#8211;execute option as follows:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">expand</span><span class="o">-</span><span class="n">cluster</span><span class="o">-</span><span class="n">reassignment</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">execute</span>
<span class="n">Current</span> <span class="n">partition</span> <span class="n">replica</span> <span class="n">assignment</span>

<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]}]</span>
<span class="p">}</span>

<span class="n">Save</span> <span class="n">this</span> <span class="n">to</span> <span class="n">use</span> <span class="k">as</span> <span class="n">the</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">option</span> <span class="n">during</span> <span class="n">rollback</span>
<span class="n">Successfully</span> <span class="n">started</span> <span class="n">reassignment</span> <span class="n">of</span> <span class="n">partitions</span>
<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]}]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Finally, the &#8211;verify option can be used with the tool to check the
status of the partition reassignment. Note that the same
expand-cluster-reassignment.json (used with the &#8211;execute option) should
be used with the &#8211;verify option:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">expand</span><span class="o">-</span><span class="n">cluster</span><span class="o">-</span><span class="n">reassignment</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">verify</span>
<span class="n">Status</span> <span class="n">of</span> <span class="n">partition</span> <span class="n">reassignment</span><span class="p">:</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">in</span> <span class="n">progress</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">in</span> <span class="n">progress</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-partition-assignment-and-migration">
<h4><a class="reference external" href="#basic_ops_partitionassignment">Custom partition assignment and migration</a><a class="headerlink" href="#custom-partition-assignment-and-migration" title="Permalink to this headline">Â¶</a></h4>
<p>The partition reassignment tool can also be used to selectively move
replicas of a partition to a specific set of brokers. When used in this
manner, it is assumed that the user knows the reassignment plan and does
not require the tool to generate a candidate reassignment, effectively
skipping the &#8211;generate step and moving straight to the &#8211;execute step</p>
<p>For instance, the following example moves partition 0 of topic foo1 to
brokers 5,6 and partition 1 of topic foo2 to brokers 2,3:</p>
<p>The first step is to hand craft the custom reassignment plan in a json
file:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">cat</span> <span class="n">custom</span><span class="o">-</span><span class="n">reassignment</span><span class="o">.</span><span class="n">json</span>
<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]}]}</span>
</pre></div>
</div>
<p>Then, use the json file with the &#8211;execute option to start the
reassignment process:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">custom</span><span class="o">-</span><span class="n">reassignment</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">execute</span>
<span class="n">Current</span> <span class="n">partition</span> <span class="n">replica</span> <span class="n">assignment</span>

<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]}]</span>
<span class="p">}</span>

<span class="n">Save</span> <span class="n">this</span> <span class="n">to</span> <span class="n">use</span> <span class="k">as</span> <span class="n">the</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">option</span> <span class="n">during</span> <span class="n">rollback</span>
<span class="n">Successfully</span> <span class="n">started</span> <span class="n">reassignment</span> <span class="n">of</span> <span class="n">partitions</span>
<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo1&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]},</span>
              <span class="p">{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo2&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]}]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The &#8211;verify option can be used with the tool to check the status of the
partition reassignment. Note that the same
expand-cluster-reassignment.json (used with the &#8211;execute option) should
be used with the &#8211;verify option:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">custom</span><span class="o">-</span><span class="n">reassignment</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">verify</span>
<span class="n">Status</span> <span class="n">of</span> <span class="n">partition</span> <span class="n">reassignment</span><span class="p">:</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="decommissioning-brokers">
<h3><a class="reference external" href="#basic_ops_decommissioning_brokers">Decommissioning brokers</a><a class="headerlink" href="#decommissioning-brokers" title="Permalink to this headline">Â¶</a></h3>
<p>The partition reassignment tool does not have the ability to
automatically generate a reassignment plan for decommissioning brokers
yet. As such, the admin has to come up with a reassignment plan to move
the replica for all partitions hosted on the broker to be
decommissioned, to the rest of the brokers. This can be relatively
tedious as the reassignment needs to ensure that all the replicas are
not moved from the decommissioned broker to only one other broker. To
make this process effortless, we plan to add tooling support for
decommissioning brokers in the future.</p>
</div>
<div class="section" id="increasing-replication-factor">
<h3><a class="reference external" href="#basic_ops_increase_replication_factor">Increasing replication factor</a><a class="headerlink" href="#increasing-replication-factor" title="Permalink to this headline">Â¶</a></h3>
<p>Increasing the replication factor of an existing partition is easy. Just
specify the extra replicas in the custom reassignment json file and use
it with the &#8211;execute option to increase the replication factor of the
specified partitions.</p>
<p>For instance, the following example increases the replication factor of
partition 0 of topic foo from 1 to 3. Before increasing the replication
factor, the partition&#8217;s only replica existed on broker 5. As part of
increasing the replication factor, we will add more replicas on brokers
6 and 7.</p>
<p>The first step is to hand craft the custom reassignment plan in a json
file:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">cat</span> <span class="n">increase</span><span class="o">-</span><span class="n">replication</span><span class="o">-</span><span class="n">factor</span><span class="o">.</span><span class="n">json</span>
<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]}]}</span>
</pre></div>
</div>
<p>Then, use the json file with the &#8211;execute option to start the
reassignment process:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">increase</span><span class="o">-</span><span class="n">replication</span><span class="o">-</span><span class="n">factor</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">execute</span>
<span class="n">Current</span> <span class="n">partition</span> <span class="n">replica</span> <span class="n">assignment</span>

<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">]}]}</span>

<span class="n">Save</span> <span class="n">this</span> <span class="n">to</span> <span class="n">use</span> <span class="k">as</span> <span class="n">the</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">option</span> <span class="n">during</span> <span class="n">rollback</span>
<span class="n">Successfully</span> <span class="n">started</span> <span class="n">reassignment</span> <span class="n">of</span> <span class="n">partitions</span>
<span class="p">{</span><span class="s2">&quot;version&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="s2">&quot;partitions&quot;</span><span class="p">:[{</span><span class="s2">&quot;topic&quot;</span><span class="p">:</span><span class="s2">&quot;foo&quot;</span><span class="p">,</span><span class="s2">&quot;partition&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s2">&quot;replicas&quot;</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]}]}</span>
</pre></div>
</div>
<p>The &#8211;verify option can be used with the tool to check the status of the
partition reassignment. Note that the same
increase-replication-factor.json (used with the &#8211;execute option) should
be used with the &#8211;verify option:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">increase</span><span class="o">-</span><span class="n">replication</span><span class="o">-</span><span class="n">factor</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">verify</span>
<span class="n">Status</span> <span class="n">of</span> <span class="n">partition</span> <span class="n">reassignment</span><span class="p">:</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">foo</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
</pre></div>
</div>
<p>You can also verify the increase in replication factor with the
kafka-topics tool:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">topics</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">topic</span> <span class="n">foo</span> <span class="o">--</span><span class="n">describe</span>
<span class="n">Topic</span><span class="p">:</span><span class="n">foo</span> <span class="n">PartitionCount</span><span class="p">:</span><span class="mi">1</span>    <span class="n">ReplicationFactor</span><span class="p">:</span><span class="mi">3</span> <span class="n">Configs</span><span class="p">:</span>
  <span class="n">Topic</span><span class="p">:</span> <span class="n">foo</span>  <span class="n">Partition</span><span class="p">:</span> <span class="mi">0</span>    <span class="n">Leader</span><span class="p">:</span> <span class="mi">5</span>   <span class="n">Replicas</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span> <span class="n">Isr</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span>
</pre></div>
</div>
</div>
<div class="section" id="limiting-bandwidth-usage-during-data-migration">
<h3><a class="reference external" href="#rep-throttle">Limiting Bandwidth Usage during Data Migration</a><a class="headerlink" href="#limiting-bandwidth-usage-during-data-migration" title="Permalink to this headline">Â¶</a></h3>
<p>Kafka lets you apply a throttle to replication traffic, setting an upper
bound on the bandwidth used to move replicas from machine to machine.
This is useful when rebalancing a cluster, bootstrapping a new broker or
adding or removing brokers, as it limits the impact these data-intensive
operations will have on users.</p>
<p>There are two interfaces that can be used to engage a throttle. The
simplest, and safest, is to apply a throttle when invoking the
kafka-reassign-partitions.sh, but kafka-configs.sh can also be used to
view and alter the throttle values directly.</p>
<p>So for example, if you were to execute a rebalance, with the below
command, it would move partitions at no more than 50MB/s.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>$ bin/kafka-reassign-partitions.sh --zookeeper myhost:2181--execute --reassignment-json-file bigger-cluster.json âthrottle 50000000
</pre></div>
</div>
<p>When you execute this script you will see the throttle engage:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">throttle</span> <span class="n">limit</span> <span class="n">was</span> <span class="nb">set</span> <span class="n">to</span> <span class="mi">50000000</span> <span class="n">B</span><span class="o">/</span><span class="n">s</span>
<span class="n">Successfully</span> <span class="n">started</span> <span class="n">reassignment</span> <span class="n">of</span> <span class="n">partitions</span><span class="o">.</span>
</pre></div>
</div>
<p>Should you wish to alter the throttle, during a rebalance, say to
increase the throughput so it completes quicker, you can do this by
re-running the execute command passing the same reassignment-json-file:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>$ bin/kafka-reassign-partitions.sh --zookeeper localhost:2181  --execute --reassignment-json-file bigger-cluster.json --throttle 700000000
  There is an existing assignment running.
  The throttle limit was set to 700000000 B/s
</pre></div>
</div>
<p>Once the rebalance completes the administrator can check the status of
the rebalance using the &#8211;verify option. If the rebalance has completed,
the throttle will be removed via the &#8211;verify command. It is important
that administrators remove the throttle in a timely manner once
rebalancing completes by running the command with the &#8211;verify option.
Failure to do so could cause regular replication traffic to be
throttled.</p>
<p>When the &#8211;verify option is executed, and the reassignment has
completed, the script will confirm that the throttle was removed:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">reassign</span><span class="o">-</span><span class="n">partitions</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span>  <span class="o">--</span><span class="n">verify</span> <span class="o">--</span><span class="n">reassignment</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="n">file</span> <span class="n">bigger</span><span class="o">-</span><span class="n">cluster</span><span class="o">.</span><span class="n">json</span>
<span class="n">Status</span> <span class="n">of</span> <span class="n">partition</span> <span class="n">reassignment</span><span class="p">:</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">my</span><span class="o">-</span><span class="n">topic</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="n">Reassignment</span> <span class="n">of</span> <span class="n">partition</span> <span class="p">[</span><span class="n">mytopic</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="n">completed</span> <span class="n">successfully</span>
<span class="n">Throttle</span> <span class="n">was</span> <span class="n">removed</span><span class="o">.</span>
</pre></div>
</div>
<p>The administrator can also validate the assigned configs using the
kafka-configs.sh. There are two pairs of throttle configuration used to
manage the throttling process. The throttle value itself. This is
configured, at a broker level, using the dynamic properties:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">leader</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">rate</span>
  <span class="n">follower</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">rate</span>
</pre></div>
</div>
<p>There is also an enumerated set of throttled replicas:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">leader</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">replicas</span>
  <span class="n">follower</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">replicas</span>
</pre></div>
</div>
<p>Which are configured per topic. All four config values are automatically
assigned by kafka-reassign-partitions.sh (discussed below).</p>
<p>To view the throttle limit configuration:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">brokers</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">brokers</span> <span class="s1">&#39;2&#39;</span> <span class="n">are</span> <span class="n">leader</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">rate</span><span class="o">=</span><span class="mi">700000000</span><span class="p">,</span><span class="n">follower</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">rate</span><span class="o">=</span><span class="mi">700000000</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">brokers</span> <span class="s1">&#39;1&#39;</span> <span class="n">are</span> <span class="n">leader</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">rate</span><span class="o">=</span><span class="mi">700000000</span><span class="p">,</span><span class="n">follower</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">rate</span><span class="o">=</span><span class="mi">700000000</span>
</pre></div>
</div>
<p>This shows the throttle applied to both leader and follower side of the
replication protocol. By default both sides are assigned the same
throttled throughput value.</p>
<p>To view the list of throttled replicas:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">topics</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">topic</span> <span class="s1">&#39;my-topic&#39;</span> <span class="n">are</span> <span class="n">leader</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span><span class="mi">102</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">101</span><span class="p">,</span>
    <span class="n">follower</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">throttled</span><span class="o">.</span><span class="n">replicas</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span><span class="mi">101</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">102</span>
</pre></div>
</div>
<p>Here we see the leader throttle is applied to partition 1 on broker 102
and partition 0 on broker 101. Likewise the follower throttle is applied
to partition 1 on broker 101 and partition 0 on broker 102.</p>
<p>By default kafka-reassign-partitions.sh will apply the leader throttle
to all replicas that exist before the rebalance, any one of which might
be leader. It will apply the follower throttle to all move destinations.
So if there is a partition with replicas on brokers 101,102, being
reassigned to 102,103, a leader throttle, for that partition, would be
applied to 101,102 and a follower throttle would be applied to 103 only.</p>
<p>If required, you can also use the &#8211;alter switch on kafka-configs.sh to
alter the throttle configurations manually.</p>
<div class="section" id="safe-usage-of-throttled-replication">
<h4><a class="toc-backref" href="#id22">Safe usage of throttled replication</a><a class="headerlink" href="#safe-usage-of-throttled-replication" title="Permalink to this headline">Â¶</a></h4>
<p>Some care should be taken when using throttled replication. In
particular:</p>
<p><em>(1) Throttle Removal:</em></p>
<p>The throttle should be removed in a timely manner once reassignment
completes (by running kafka-reassign-partitions âverify).</p>
<p><em>(2) Ensuring Progress:</em></p>
<p>If the throttle is set too low, in comparison to the incoming write
rate, it is possible for replication to not make progress. This occurs
when:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nb">max</span><span class="p">(</span><span class="n">BytesInPerSec</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">throttle</span>
</pre></div>
</div>
<p>Where BytesInPerSec is the metric that monitors the write throughput of
producers into each broker.</p>
<p>The administrator can monitor whether replication is making progress,
during the rebalance, using the metric:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">kafka</span><span class="o">.</span><span class="n">server</span><span class="p">:</span><span class="nb">type</span><span class="o">=</span><span class="n">FetcherLagMetrics</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="n">ConsumerLag</span><span class="p">,</span><span class="n">clientId</span><span class="o">=</span><span class="p">([</span><span class="o">-.</span>\<span class="n">w</span><span class="p">]</span><span class="o">+</span><span class="p">),</span><span class="n">topic</span><span class="o">=</span><span class="p">([</span><span class="o">-.</span>\<span class="n">w</span><span class="p">]</span><span class="o">+</span><span class="p">),</span><span class="n">partition</span><span class="o">=</span><span class="p">([</span><span class="mi">0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+</span><span class="p">)</span>
</pre></div>
</div>
<p>The lag should constantly decrease during replication. If the metric
does not decrease the administrator should increase the throttle
throughput as described above.</p>
</div>
</div>
<div class="section" id="setting-quotas">
<h3><a class="reference external" href="#quotas">Setting quotas</a><a class="headerlink" href="#setting-quotas" title="Permalink to this headline">Â¶</a></h3>
<p>Quotas overrides and defaults may be configured at (user, client-id),
user or client-id levels as described <a class="reference external" href="#design_quotas">here</a>. By
default, clients receive an unlimited quota. It is possible to set
custom quotas for each (user, client-id), user or client-id group.</p>
<p>Configure custom quota for (user=user1, client-id=clientA):</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="s1">&#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&#39;</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">user1</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">clientA</span>
<span class="n">Updated</span> <span class="n">config</span> <span class="k">for</span> <span class="n">entity</span><span class="p">:</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span><span class="p">,</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span> <span class="s1">&#39;clientA&#39;</span><span class="o">.</span>
</pre></div>
</div>
<p>Configure custom quota for user=user1:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="s1">&#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&#39;</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">user1</span>
<span class="n">Updated</span> <span class="n">config</span> <span class="k">for</span> <span class="n">entity</span><span class="p">:</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span><span class="o">.</span>
</pre></div>
</div>
<p>Configure custom quota for client-id=clientA:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="s1">&#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&#39;</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">clientA</span>
<span class="n">Updated</span> <span class="n">config</span> <span class="k">for</span> <span class="n">entity</span><span class="p">:</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span> <span class="s1">&#39;clientA&#39;</span><span class="o">.</span>
</pre></div>
</div>
<p>It is possible to set default quotas for each (user, client-id), user or
client-id group by specifying <em>&#8211;entity-default</em> option instead of
<em>&#8211;entity-name</em>.</p>
<p>Configure default client-id quota for user=userA:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="s1">&#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&#39;</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">user1</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">default</span>
<span class="n">Updated</span> <span class="n">config</span> <span class="k">for</span> <span class="n">entity</span><span class="p">:</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span><span class="p">,</span> <span class="n">default</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span><span class="o">.</span>
</pre></div>
</div>
<p>Configure default quota for user:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="s1">&#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&#39;</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">default</span>
<span class="n">Updated</span> <span class="n">config</span> <span class="k">for</span> <span class="n">entity</span><span class="p">:</span> <span class="n">default</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span><span class="o">.</span>
</pre></div>
</div>
<p>Configure default quota for client-id:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">alter</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">config</span> <span class="s1">&#39;producer_byte_rate=1024,consumer_byte_rate=2048,request_percentage=200&#39;</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">default</span>
<span class="n">Updated</span> <span class="n">config</span> <span class="k">for</span> <span class="n">entity</span><span class="p">:</span> <span class="n">default</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span><span class="o">.</span>
</pre></div>
</div>
<p>Here&#8217;s how to describe the quota for a given (user, client-id):</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">user1</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">clientA</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span><span class="p">,</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span> <span class="s1">&#39;clientA&#39;</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
</pre></div>
</div>
<p>Describe quota for a given user:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">user1</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
</pre></div>
</div>
<p>Describe quota for a given client-id:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="n">name</span> <span class="n">clientA</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span> <span class="s1">&#39;clientA&#39;</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
</pre></div>
</div>
<p>If entity name is not specified, all entities of the specified type are
described. For example, describe all users:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">default</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
</pre></div>
</div>
<p>Similarly for (user, client):</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">configs</span><span class="o">.</span><span class="n">sh</span>  <span class="o">--</span><span class="n">zookeeper</span> <span class="n">localhost</span><span class="p">:</span><span class="mi">2181</span> <span class="o">--</span><span class="n">describe</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">users</span> <span class="o">--</span><span class="n">entity</span><span class="o">-</span><span class="nb">type</span> <span class="n">clients</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span><span class="p">,</span> <span class="n">default</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
<span class="n">Configs</span> <span class="k">for</span> <span class="n">user</span><span class="o">-</span><span class="n">principal</span> <span class="s1">&#39;user1&#39;</span><span class="p">,</span> <span class="n">client</span><span class="o">-</span><span class="nb">id</span> <span class="s1">&#39;clientA&#39;</span> <span class="n">are</span> <span class="n">producer_byte_rate</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span><span class="n">consumer_byte_rate</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">request_percentage</span><span class="o">=</span><span class="mi">200</span>
</pre></div>
</div>
<p>It is possible to set default quotas that apply to all client-ids by
setting these configs on the brokers. These properties are applied only
if quota overrides or defaults are not configured in Zookeeper. By
default, each client-id receives an unlimited quota. The following sets
the default quota per producer and consumer client-id to 10MB/sec.</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">quota</span><span class="o">.</span><span class="n">producer</span><span class="o">.</span><span class="n">default</span><span class="o">=</span><span class="mi">10485760</span>
<span class="n">quota</span><span class="o">.</span><span class="n">consumer</span><span class="o">.</span><span class="n">default</span><span class="o">=</span><span class="mi">10485760</span>
</pre></div>
</div>
<p>Note that these properties are being deprecated and may be removed in a
future release. Defaults configured using kafka-configs.sh take
precedence over these properties.</p>
</div>
</div>
<div class="section" id="datacenters">
<h2><a class="reference external" href="#datacenters">6.2 Datacenters</a><a class="headerlink" href="#datacenters" title="Permalink to this headline">Â¶</a></h2>
<p>Some deployments will need to manage a data pipeline that spans multiple
datacenters. Our recommended approach to this is to deploy a local Kafka
cluster in each datacenter with application instances in each datacenter
interacting only with their local cluster and mirroring between clusters
(see the documentation on the <a class="reference external" href="#basic_ops_mirror_maker">mirror maker
tool</a> for how to do this).</p>
<p>This deployment pattern allows datacenters to act as independent
entities and allows us to manage and tune inter-datacenter replication
centrally. This allows each facility to stand alone and operate even if
the inter-datacenter links are unavailable: when this occurs the
mirroring falls behind until the link is restored at which time it
catches up.</p>
<p>For applications that need a global view of all data you can use
mirroring to provide clusters which have aggregate data mirrored from
the local clusters in <em>all</em> datacenters. These aggregate clusters are
used for reads by applications that require the full data set.</p>
<p>This is not the only possible deployment pattern. It is possible to read
from or write to a remote Kafka cluster over the WAN, though obviously
this will add whatever latency is required to get the cluster.</p>
<p>Kafka naturally batches data in both the producer and consumer so it can
achieve high-throughput even over a high-latency connection. To allow
this though it may be necessary to increase the TCP socket buffer sizes
for the producer, consumer, and broker using the
<code class="docutils literal"><span class="pre">socket.send.buffer.bytes</span></code> and <code class="docutils literal"><span class="pre">socket.receive.buffer.bytes</span></code>
configurations. The appropriate way to set this is documented
<a class="reference external" href="http://en.wikipedia.org/wiki/Bandwidth-delay_product">here</a>.</p>
<p>It is generally <em>not</em> advisable to run a <em>single</em> Kafka cluster that
spans multiple datacenters over a high-latency link. This will incur
very high replication latency both for Kafka writes and ZooKeeper
writes, and neither Kafka nor ZooKeeper will remain available in all
locations if the network between locations is unavailable.</p>
</div>
<div class="section" id="kafka-configuration">
<h2><a class="reference external" href="#config">6.3 Kafka Configuration</a><a class="headerlink" href="#kafka-configuration" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="important-client-configurations">
<h3><a class="reference external" href="#clientconfig">Important Client Configurations</a><a class="headerlink" href="#important-client-configurations" title="Permalink to this headline">Â¶</a></h3>
<p>The most important old Scala producer configurations control</p>
<ul class="simple">
<li>acks</li>
<li>compression</li>
<li>sync vs async production</li>
<li>batch size (for async producers)</li>
</ul>
<p>The most important new Java producer configurations control</p>
<ul class="simple">
<li>acks</li>
<li>compression</li>
<li>batch size</li>
</ul>
<p>The most important consumer configuration is the fetch size.</p>
<p>All configurations are documented in the
<a class="reference external" href="#configuration">configuration</a> section.</p>
</div>
<div class="section" id="a-production-server-config">
<h3><a class="reference external" href="#prodconfig">A Production Server Config</a><a class="headerlink" href="#a-production-server-config" title="Permalink to this headline">Â¶</a></h3>
<p>Here is an example production server configuration:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="c1"># ZooKeeper</span>
<span class="n">zookeeper</span><span class="o">.</span><span class="n">connect</span><span class="o">=</span><span class="p">[</span><span class="nb">list</span> <span class="n">of</span> <span class="n">ZooKeeper</span> <span class="n">servers</span><span class="p">]</span>

<span class="c1"># Log configuration</span>
<span class="n">num</span><span class="o">.</span><span class="n">partitions</span><span class="o">=</span><span class="mi">8</span>
<span class="n">default</span><span class="o">.</span><span class="n">replication</span><span class="o">.</span><span class="n">factor</span><span class="o">=</span><span class="mi">3</span>
<span class="n">log</span><span class="o">.</span><span class="n">dir</span><span class="o">=</span><span class="p">[</span><span class="n">List</span> <span class="n">of</span> <span class="n">directories</span><span class="o">.</span> <span class="n">Kafka</span> <span class="n">should</span> <span class="n">have</span> <span class="n">its</span> <span class="n">own</span> <span class="n">dedicated</span> <span class="n">disk</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="ow">or</span> <span class="n">SSD</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="p">]</span>

<span class="c1"># Other configurations</span>
<span class="n">broker</span><span class="o">.</span><span class="n">id</span><span class="o">=</span><span class="p">[</span><span class="n">An</span> <span class="n">integer</span><span class="o">.</span> <span class="n">Start</span> <span class="k">with</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">increment</span> <span class="n">by</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">each</span> <span class="n">new</span> <span class="n">broker</span><span class="o">.</span><span class="p">]</span>
<span class="n">listeners</span><span class="o">=</span><span class="p">[</span><span class="nb">list</span> <span class="n">of</span> <span class="n">listeners</span><span class="p">]</span>
<span class="n">auto</span><span class="o">.</span><span class="n">create</span><span class="o">.</span><span class="n">topics</span><span class="o">.</span><span class="n">enable</span><span class="o">=</span><span class="n">false</span>
<span class="nb">min</span><span class="o">.</span><span class="n">insync</span><span class="o">.</span><span class="n">replicas</span><span class="o">=</span><span class="mi">2</span>
<span class="n">queued</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">requests</span><span class="o">=</span><span class="p">[</span><span class="n">number</span> <span class="n">of</span> <span class="n">concurrent</span> <span class="n">requests</span><span class="p">]</span>
</pre></div>
</div>
<p>Our client configuration varies a fair amount between different use
cases.</p>
</div>
</div>
<div class="section" id="java-version">
<h2><a class="reference external" href="#java">6.4 Java Version</a><a class="headerlink" href="#java-version" title="Permalink to this headline">Â¶</a></h2>
<p>From a security perspective, we recommend you use the latest released
version of JDK 1.8 as older freely available versions have disclosed
security vulnerabilities. LinkedIn is currently running JDK 1.8 u5
(looking to upgrade to a newer version) with the G1 collector. If you
decide to use the G1 collector (the current default) and you are still
on JDK 1.7, make sure you are on u51 or newer. LinkedIn tried out u21 in
testing, but they had a number of problems with the GC implementation in
that version. LinkedIn&#8217;s tuning looks like this:</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">Xmx6g</span> <span class="o">-</span><span class="n">Xms6g</span> <span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="n">MetaspaceSize</span><span class="o">=</span><span class="mi">96</span><span class="n">m</span> <span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="o">+</span><span class="n">UseG1GC</span>
<span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="n">MaxGCPauseMillis</span><span class="o">=</span><span class="mi">20</span> <span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="n">InitiatingHeapOccupancyPercent</span><span class="o">=</span><span class="mi">35</span> <span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="n">G1HeapRegionSize</span><span class="o">=</span><span class="mi">16</span><span class="n">M</span>
<span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="n">MinMetaspaceFreeRatio</span><span class="o">=</span><span class="mi">50</span> <span class="o">-</span><span class="n">XX</span><span class="p">:</span><span class="n">MaxMetaspaceFreeRatio</span><span class="o">=</span><span class="mi">80</span>
</pre></div>
</div>
<p>For reference, here are the stats on one of LinkedIn&#8217;s busiest clusters
(at peak):</p>
<ul class="simple">
<li>60 brokers</li>
<li>50k partitions (replication factor 2)</li>
<li>800k messages/sec in</li>
<li>300 MB/sec inbound, 1 GB/sec+ outbound</li>
</ul>
<p>The tuning looks fairly aggressive, but all of the brokers in that
cluster have a 90% GC pause time of about 21ms, and they&#8217;re doing less
than 1 young GC per second.</p>
</div>
<div class="section" id="hardware-and-os">
<h2><a class="reference external" href="#hwandos">6.5 Hardware and OS</a><a class="headerlink" href="#hardware-and-os" title="Permalink to this headline">Â¶</a></h2>
<p>We are using dual quad-core Intel Xeon machines with 24GB of memory.</p>
<p>You need sufficient memory to buffer active readers and writers. You can
do a back-of-the-envelope estimate of memory needs by assuming you want
to be able to buffer for 30 seconds and compute your memory need as
write_throughput*30.</p>
<p>The disk throughput is important. We have 8x7200 rpm SATA drives. In
general disk throughput is the performance bottleneck, and more disks is
better. Depending on how you configure flush behavior you may or may not
benefit from more expensive disks (if you force flush often then higher
RPM SAS drives may be better).</p>
<div class="section" id="os">
<h3><a class="reference external" href="#os">OS</a><a class="headerlink" href="#os" title="Permalink to this headline">Â¶</a></h3>
<p>Kafka should run well on any unix system and has been tested on Linux
and Solaris.</p>
<p>We have seen a few issues running on Windows and Windows is not
currently a well supported platform though we would be happy to change
that.</p>
<p>It is unlikely to require much OS-level tuning, but there are two
potentially important OS-level configurations:</p>
<ul class="simple">
<li>File descriptor limits: Kafka uses file descriptors for log segments
and open connections. If a broker hosts many partitions, consider
that the broker needs at least
(number_of_partitions)*(partition_size/segment_size) to track all log
segments in addition to the number of connections the broker makes.
We recommend at least 100000 allowed file descriptors for the broker
processes as a starting point.</li>
<li>Max socket buffer size: can be increased to enable high-performance
data transfer between data centers as <a class="reference external" href="http://www.psc.edu/index.php/networking/641-tcp-tune">described
here</a>.</li>
</ul>
</div>
<div class="section" id="disks-and-filesystem">
<h3><a class="reference external" href="#diskandfs">Disks and Filesystem</a><a class="headerlink" href="#disks-and-filesystem" title="Permalink to this headline">Â¶</a></h3>
<p>We recommend using multiple drives to get good throughput and not
sharing the same drives used for Kafka data with application logs or
other OS filesystem activity to ensure good latency. You can either RAID
these drives together into a single volume or format and mount each
drive as its own directory. Since Kafka has replication the redundancy
provided by RAID can also be provided at the application level. This
choice has several tradeoffs.</p>
<p>If you configure multiple data directories partitions will be assigned
round-robin to data directories. Each partition will be entirely in one
of the data directories. If data is not well balanced among partitions
this can lead to load imbalance between disks.</p>
<p>RAID can potentially do better at balancing load between disks (although
it doesn&#8217;t always seem to) because it balances load at a lower level.
The primary downside of RAID is that it is usually a big performance hit
for write throughput and reduces the available disk space.</p>
<p>Another potential benefit of RAID is the ability to tolerate disk
failures. However our experience has been that rebuilding the RAID array
is so I/O intensive that it effectively disables the server, so this
does not provide much real availability improvement.</p>
</div>
<div class="section" id="application-vs-os-flush-management">
<h3><a class="reference external" href="#appvsosflush">Application vs. OS Flush Management</a><a class="headerlink" href="#application-vs-os-flush-management" title="Permalink to this headline">Â¶</a></h3>
<p>Kafka always immediately writes all data to the filesystem and supports
the ability to configure the flush policy that controls when data is
forced out of the OS cache and onto disk using the flush. This flush
policy can be controlled to force data to disk after a period of time or
after a certain number of messages has been written. There are several
choices in this configuration.</p>
<p>Kafka must eventually call fsync to know that data was flushed. When
recovering from a crash for any log segment not known to be fsync&#8217;d
Kafka will check the integrity of each message by checking its CRC and
also rebuild the accompanying offset index file as part of the recovery
process executed on startup.</p>
<p>Note that durability in Kafka does not require syncing data to disk, as
a failed node will always recover from its replicas.</p>
<p>We recommend using the default flush settings which disable application
fsync entirely. This means relying on the background flush done by the
OS and Kafka&#8217;s own background flush. This provides the best of all
worlds for most uses: no knobs to tune, great throughput and latency,
and full recovery guarantees. We generally feel that the guarantees
provided by replication are stronger than sync to local disk, however
the paranoid still may prefer having both and application level fsync
policies are still supported.</p>
<p>The drawback of using application level flush settings is that it is
less efficient in its disk usage pattern (it gives the OS less leeway to
re-order writes) and it can introduce latency as fsync in most Linux
filesystems blocks writes to the file whereas the background flushing
does much more granular page-level locking.</p>
<p>In general you don&#8217;t need to do any low-level tuning of the filesystem,
but in the next few sections we will go over some of this in case it is
useful.</p>
</div>
<div class="section" id="understanding-linux-os-flush-behavior">
<h3><a class="reference external" href="#linuxflush">Understanding Linux OS Flush Behavior</a><a class="headerlink" href="#understanding-linux-os-flush-behavior" title="Permalink to this headline">Â¶</a></h3>
<p>In Linux, data written to the filesystem is maintained in
<a class="reference external" href="http://en.wikipedia.org/wiki/Page_cache">pagecache</a> until it must be
written out to disk (due to an application-level fsync or the OS&#8217;s own
flush policy). The flushing of data is done by a set of background
threads called pdflush (or in post 2.6.32 kernels &#8220;flusher threads&#8221;).</p>
<p>Pdflush has a configurable policy that controls how much dirty data can
be maintained in cache and for how long before it must be written back
to disk. This policy is described
<a class="reference external" href="http://web.archive.org/web/20160518040713/http://www.westnet.com/~gsmith/content/linux-pdflush.htm">here</a>.
When Pdflush cannot keep up with the rate of data being written it will
eventually cause the writing process to block incurring latency in the
writes to slow down the accumulation of data.</p>
<p>You can see the current state of OS memory usage by doing</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">cat</span> <span class="o">/</span><span class="n">proc</span><span class="o">/</span><span class="n">meminfo</span>
</pre></div>
</div>
<p>The meaning of these values are described in the link above.</p>
<p>Using pagecache has several advantages over an in-process cache for
storing data that will be written out to disk:</p>
<ul class="simple">
<li>The I/O scheduler will batch together consecutive small writes into
bigger physical writes which improves throughput.</li>
<li>The I/O scheduler will attempt to re-sequence writes to minimize
movement of the disk head which improves throughput.</li>
<li>It automatically uses all the free memory on the machine</li>
</ul>
</div>
<div class="section" id="filesystem-selection">
<h3><a class="reference external" href="#filesystems">Filesystem Selection</a><a class="headerlink" href="#filesystem-selection" title="Permalink to this headline">Â¶</a></h3>
<p>Kafka uses regular files on disk, and as such it has no hard dependency
on a specific filesystem. The two filesystems which have the most usage,
however, are EXT4 and XFS. Historically, EXT4 has had more usage, but
recent improvements to the XFS filesystem have shown it to have better
performance characteristics for Kafka&#8217;s workload with no compromise in
stability.</p>
<p>Comparison testing was performed on a cluster with significant message
loads, using a variety of filesystem creation and mount options. The
primary metric in Kafka that was monitored was the &#8220;Request Local Time&#8221;,
indicating the amount of time append operations were taking. XFS
resulted in much better local times (160ms vs. 250ms+ for the best EXT4
configuration), as well as lower average wait times. The XFS performance
also showed less variability in disk performance.</p>
<div class="section" id="general-filesystem-notes">
<h4><a class="reference external" href="#generalfs">General Filesystem Notes</a><a class="headerlink" href="#general-filesystem-notes" title="Permalink to this headline">Â¶</a></h4>
<p>For any filesystem used for data directories, on Linux systems, the
following options are recommended to be used at mount time:</p>
<ul class="simple">
<li>noatime: This option disables updating of a file&#8217;s atime (last access
time) attribute when the file is read. This can eliminate a
significant number of filesystem writes, especially in the case of
bootstrapping consumers. Kafka does not rely on the atime attributes
at all, so it is safe to disable this.</li>
</ul>
</div>
<div class="section" id="xfs-notes">
<h4><a class="reference external" href="#xfs">XFS Notes</a><a class="headerlink" href="#xfs-notes" title="Permalink to this headline">Â¶</a></h4>
<p>The XFS filesystem has a significant amount of auto-tuning in place, so
it does not require any change in the default settings, either at
filesystem creation time or at mount. The only tuning parameters worth
considering are:</p>
<ul class="simple">
<li>largeio: This affects the preferred I/O size reported by the stat
call. While this can allow for higher performance on larger disk
writes, in practice it had minimal or no effect on performance.</li>
<li>nobarrier: For underlying devices that have battery-backed cache,
this option can provide a little more performance by disabling
periodic write flushes. However, if the underlying device is
well-behaved, it will report to the filesystem that it does not
require flushes, and this option will have no effect.</li>
</ul>
</div>
<div class="section" id="ext4-notes">
<h4><a class="reference external" href="#ext4">EXT4 Notes</a><a class="headerlink" href="#ext4-notes" title="Permalink to this headline">Â¶</a></h4>
<p>EXT4 is a serviceable choice of filesystem for the Kafka data
directories, however getting the most performance out of it will require
adjusting several mount options. In addition, these options are
generally unsafe in a failure scenario, and will result in much more
data loss and corruption. For a single broker failure, this is not much
of a concern as the disk can be wiped and the replicas rebuilt from the
cluster. In a multiple-failure scenario, such as a power outage, this
can mean underlying filesystem (and therefore data) corruption that is
not easily recoverable. The following options can be adjusted:</p>
<ul class="simple">
<li>data=writeback: Ext4 defaults to data=ordered which puts a strong
order on some writes. Kafka does not require this ordering as it does
very paranoid data recovery on all unflushed log. This setting
removes the ordering constraint and seems to significantly reduce
latency.</li>
<li>Disabling journaling: Journaling is a tradeoff: it makes reboots
faster after server crashes but it introduces a great deal of
additional locking which adds variance to write performance. Those
who don&#8217;t care about reboot time and want to reduce a major source of
write latency spikes can turn off journaling entirely.</li>
<li>commit=num_secs: This tunes the frequency with which ext4 commits to
its metadata journal. Setting this to a lower value reduces the loss
of unflushed data during a crash. Setting this to a higher value will
improve throughput.</li>
<li>nobh: This setting controls additional ordering guarantees when using
data=writeback mode. This should be safe with Kafka as we do not
depend on write ordering and improves throughput and latency.</li>
<li>delalloc: Delayed allocation means that the filesystem avoid
allocating any blocks until the physical write occurs. This allows
ext4 to allocate a large extent instead of smaller pages and helps
ensure the data is written sequentially. This feature is great for
throughput. It does seem to involve some locking in the filesystem
which adds a bit of latency variance.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="monitoring">
<h2><a class="reference external" href="#monitoring">6.6 Monitoring</a><a class="headerlink" href="#monitoring" title="Permalink to this headline">Â¶</a></h2>
<p>Kafka uses Yammer Metrics for metrics reporting in the server and Scala
clients. The Java clients use Kafka Metrics, a built-in metrics registry
that minimizes transitive dependencies pulled into client applications.
Both expose metrics via JMX and can be configured to report stats using
pluggable stats reporters to hook up to your monitoring system.</p>
<p>All Kafka rate metrics have a corresponding cumulative count metric with
suffix <code class="docutils literal"><span class="pre">-total</span></code>. For example, <code class="docutils literal"><span class="pre">records-consumed-rate</span></code> has a
corresponding metric named <code class="docutils literal"><span class="pre">records-consumed-total</span></code>.</p>
<p>The easiest way to see the available metrics is to fire up jconsole and
point it at a running kafka client or server; this will allow browsing
all metrics with JMX.</p>
<p>We do graphing and alerting on the following metrics:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Description</th>
<th class="head">Mbean name</th>
<th class="head">Normal value</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Message in rate</td>
<td>kafka.server:type=Bro
kerTopicMetrics,name=
MessagesInPerSec</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>Byte in rate</td>
<td>kafka.server:type=Bro
kerTopicMetrics,name=
BytesInPerSec</td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td>Request rate</td>
<td>kafka.network:type=Re
questMetrics,name=Req
uestsPerSec,request={
Produce|FetchConsumer
<a href="#id1"><span class="problematic" id="id2">|</span></a>FetchFollower}</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>Error rate</td>
<td>kafka.network:type=Re
questMetrics,name=Err
orsPerSec,request=([-
.w]+),error=([-.w]+
)</td>
<td>Number of errors in
responses counted
per-request-type,
per-error-code. If a
response contains
multiple errors, all
are counted.
error=NONE indicates
successful responses.</td>
</tr>
<tr class="row-even"><td>Request size in bytes</td>
<td>kafka.network:type=Re
questMetrics,name=Req
uestBytes,request=([-
.w]+)</td>
<td>Size of requests for
each request type.</td>
</tr>
<tr class="row-odd"><td>Temporary memory size
in bytes</td>
<td>kafka.network:type=Re
questMetrics,name=Tem
poraryMemoryBytes,req
uest={Produce|Fetch}</td>
<td>Temporary memory used
for message format
conversions and
decompression.</td>
</tr>
<tr class="row-even"><td>Message conversion
time</td>
<td>kafka.network:type=Re
questMetrics,name=Mes
sageConversionsTimeMs
,request={Produce|Fet
ch}</td>
<td>Time in milliseconds
spent on message
format conversions.</td>
</tr>
<tr class="row-odd"><td>Message conversion
rate</td>
<td>kafka.server:type=Bro
kerTopicMetrics,name=
{Produce|Fetch}Messag
eConversionsPerSec,to
pic=([-.w]+)</td>
<td>Number of records
which required
message format
conversion.</td>
</tr>
<tr class="row-even"><td>Byte out rate</td>
<td>kafka.server:type=Bro
kerTopicMetrics,name=
BytesOutPerSec</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>Log flush rate and
time</td>
<td>kafka.log:type=LogFlu
shStats,name=LogFlush
RateAndTimeMs</td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td># of under replicated
partitions (<a href="#id5"><span class="problematic" id="id6">|ISR\| &lt;
\|all replicas|</span></a>)</td>
<td>kafka.server:type=Rep
licaManager,name=Unde
rReplicatedPartitions</td>
<td>0</td>
</tr>
<tr class="row-odd"><td># of under minIsr
partitions (<a href="#id3"><span class="problematic" id="id4">|</span></a>ISR| &lt;
min.insync.replicas)</td>
<td>kafka.server:type=Rep
licaManager,name=Unde
rMinIsrPartitionCount</td>
<td>0</td>
</tr>
<tr class="row-even"><td># of offline log
directories</td>
<td>kafka.log:type=LogMan
ager,name=OfflineLogD
irectoryCount</td>
<td>0</td>
</tr>
<tr class="row-odd"><td>Is controller active
on broker</td>
<td>kafka.controller:type
=KafkaController,name
=ActiveControllerCoun
t</td>
<td>only one broker in
the cluster should
have 1</td>
</tr>
<tr class="row-even"><td>Leader election rate</td>
<td>kafka.controller:type
=ControllerStats,name
=LeaderElectionRateAn
dTimeMs</td>
<td>non-zero when there
are broker failures</td>
</tr>
<tr class="row-odd"><td>Unclean leader
election rate</td>
<td>kafka.controller:type
=ControllerStats,name
=UncleanLeaderElectio
nsPerSec</td>
<td>0</td>
</tr>
<tr class="row-even"><td>Partition counts</td>
<td>kafka.server:type=Rep
licaManager,name=Part
itionCount</td>
<td>mostly even across
brokers</td>
</tr>
<tr class="row-odd"><td>Leader replica counts</td>
<td>kafka.server:type=Rep
licaManager,name=Lead
erCount</td>
<td>mostly even across
brokers</td>
</tr>
<tr class="row-even"><td>ISR shrink rate</td>
<td>kafka.server:type=Rep
licaManager,name=IsrS
hrinksPerSec</td>
<td>If a broker goes
down, ISR for some of
the partitions will
shrink. When that
broker is up again,
ISR will be expanded
once the replicas are
fully caught up.
Other than that, the
expected value for
both ISR shrink rate
and expansion rate is
0.</td>
</tr>
<tr class="row-odd"><td>ISR expansion rate</td>
<td>kafka.server:type=Rep
licaManager,name=IsrE
xpandsPerSec</td>
<td>See above</td>
</tr>
<tr class="row-even"><td>Max lag in messages
btw follower and
leader replicas</td>
<td>kafka.server:type=Rep
licaFetcherManager,na
me=MaxLag,clientId=Re
plica</td>
<td>lag should be
proportional to the
maximum batch size of
a produce request.</td>
</tr>
<tr class="row-odd"><td>Lag in messages per
follower replica</td>
<td>kafka.server:type=Fet
cherLagMetrics,name=C
onsumerLag,clientId=(
[-.w]+),topic=([-.w
]+),partition=([0-9]+
)</td>
<td>lag should be
proportional to the
maximum batch size of
a produce request.</td>
</tr>
<tr class="row-even"><td>Requests waiting in
the producer
purgatory</td>
<td>kafka.server:type=Del
ayedOperationPurgator
y,name=PurgatorySize,
delayedOperation=Prod
uce</td>
<td>non-zero if ack=-1 is
used</td>
</tr>
<tr class="row-odd"><td>Requests waiting in
the fetch purgatory</td>
<td>kafka.server:type=Del
ayedOperationPurgator
y,name=PurgatorySize,
delayedOperation=Fetc
h</td>
<td>size depends on
fetch.wait.max.ms in
the consumer</td>
</tr>
<tr class="row-even"><td>Request total time</td>
<td>kafka.network:type=Re
questMetrics,name=Tot
alTimeMs,request={Pro
duce|FetchConsumer|Fe
tchFollower}</td>
<td>broken into queue,
local, remote and
response send time</td>
</tr>
<tr class="row-odd"><td>Time the request
waits in the request
queue</td>
<td>kafka.network:type=Re
questMetrics,name=Req
uestQueueTimeMs,reque
st={Produce|FetchCons
umer|FetchFollower}</td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td>Time the request is
processed at the
leader</td>
<td>kafka.network:type=Re
questMetrics,name=Loc
alTimeMs,request={Pro
duce|FetchConsumer|Fe
tchFollower}</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>Time the request
waits for the
follower</td>
<td>kafka.network:type=Re
questMetrics,name=Rem
oteTimeMs,request={Pr
oduce|FetchConsumer|F
etchFollower}</td>
<td>non-zero for produce
requests when ack=-1</td>
</tr>
<tr class="row-even"><td>Time the request
waits in the response
queue</td>
<td>kafka.network:type=Re
questMetrics,name=Res
ponseQueueTimeMs,requ
est={Produce|FetchCon
sumer|FetchFollower}</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>Time to send the
response</td>
<td>kafka.network:type=Re
questMetrics,name=Res
ponseSendTimeMs,reque
st={Produce|FetchCons
umer|FetchFollower}</td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td>Number of messages
the consumer lags
behind the producer
by. Published by the
consumer, not broker.</td>
<td><p class="first"><em>Old consumer:</em>
kafka.consumer:type=C
onsumerFetcherManager
,name=MaxLag,clientId
=([-.w]+)</p>
<p class="last"><em>New consumer:</em>
kafka.consumer:type=c
onsumer-fetch-manager
-metrics,client-id={c
lient-id}
Attribute:
records-lag-max</p>
</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>The average fraction
of time the network
processors are idle</td>
<td>kafka.network:type=So
cketServer,name=Netwo
rkProcessorAvgIdlePer
cent</td>
<td>between 0 and 1,
ideally &gt; 0.3</td>
</tr>
<tr class="row-even"><td>The average fraction
of time the request
handler threads are
idle</td>
<td>kafka.server:type=Kaf
kaRequestHandlerPool,
name=RequestHandlerAv
gIdlePercent</td>
<td>between 0 and 1,
ideally &gt; 0.3</td>
</tr>
<tr class="row-odd"><td>Bandwidth quota
metrics per (user,
client-id), user or
client-id</td>
<td>kafka.server:type={Pr
oduce|Fetch},user=([-
.w]+),client-id=([-.
w]+)</td>
<td>Two attributes.
throttle-time
indicates the amount
of time in ms the
client was throttled.
Ideally = 0.
byte-rate indicates
the data
produce/consume rate
of the client in
bytes/sec. For (user,
client-id) quotas,
both user and
client-id are
specified. If
per-client-id quota
is applied to the
client, user is not
specified. If
per-user quota is
applied, client-id is
not specified.</td>
</tr>
<tr class="row-even"><td>Request quota metrics
per (user,
client-id), user or
client-id</td>
<td>kafka.server:type=Req
uest,user=([-.w]+),c
lient-id=([-.w]+)</td>
<td>Two attributes.
throttle-time
indicates the amount
of time in ms the
client was throttled.
Ideally = 0.
request-time
indicates the
percentage of time
spent in broker
network and I/O
threads to process
requests from client
group. For (user,
client-id) quotas,
both user and
client-id are
specified. If
per-client-id quota
is applied to the
client, user is not
specified. If
per-user quota is
applied, client-id is
not specified.</td>
</tr>
<tr class="row-odd"><td>Requests exempt from
throttling</td>
<td>kafka.server:type=Req
uest</td>
<td>exempt-throttle-time
indicates the
percentage of time
spent in broker
network and I/O
threads to process
requests that are
exempt from
throttling.</td>
</tr>
<tr class="row-even"><td>ZooKeeper client
request latency</td>
<td>kafka.server:type=Zoo
KeeperClientMetrics,n
ame=ZooKeeperRequestL
atencyMs</td>
<td>Latency in
millseconds for
ZooKeeper requests
from broker.</td>
</tr>
<tr class="row-odd"><td>ZooKeeper connection
status</td>
<td>kafka.server:type=Ses
sionExpireListener,na
me=SessionState</td>
<td>Connection status of
broker&#8217;s ZooKeeper
session which may be
one of
Disconnected|SyncConn
ected|AuthFailed|Conn
ectedReadOnly|SaslAut
henticated|Expired.</td>
</tr>
</tbody>
</table>
<div class="section" id="common-monitoring-metrics-for-producer-consumer-connect-streams">
<h3><a class="reference external" href="#selector_monitoring">Common monitoring metrics for producer/consumer/connect/streams</a><a class="headerlink" href="#common-monitoring-metrics-for-producer-consumer-connect-streams" title="Permalink to this headline">Â¶</a></h3>
<p>The following metrics are available on
producer/consumer/connector/streams instances. For specific metrics,
please see following sections.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>connection-close-rate</td>
<td>Connections closed
per second in the
window.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>connection-creation-r
ate</td>
<td>New connections
established per
second in the window.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>network-io-rate</td>
<td>The average number of
network operations
(reads or writes) on
all connections per
second.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>outgoing-byte-rate</td>
<td>The average number of
outgoing bytes sent
per second to all
servers.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>request-rate</td>
<td>The average number of
requests sent per
second.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>request-size-avg</td>
<td>The average size of
all requests in the
window.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>request-size-max</td>
<td>The maximum size of
any request sent in
the window.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>incoming-byte-rate</td>
<td>Bytes/second read off
all sockets.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>response-rate</td>
<td>Responses received
sent per second.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>select-rate</td>
<td>Number of times the
I/O layer checked for
new I/O to perform
per second.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>io-wait-time-ns-avg</td>
<td>The average length of
time the I/O thread
spent waiting for a
socket ready for
reads or writes in
nanoseconds.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>io-wait-ratio</td>
<td>The fraction of time
the I/O thread spent
waiting.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>io-time-ns-avg</td>
<td>The average length of
time for I/O per
select call in
nanoseconds.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>io-ratio</td>
<td>The fraction of time
the I/O thread spent
doing I/O.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>connection-count</td>
<td>The current number of
active connections.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>successful-authentica
tion-rate</td>
<td>Connections that were
successfully
authenticated using
SASL or SSL.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
<tr class="row-even"><td>failed-authentication
-rate</td>
<td>Connections that
failed
authentication.</td>
<td>kafka.[producer|consu
mer|connect]:type=[pr
oducer|consumer|conne
ct]-metrics,client-id
=([-.w]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="common-per-broker-metrics-for-producer-consumer-connect-streams">
<h3><a class="reference external" href="#common_node_monitoring">Common Per-broker metrics for producer/consumer/connect/streams</a><a class="headerlink" href="#common-per-broker-metrics-for-producer-consumer-connect-streams" title="Permalink to this headline">Â¶</a></h3>
<p>The following metrics are available on
producer/consumer/connector/streams instances. For specific metrics,
please see following sections.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>outgoing-byte-rate</td>
<td>The average number of
outgoing bytes sent
per second for a
node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-odd"><td>request-rate</td>
<td>The average number of
requests sent per
second for a node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-even"><td>request-size-avg</td>
<td>The average size of
all requests in the
window for a node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-odd"><td>request-size-max</td>
<td>The maximum size of
any request sent in
the window for a
node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-even"><td>incoming-byte-rate</td>
<td>The average number of
responses received
per second for a
node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-odd"><td>request-latency-avg</td>
<td>The average request
latency in ms for a
node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-even"><td>request-latency-max</td>
<td>The maximum request
latency in ms for a
node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
<tr class="row-odd"><td>response-rate</td>
<td>Responses received
sent per second for a
node.</td>
<td>kafka.producer:type=[
consumer|producer|con
nect]-node-metrics,cl
ient-id=([-.w]+),nod
e-id=([0-9]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="producer-monitoring">
<h3><a class="reference external" href="#producer_monitoring">Producer monitoring</a><a class="headerlink" href="#producer-monitoring" title="Permalink to this headline">Â¶</a></h3>
<p>The following metrics are available on producer instances.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>waiting-threads</td>
<td>The number of user
threads blocked
waiting for buffer
memory to enqueue
their records.</td>
<td>kafka.producer:type=p
roducer-metrics,clien
t-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>buffer-total-bytes</td>
<td>The maximum amount of
buffer memory the
client can use
(whether or not it is
currently used).</td>
<td>kafka.producer:type=p
roducer-metrics,clien
t-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>buffer-available-byte
s</td>
<td>The total amount of
buffer memory that is
not being used
(either unallocated
or in the free list).</td>
<td>kafka.producer:type=p
roducer-metrics,clien
t-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>bufferpool-wait-time</td>
<td>The fraction of time
an appender waits for
space allocation.</td>
<td>kafka.producer:type=p
roducer-metrics,clien
t-id=([-.w]+)</td>
</tr>
</tbody>
</table>
<div class="section" id="producer-sender-metrics">
<h4><a class="reference external" href="#producer_sender_monitoring">Producer Sender Metrics</a><a class="headerlink" href="#producer-sender-metrics" title="Permalink to this headline">Â¶</a></h4>
</div>
</div>
<div class="section" id="new-consumer-monitoring">
<h3><a class="reference external" href="#new_consumer_monitoring">New consumer monitoring</a><a class="headerlink" href="#new-consumer-monitoring" title="Permalink to this headline">Â¶</a></h3>
<p>The following metrics are available on new consumer instances.</p>
<div class="section" id="consumer-group-metrics">
<h4><a class="reference external" href="#new_consumer_group_monitoring">Consumer Group Metrics</a><a class="headerlink" href="#consumer-group-metrics" title="Permalink to this headline">Â¶</a></h4>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>commit-latency-avg</td>
<td>The average time
taken for a commit
request</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>commit-latency-max</td>
<td>The max time taken
for a commit request</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>commit-rate</td>
<td>The number of commit
calls per second</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>assigned-partitions</td>
<td>The number of
partitions currently
assigned to this
consumer</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>heartbeat-response-ti
me-max</td>
<td>The max time taken to
receive a response to
a heartbeat request</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>heartbeat-rate</td>
<td>The average number of
heartbeats per second</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>join-time-avg</td>
<td>The average time
taken for a group
rejoin</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>join-time-max</td>
<td>The max time taken
for a group rejoin</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>join-rate</td>
<td>The number of group
joins per second</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>sync-time-avg</td>
<td>The average time
taken for a group
sync</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>sync-time-max</td>
<td>The max time taken
for a group sync</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>sync-rate</td>
<td>The number of group
syncs per second</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>last-heartbeat-second
s-ago</td>
<td>The number of seconds
since the last
controller heartbeat</td>
<td>kafka.consumer:type=c
onsumer-coordinator-m
etrics,client-id=([-.
w]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="consumer-fetch-metrics">
<h4><a class="reference external" href="#new_consumer_fetch_monitoring">Consumer Fetch Metrics</a><a class="headerlink" href="#consumer-fetch-metrics" title="Permalink to this headline">Â¶</a></h4>
</div>
</div>
<div class="section" id="connect-monitoring">
<h3><a class="reference external" href="#connect_monitoring">Connect Monitoring</a><a class="headerlink" href="#connect-monitoring" title="Permalink to this headline">Â¶</a></h3>
<p>A Connect worker process contains all the producer and consumer metrics
as well as metrics specific to Connect. The worker process itself has a
number of metrics, while each connector and task have additional
metrics.</p>
</div>
<div class="section" id="streams-monitoring">
<h3><a class="reference external" href="#kafka_streams_monitoring">Streams Monitoring</a><a class="headerlink" href="#streams-monitoring" title="Permalink to this headline">Â¶</a></h3>
<p>A Kafka Streams instance contains all the producer and consumer metrics
as well as additional metrics specific to streams. By default Kafka
Streams has metrics with two recording levels: debug and info. The debug
level records all metrics, while the info level records only the
thread-level metrics.</p>
<p>Note that the metrics have a 3-layer hierarchy. At the top level there
are per-thread metrics. Each thread has tasks, with their own metrics.
Each task has a number of processor nodes, with their own metrics. Each
task also has a number of state stores and record caches, all with their
own metrics.</p>
<p>Use the following configuration option to specify which metrics you want
collected:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">metrics</span><span class="o">.</span><span class="n">recording</span><span class="o">.</span><span class="n">level</span><span class="o">=</span><span class="s2">&quot;info&quot;</span>
</pre></div>
</div>
<div class="section" id="thread-metrics">
<h4><a class="reference external" href="#kafka_streams_thread_monitoring">Thread Metrics</a><a class="headerlink" href="#thread-metrics" title="Permalink to this headline">Â¶</a></h4>
<p>All the following metrics have a recording level of ``info``:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>commit-latency-avg</td>
<td>The average execution
time in ms for
committing, across
all running tasks of
this thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>commit-latency-max</td>
<td>The maximum execution
time in ms for
committing across all
running tasks of this
thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>poll-latency-avg</td>
<td>The average execution
time in ms for
polling, across all
running tasks of this
thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>poll-latency-max</td>
<td>The maximum execution
time in ms for
polling across all
running tasks of this
thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>process-latency-avg</td>
<td>The average execution
time in ms for
processing, across
all running tasks of
this thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>process-latency-max</td>
<td>The maximum execution
time in ms for
processing across all
running tasks of this
thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>punctuate-latency-avg</td>
<td>The average execution
time in ms for
punctuating, across
all running tasks of
this thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>punctuate-latency-max</td>
<td>The maximum execution
time in ms for
punctuating across
all running tasks of
this thread.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>commit-rate</td>
<td>The average number of
commits per second
across all tasks.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>poll-rate</td>
<td>The average number of
polls per second
across all tasks.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>process-rate</td>
<td>The average number of
process calls per
second across all
tasks.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>punctuate-rate</td>
<td>The average number of
punctuates per second
across all tasks.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>task-created-rate</td>
<td>The average number of
newly created tasks
per second.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>task-closed-rate</td>
<td>The average number of
tasks closed per
second.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
<tr class="row-even"><td>skipped-records-rate</td>
<td>The average number of
skipped records per
second.</td>
<td>kafka.streams:type=st
ream-metrics,client-i
d=([-.w]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="task-metrics">
<h4><a class="reference external" href="#kafka_streams_task_monitoring">Task Metrics</a><a class="headerlink" href="#task-metrics" title="Permalink to this headline">Â¶</a></h4>
<p>All the following metrics have a recording level of ``debug``:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>commit-latency-avg</td>
<td>The average commit
time in ns for this
task.</td>
<td>kafka.streams:type=st
ream-task-metrics,cli
ent-id=([-.w]+),task
-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>commit-latency-max</td>
<td>The maximum commit
time in ns for this
task.</td>
<td>kafka.streams:type=st
ream-task-metrics,cli
ent-id=([-.w]+),task
-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>commit-rate</td>
<td>The average number of
commit calls per
second.</td>
<td>kafka.streams:type=st
ream-task-metrics,cli
ent-id=([-.w]+),task
-id=([-.w]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="processor-node-metrics">
<h4><a class="reference external" href="#kafka_streams_node_monitoring">Processor Node Metrics</a><a class="headerlink" href="#processor-node-metrics" title="Permalink to this headline">Â¶</a></h4>
<p>All the following metrics have a recording level of ``debug``:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>process-latency-avg</td>
<td>The average process
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-odd"><td>process-latency-max</td>
<td>The maximum process
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-even"><td>punctuate-latency-avg</td>
<td>The average punctuate
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-odd"><td>punctuate-latency-max</td>
<td>The maximum punctuate
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-even"><td>create-latency-avg</td>
<td>The average create
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-odd"><td>create-latency-max</td>
<td>The maximum create
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-even"><td>destroy-latency-avg</td>
<td>The average destroy
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-odd"><td>destroy-latency-max</td>
<td>The maximum destroy
execution time in ns.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-even"><td>process-rate</td>
<td>The average number of
process operations
per second.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-odd"><td>punctuate-rate</td>
<td>The average number of
punctuate operations
per second.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-even"><td>create-rate</td>
<td>The average number of
create operations per
second.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-odd"><td>destroy-rate</td>
<td>The average number of
destroy operations
per second.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
<tr class="row-even"><td>forward-rate</td>
<td>The average rate of
records being
forwarded downstream,
from source nodes
only, per second.</td>
<td>kafka.streams:type=st
ream-processor-node-m
etrics,client-id=([-.
w]+),task-id=([-.w]
+),processor-node-id=
([-.w]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="state-store-metrics">
<h4><a class="reference external" href="#kafka_streams_store_monitoring">State Store Metrics</a><a class="headerlink" href="#state-store-metrics" title="Permalink to this headline">Â¶</a></h4>
<p>All the following metrics have a recording level of ``debug``:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>put-latency-avg</td>
<td>The average put
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>put-latency-max</td>
<td>The maximum put
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>put-if-absent-latency
-avg</td>
<td>The average
put-if-absent
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>put-if-absent-latency
-max</td>
<td>The maximum
put-if-absent
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>get-latency-avg</td>
<td>The average get
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>get-latency-max</td>
<td>The maximum get
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>delete-latency-avg</td>
<td>The average delete
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>delete-latency-max</td>
<td>The maximum delete
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>put-all-latency-avg</td>
<td>The average put-all
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>put-all-latency-max</td>
<td>The maximum put-all
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>all-latency-avg</td>
<td>The average all
operation execution
time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>all-latency-max</td>
<td>The maximum all
operation execution
time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>range-latency-avg</td>
<td>The average range
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>range-latency-max</td>
<td>The maximum range
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>flush-latency-avg</td>
<td>The average flush
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>flush-latency-max</td>
<td>The maximum flush
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>restore-latency-avg</td>
<td>The average restore
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>restore-latency-max</td>
<td>The maximum restore
execution time in ns.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>put-rate</td>
<td>The average put rate
for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>put-if-absent-rate</td>
<td>The average
put-if-absent rate
for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>get-rate</td>
<td>The average get rate
for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>delete-rate</td>
<td>The average delete
rate for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>put-all-rate</td>
<td>The average put-all
rate for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>all-rate</td>
<td>The average all
operation rate for
this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>range-rate</td>
<td>The average range
rate for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-odd"><td>flush-rate</td>
<td>The average flush
rate for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
<tr class="row-even"><td>restore-rate</td>
<td>The average restore
rate for this store.</td>
<td>kafka.streams:type=st
ream-[store-type]-sta
te-metrics,client-id=
([-.w]+),task-id=([-
.w]+),[store-type]-s
tate-id=([-.w]+)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="record-cache-metrics">
<h4><a class="reference external" href="#kafka_streams_cache_monitoring">Record Cache Metrics</a><a class="headerlink" href="#record-cache-metrics" title="Permalink to this headline">Â¶</a></h4>
<p>All the following metrics have a recording level of ``debug``:</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Metric/Attribute name</th>
<th class="head">Description</th>
<th class="head">Mbean name</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>hitRatio-avg</td>
<td>The average cache hit
ratio defined as the
ratio of cache read
hits over the total
cache read requests.</td>
<td>kafka.streams:type=st
ream-record-cache-met
rics,client-id=([-.w
]+),task-id=([-.w]+)
,record-cache-id=([-.
w]+)</td>
</tr>
<tr class="row-odd"><td>hitRatio-min</td>
<td>The mininum cache hit
ratio.</td>
<td>kafka.streams:type=st
ream-record-cache-met
rics,client-id=([-.w
]+),task-id=([-.w]+)
,record-cache-id=([-.
w]+)</td>
</tr>
<tr class="row-even"><td>hitRatio-max</td>
<td>The maximum cache hit
ratio.</td>
<td>kafka.streams:type=st
ream-record-cache-met
rics,client-id=([-.w
]+),task-id=([-.w]+)
,record-cache-id=([-.
w]+)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="others">
<h3><a class="reference external" href="#others_monitoring">Others</a><a class="headerlink" href="#others" title="Permalink to this headline">Â¶</a></h3>
<p>We recommend monitoring GC time and other stats and various server stats
such as CPU utilization, I/O service time, etc. On the client side, we
recommend monitoring the message/byte rate (global and per topic),
request rate/size/time, and on the consumer side, max lag in messages
among all partitions and min fetch request rate. For a consumer to keep
up, max lag needs to be less than a threshold and min fetch rate needs
to be larger than 0.</p>
</div>
<div class="section" id="audit">
<h3><a class="reference external" href="#basic_ops_audit">Audit</a><a class="headerlink" href="#audit" title="Permalink to this headline">Â¶</a></h3>
<p>The final alerting we do is on the correctness of the data delivery. We
audit that every message that is sent is consumed by all consumers and
measure the lag for this to occur. For important topics we alert if a
certain completeness is not achieved in a certain time period. The
details of this are discussed in KAFKA-260.</p>
</div>
</div>
<div class="section" id="zookeeper">
<h2><a class="reference external" href="#zk">6.7 ZooKeeper</a><a class="headerlink" href="#zookeeper" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="stable-version">
<h3><a class="reference external" href="#zkversion">Stable version</a><a class="headerlink" href="#stable-version" title="Permalink to this headline">Â¶</a></h3>
<p>The current stable branch is 3.4 and the latest release of that branch
is 3.4.9.</p>
</div>
<div class="section" id="operationalizing-zookeeper">
<h3><a class="reference external" href="#zkops">Operationalizing ZooKeeper</a><a class="headerlink" href="#operationalizing-zookeeper" title="Permalink to this headline">Â¶</a></h3>
<p>Operationally, we do the following for a healthy ZooKeeper installation:</p>
<ul class="simple">
<li>Redundancy in the physical/hardware/network layout: try not to put
them all in the same rack, decent (but don&#8217;t go nuts) hardware, try
to keep redundant power and network paths, etc. A typical ZooKeeper
ensemble has 5 or 7 servers, which tolerates 2 and 3 servers down,
respectively. If you have a small deployment, then using 3 servers is
acceptable, but keep in mind that you&#8217;ll only be able to tolerate 1
server down in this case.</li>
<li>I/O segregation: if you do a lot of write type traffic you&#8217;ll almost
definitely want the transaction logs on a dedicated disk group.
Writes to the transaction log are synchronous (but batched for
performance), and consequently, concurrent writes can significantly
affect performance. ZooKeeper snapshots can be one such a source of
concurrent writes, and ideally should be written on a disk group
separate from the transaction log. Snapshots are written to disk
asynchronously, so it is typically ok to share with the operating
system and message log files. You can configure a server to use a
separate disk group with the dataLogDir parameter.</li>
<li>Application segregation: Unless you really understand the application
patterns of other apps that you want to install on the same box, it
can be a good idea to run ZooKeeper in isolation (though this can be
a balancing act with the capabilities of the hardware).</li>
<li>Use care with virtualization: It can work, depending on your cluster
layout and read/write patterns and SLAs, but the tiny overheads
introduced by the virtualization layer can add up and throw off
ZooKeeper, as it can be very time sensitive</li>
<li>ZooKeeper configuration: It&#8217;s java, make sure you give it &#8216;enough&#8217;
heap space (We usually run them with 3-5G, but that&#8217;s mostly due to
the data set size we have here). Unfortunately we don&#8217;t have a good
formula for it, but keep in mind that allowing for more ZooKeeper
state means that snapshots can become large, and large snapshots
affect recovery time. In fact, if the snapshot becomes too large (a
few gigabytes), then you may need to increase the initLimit parameter
to give enough time for servers to recover and join the ensemble.</li>
<li>Monitoring: Both JMX and the 4 letter words (4lw) commands are very
useful, they do overlap in some cases (and in those cases we prefer
the 4 letter commands, they seem more predictable, or at the very
least, they work better with the LI monitoring infrastructure)</li>
<li>Don&#8217;t overbuild the cluster: large clusters, especially in a write
heavy usage pattern, means a lot of intracluster communication
(quorums on the writes and subsequent cluster member updates), but
don&#8217;t underbuild it (and risk swamping the cluster). Having more
servers adds to your read capacity.</li>
</ul>
<p>Overall, we try to keep the ZooKeeper system as small as will handle the
load (plus standard growth capacity planning) and as simple as possible.
We try not to do anything fancy with the configuration or application
layout as compared to the official release as well as keep it as self
contained as possible. For these reasons, we tend to skip the OS
packaged versions, since it has a tendency to try to put things in the
OS standard hierarchy, which can be &#8216;messy&#8217;, for want of a better way to
word it.</p>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="implementation.html" class="btn btn-neutral" title="Implementation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Apache Software Foundation.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'4.0.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: ''
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>