

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Processor API &mdash; Apache Kafka 4.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="Apache Kafka 4.0.0 documentation" href="../../../index.html"/>
        <link rel="up" title="Developer Guide for Kafka Streams" href="index.html"/>
        <link rel="next" title="Data Types and Serialization" href="datatypes.html"/>
        <link rel="prev" title="Streams DSL" href="dsl-api.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> Apache Kafka
          

          
          </a>

          
            
            
              <div class="version">
                4.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../uses.html">Use Cases</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Apache Kafka Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api.html">Kafka APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../configuration.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../design.html">Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../implementation.html">Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ops.html">Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../security.html">Security</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../connect.html">Kafka Connect</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">Kafka Streams</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../quickstart.html">Run Kafka Streams Demo Application</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tutorial.html">Tutorial: Write a Kafka Streams Application</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts.html">Core Concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../architecture.html">Architecture</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html">Developer Guide for Kafka Streams</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="config-streams.html">Configuring a Streams Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="dsl-api.html">Streams DSL</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Processor API</a></li>
<li class="toctree-l4"><a class="reference internal" href="datatypes.html">Data Types and Serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="interactive-queries.html">Interactive Queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="manage-topics.html">Managing Streams Application Topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="app-reset-tool.html">Application Reset Tool</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../upgrade-guide.html">Upgrade Guide and API Changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#why-you-ll-love-using-kafka-streams">Why you&#8217;ll love using Kafka Streams!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#kafka-streams-use-cases">Kafka Streams use cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#hello-kafka-streams">Hello Kafka Streams</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Apache Kafka</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Apache Kafka Documentation</a> &raquo;</li>
        
          <li><a href="../index.html">Kafka Streams</a> &raquo;</li>
        
          <li><a href="index.html">Developer Guide for Kafka Streams</a> &raquo;</li>
        
      <li>Processor API</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/documentation/streams/developer-guide/processor-api.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="processor-api">
<span id="streams-developer-guide-processor-api"></span><h1><a class="reference external" href="#processor-api">Processor API</a><a class="headerlink" href="#processor-api" title="Permalink to this headline">¶</a></h1>
<p>The Processor API allows developers to define and connect custom
processors and to interact with state stores. With the Processor API,
you can define arbitrary stream processors that process one received
record at a time, and connect these processors with their associated
state stores to compose the processor topology that represents a
customized processing logic.</p>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title first">Table of Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#overview" id="id1">Overview</a></li>
<li><a class="reference internal" href="#defining-a-stream-processor" id="id2">Defining a Stream Processor</a></li>
<li><a class="reference internal" href="#state-stores" id="id3">State Stores</a></li>
<li><a class="reference internal" href="#defining-and-creating-a-state-store" id="id4">Defining and creating a State Store</a></li>
<li><a class="reference internal" href="#fault-tolerant-state-stores" id="id5">Fault-tolerant State Stores</a></li>
<li><a class="reference internal" href="#enable-or-disable-fault-tolerance-of-state-stores-store-changelogs" id="id6">Enable or Disable Fault Tolerance of State Stores (Store Changelogs)</a></li>
<li><a class="reference internal" href="#implementing-custom-state-stores" id="id7">Implementing Custom State Stores</a></li>
<li><a class="reference internal" href="#connecting-processors-and-state-stores" id="id8">Connecting Processors and State Stores</a></li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="reference external" href="#overview">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The Processor API can be used to implement both <strong>stateless</strong> as well as
<strong>stateful</strong> operations, where the latter is achieved through the use of
<a class="reference external" href="#streams-developer-guide-state-store">state stores</a>.</p>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p class="last"><strong>Combining the DSL and the Processor API:</strong> You can combine the
convenience of the DSL with the power and flexibility of the Processor
API as described in the section <a class="reference external" href="dsl-api.html#streams-developer-guide-dsl-process">Applying processors and transformers
(Processor API
integration)</a>.</p>
</div>
<p>For a complete list of available API functionality, see the <a class="reference external" href="../javadocs.html#streams-javadocs">Kafka
Streams API docs</a>.</p>
</div>
<div class="section" id="defining-a-stream-processor">
<h2><a class="reference external" href="#defining-a-stream-processor">Defining a Stream Processor</a><a class="headerlink" href="#defining-a-stream-processor" title="Permalink to this headline">¶</a></h2>
<p>A <a class="reference external" href="../concepts.html#streams-concepts">stream processor</a> is a node in
the processor topology that represents a single processing step. With
the Processor API, you can define arbitrary stream processors that
processes one received record at a time, and connect these processors
with their associated state stores to compose the processor topology.</p>
<p>You can define a customized stream processor by implementing the
<code class="docutils literal"><span class="pre">Processor</span></code> interface, which provides the <code class="docutils literal"><span class="pre">process()</span></code> API method.
The <code class="docutils literal"><span class="pre">process()</span></code> method is called on each of the received records.</p>
<p>The <code class="docutils literal"><span class="pre">Processor</span></code> interface also has an <code class="docutils literal"><span class="pre">init()</span></code> method, which is
called by the Kafka Streams library during task construction phase.
Processor instances should perform any required initialization in this
method. The <code class="docutils literal"><span class="pre">init()</span></code> method passes in a <code class="docutils literal"><span class="pre">ProcessorContext</span></code> instance,
which provides access to the metadata of the currently processed record,
including its source Kafka topic and partition, its corresponding
message offset, and further such information. You can also use this
context instance to schedule a punctuation function (via
<code class="docutils literal"><span class="pre">ProcessorContext#schedule()</span></code>), to forward a new record as a key-value
pair to the downstream processors (via <code class="docutils literal"><span class="pre">ProcessorContext#forward()</span></code>),
and to commit the current processing progress (via
<code class="docutils literal"><span class="pre">ProcessorContext#commit()</span></code>).</p>
<p>Specifically, <code class="docutils literal"><span class="pre">ProcessorContext#schedule()</span></code> accepts a user
<code class="docutils literal"><span class="pre">Punctuator</span></code> callback interface, which triggers its <code class="docutils literal"><span class="pre">punctuate()</span></code>
API method periodically based on the <code class="docutils literal"><span class="pre">PunctuationType</span></code>. The
<code class="docutils literal"><span class="pre">PunctuationType</span></code> determines what notion of time is used for the
punctuation scheduling: either
<a class="reference external" href="../concepts.html#streams-concepts-time">stream-time</a> or
wall-clock-time (by default, stream-time is configured to represent
event-time via <code class="docutils literal"><span class="pre">TimestampExtractor</span></code>). When stream-time is used,
<code class="docutils literal"><span class="pre">punctuate()</span></code> is triggered purely by data because stream-time is
determined (and advanced forward) by the timestamps derived from the
input data. When there is no new input data arriving, stream-time is not
advanced and thus <code class="docutils literal"><span class="pre">punctuate()</span></code> is not called.</p>
<p>For example, if you schedule a <code class="docutils literal"><span class="pre">Punctuator</span></code> function every 10 seconds
based on <code class="docutils literal"><span class="pre">PunctuationType.STREAM_TIME</span></code> and if you process a stream of
60 records with consecutive timestamps from 1 (first record) to 60
seconds (last record), then <code class="docutils literal"><span class="pre">punctuate()</span></code> would be called 6 times.
This happens regardless of the time required to actually process those
records. <code class="docutils literal"><span class="pre">punctuate()</span></code> would be called 6 times regardless of whether
processing these 60 records takes a second, a minute, or an hour.</p>
<p>When wall-clock-time (i.e. <code class="docutils literal"><span class="pre">PunctuationType.WALL_CLOCK_TIME</span></code>) is used,
<code class="docutils literal"><span class="pre">punctuate()</span></code> is triggered purely by the wall-clock time. Reusing the
example above, if the <code class="docutils literal"><span class="pre">Punctuator</span></code> function is scheduled based on
<code class="docutils literal"><span class="pre">PunctuationType.WALL_CLOCK_TIME</span></code>, and if these 60 records were
processed within 20 seconds, <code class="docutils literal"><span class="pre">punctuate()</span></code> is called 2 times (one time
every 10 seconds). If these 60 records were processed within 5 seconds,
then no <code class="docutils literal"><span class="pre">punctuate()</span></code> is called at all. Note that you can schedule
multiple <code class="docutils literal"><span class="pre">Punctuator</span></code> callbacks with different <code class="docutils literal"><span class="pre">PunctuationType</span></code>
types within the same processor by calling
<code class="docutils literal"><span class="pre">ProcessorContext#schedule()</span></code> multiple times inside <code class="docutils literal"><span class="pre">init()</span></code> method.</p>
<div class="admonition attention">
<p class="first admonition-title">Attention</p>
<p class="last">Stream-time is only advanced if all input partitions over all input
topics have new data (with newer timestamps) available. If at least one
partition does not have any new data available, stream-time will not be
advanced and thus <code class="docutils literal"><span class="pre">punctuate()</span></code> will not be triggered if
<code class="docutils literal"><span class="pre">PunctuationType.STREAM_TIME</span></code> was specified. This behavior is
independent of the configured timestamp extractor, i.e., using
<code class="docutils literal"><span class="pre">WallclockTimestampExtractor</span></code> does not enable wall-clock triggering of
<code class="docutils literal"><span class="pre">punctuate()</span></code>.</p>
</div>
<p>The following example <code class="docutils literal"><span class="pre">Processor</span></code> defines a simple word-count
algorithm and the following actions are performed:</p>
<ul class="simple">
<li>In the <code class="docutils literal"><span class="pre">init()</span></code> method, schedule the punctuation every 1000 time
units (the time unit is normally milliseconds, which in this example
would translate to punctuation every 1 second) and retrieve the local
state store by its name “Counts”.</li>
<li>In the <code class="docutils literal"><span class="pre">process()</span></code> method, upon each received record, split the
value string into words, and update their counts into the state store
(we will talk about this later in this section).</li>
<li>In the <code class="docutils literal"><span class="pre">punctuate()</span></code> method, iterate the local state store and send
the aggregated counts to the downstream processor (we will talk about
downstream processors later in this section), and commit the current
stream state.</li>
</ul>
<div class="code java highlight-default"><div class="highlight"><pre><span></span><span class="n">public</span> <span class="k">class</span> <span class="nc">WordCountProcessor</span> <span class="n">implements</span> <span class="n">Processor</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="p">{</span>

  <span class="n">private</span> <span class="n">ProcessorContext</span> <span class="n">context</span><span class="p">;</span>
  <span class="n">private</span> <span class="n">KeyValueStore</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="n">kvStore</span><span class="p">;</span>

  <span class="nd">@Override</span>
  <span class="nd">@SuppressWarnings</span><span class="p">(</span><span class="s2">&quot;unchecked&quot;</span><span class="p">)</span>
  <span class="n">public</span> <span class="n">void</span> <span class="n">init</span><span class="p">(</span><span class="n">ProcessorContext</span> <span class="n">context</span><span class="p">)</span> <span class="p">{</span>
      <span class="o">//</span> <span class="n">keep</span> <span class="n">the</span> <span class="n">processor</span> <span class="n">context</span> <span class="n">locally</span> <span class="n">because</span> <span class="n">we</span> <span class="n">need</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">punctuate</span><span class="p">()</span> <span class="ow">and</span> <span class="n">commit</span><span class="p">()</span>
      <span class="n">this</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="p">;</span>

      <span class="o">//</span> <span class="n">retrieve</span> <span class="n">the</span> <span class="n">key</span><span class="o">-</span><span class="n">value</span> <span class="n">store</span> <span class="n">named</span> <span class="s2">&quot;Counts&quot;</span>
      <span class="n">kvStore</span> <span class="o">=</span> <span class="p">(</span><span class="n">KeyValueStore</span><span class="p">)</span> <span class="n">context</span><span class="o">.</span><span class="n">getStateStore</span><span class="p">(</span><span class="s2">&quot;Counts&quot;</span><span class="p">);</span>

      <span class="o">//</span> <span class="n">schedule</span> <span class="n">a</span> <span class="n">punctuate</span><span class="p">()</span> <span class="n">method</span> <span class="n">every</span> <span class="mi">1000</span> <span class="n">milliseconds</span> <span class="n">based</span> <span class="n">on</span> <span class="n">stream</span><span class="o">-</span><span class="n">time</span>
      <span class="n">this</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">PunctuationType</span><span class="o">.</span><span class="n">STREAM_TIME</span><span class="p">,</span> <span class="p">(</span><span class="n">timestamp</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">{</span>
          <span class="n">KeyValueIterator</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="nb">iter</span> <span class="o">=</span> <span class="n">this</span><span class="o">.</span><span class="n">kvStore</span><span class="o">.</span><span class="n">all</span><span class="p">();</span>
          <span class="k">while</span> <span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">hasNext</span><span class="p">())</span> <span class="p">{</span>
              <span class="n">KeyValue</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">Long</span><span class="o">&gt;</span> <span class="n">entry</span> <span class="o">=</span> <span class="nb">iter</span><span class="o">.</span><span class="n">next</span><span class="p">();</span>
              <span class="n">context</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">key</span><span class="p">,</span> <span class="n">entry</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">toString</span><span class="p">());</span>
          <span class="p">}</span>
          <span class="nb">iter</span><span class="o">.</span><span class="n">close</span><span class="p">();</span>

          <span class="o">//</span> <span class="n">commit</span> <span class="n">the</span> <span class="n">current</span> <span class="n">processing</span> <span class="n">progress</span>
          <span class="n">context</span><span class="o">.</span><span class="n">commit</span><span class="p">();</span>
      <span class="p">});</span>
  <span class="p">}</span>

  <span class="nd">@Override</span>
  <span class="n">public</span> <span class="n">void</span> <span class="n">punctuate</span><span class="p">(</span><span class="n">long</span> <span class="n">timestamp</span><span class="p">)</span> <span class="p">{</span>
      <span class="o">//</span> <span class="n">this</span> <span class="n">method</span> <span class="ow">is</span> <span class="n">deprecated</span> <span class="ow">and</span> <span class="n">should</span> <span class="ow">not</span> <span class="n">be</span> <span class="n">used</span> <span class="n">anymore</span>
  <span class="p">}</span>

  <span class="nd">@Override</span>
  <span class="n">public</span> <span class="n">void</span> <span class="n">close</span><span class="p">()</span> <span class="p">{</span>
      <span class="o">//</span> <span class="n">close</span> <span class="n">the</span> <span class="n">key</span><span class="o">-</span><span class="n">value</span> <span class="n">store</span>
      <span class="n">kvStore</span><span class="o">.</span><span class="n">close</span><span class="p">();</span>
  <span class="p">}</span>

<span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><strong>Stateful processing with state stores:</strong> The <code class="docutils literal"><span class="pre">WordCountProcessor</span></code>
defined above can access the currently received record in its
<code class="docutils literal"><span class="pre">process()</span></code> method, and it can leverage <a class="reference external" href="#streams-developer-guide-state-store">state
stores</a> to maintain processing
states to, for example, remember recently arrived records for stateful
processing needs like aggregations and joins. For more information, see
the <a class="reference external" href="#streams-developer-guide-state-store">state stores</a>
documentation.</p>
</div>
</div>
<div class="section" id="state-stores">
<h2><a class="reference external" href="#state-stores">State Stores</a><a class="headerlink" href="#state-stores" title="Permalink to this headline">¶</a></h2>
<p>To implement a <strong>stateful</strong> <code class="docutils literal"><span class="pre">Processor</span></code> or <code class="docutils literal"><span class="pre">Transformer</span></code>, you must
provide one or more state stores to the processor or transformer
(<em>stateless</em> processors or transformers do not need state stores). State
stores can be used to remember recently received input records, to track
rolling aggregates, to de-duplicate input records, and more. Another
feature of state stores is that they can be <a class="reference external" href="interactive-queries.html#streams-developer-guide-interactive-queries">interactively
queried</a>
from other applications, such as a NodeJS-based dashboard or a
microservice implemented in Scala or Go.</p>
<p>The <a class="reference external" href="#streams-developer-guide-state-store-defining">available state store
types</a> in Kafka
Streams have <a class="reference external" href="#streams-developer-guide-state-store-fault-tolerance">fault
tolerance</a>
enabled by default.</p>
</div>
<div class="section" id="defining-and-creating-a-state-store">
<h2><a class="reference external" href="#defining-and-creating-a-state-store">Defining and creating a State Store</a><a class="headerlink" href="#defining-and-creating-a-state-store" title="Permalink to this headline">¶</a></h2>
<p>You can either use one of the available store types or <a class="reference external" href="#streams-developer-guide-state-store-custom">implement your
own custom store type</a>.
It’s common practice to leverage an existing store type via the
<code class="docutils literal"><span class="pre">Stores</span></code> factory.</p>
<p>Note that, when using Kafka Streams, you normally don’t create or
instantiate state stores directly in your code. Rather, you define state
stores indirectly by creating a so-called <code class="docutils literal"><span class="pre">StoreBuilder</span></code>. This
buildeer is used by Kafka Streams as a factory to instantiate the actual
state stores locally in application instances when and where needed.</p>
<p>The following store types are available out of the box.</p>
<table border="1" class="docutils">
<colgroup>
<col width="19%" />
<col width="11%" />
<col width="18%" />
<col width="51%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Store Type</th>
<th class="head">Storage Engine</th>
<th class="head">Fault-tolerant?</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Persistent
<code class="docutils literal"><span class="pre">KeyValueStore&lt;K,</span> <span class="pre">V&gt;</span></code></td>
<td>RocksDB</td>
<td>Yes (enabled by default)</td>
<td><ul class="first simple">
<li><strong>The recommended store type for most use cases.</strong></li>
<li>Stores its data on local disk.</li>
<li>Storage capacity:
managed local state can be larger than the memory (heap space) of an
application instance, but must fit into the available local disk
space.</li>
<li>RocksDB settings can be fine-tuned, see
<a class="reference internal" href="config-streams.html#streams-developer-guide-rocksdb-config"><span class="std std-ref">RocksDB configuration</span></a>.</li>
<li>Available <a class="reference external" href="../javadocs/org/apache/kafka/streams/state/Stores.PersistentKeyValueFactory.html">store variants</a>:
time window key-value store, session window key-value store.</li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="c1">// Creating a persistent key-value store:</span>
<span class="c1">// here, we create a `KeyValueStore&lt;String, Long&gt;` named &quot;persistent-counts&quot;.</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.streams.processor.StateStoreSupplier</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.streams.state.Stores</span><span class="o">;</span>

<span class="c1">// Note: The `Stores` factory returns a supplier for the state store,</span>
<span class="c1">// because that&#39;s what you typically need to pass as API parameter.</span>
<span class="n">StateStoreSupplier</span> <span class="n">countStoreSupplier</span> <span class="o">=</span>
  <span class="n">Stores</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="s">&quot;persistent-counts&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withKeys</span><span class="o">(</span><span class="n">Serdes</span><span class="o">.</span><span class="na">String</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withValues</span><span class="o">(</span><span class="n">Serdes</span><span class="o">.</span><span class="na">Long</span><span class="o">())</span>
    <span class="o">.</span><span class="na">persistent</span><span class="o">()</span>
    <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</pre></div>
</div>
<p class="last">See
<a class="reference external" href="../javadocs/org/apache/kafka/streams/state/Stores.PersistentKeyValueFactory.html">PersistentKeyValueFactory</a> for
detailed factory options.</p>
</td>
</tr>
<tr class="row-odd"><td>In-memory
<code class="docutils literal"><span class="pre">KeyValueStore&lt;K,</span> <span class="pre">V&gt;</span></code></td>
<td>-</td>
<td>Yes (enabled by default)</td>
<td><ul class="first simple">
<li>Stores its data in memory.</li>
<li>Storage capacity:
managed local state must fit into memory (heap space) of an
application instance.</li>
<li>Useful when application instances run in an environment where local
disk space is either not available or local disk space is wiped
in-between app instance restarts.</li>
</ul>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="c1">// Creating an in-memory key-value store:</span>
<span class="c1">// here, we create a `KeyValueStore&lt;String, Long&gt;` named &quot;inmemory-counts&quot;.</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.streams.processor.StateStoreSupplier</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.streams.state.Stores</span><span class="o">;</span>

<span class="c1">// Note: The `Stores` factory returns a supplier for the state store,</span>
<span class="c1">// because that&#39;s what you typically need to pass as API parameter.</span>
<span class="n">StateStoreSupplier</span> <span class="n">countStoreSupplier</span> <span class="o">=</span>
  <span class="n">Stores</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="s">&quot;inmemory-counts&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withKeys</span><span class="o">(</span><span class="n">Serdes</span><span class="o">.</span><span class="na">String</span><span class="o">())</span>
    <span class="o">.</span><span class="na">withValues</span><span class="o">(</span><span class="n">Serdes</span><span class="o">.</span><span class="na">Long</span><span class="o">())</span>
    <span class="o">.</span><span class="na">inMemory</span><span class="o">()</span>
    <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</pre></div>
</div>
<p class="last">See
<a class="reference external" href="../javadocs/org/apache/kafka/streams/state/Stores.InMemoryKeyValueFactory.html">InMemoryKeyValueFactory</a> for
detailed factory options.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="fault-tolerant-state-stores">
<h2><a class="reference external" href="#fault-tolerant-state-stores">Fault-tolerant State Stores</a><a class="headerlink" href="#fault-tolerant-state-stores" title="Permalink to this headline">¶</a></h2>
<p>To make state stores fault-tolerant and to allow for state store
migration without data loss, a state store can be continuously backed up
to a Kafka topic behind the scenes. For example, to migrate a stateful
stream task from one machine to another when <a class="reference external" href="running-app.html#streams-developer-guide-execution-scaling">elastically adding or
removing capacity from your
application</a>.
This topic is sometimes referred to as the state store’s associated
<em>changelog topic</em>, or its <em>changelog</em>. For example, if you experience
machine failure, the state store and the application’s state can be
fully restored from its changelog. You can <a class="reference external" href="#streams-developer-guide-state-store-enable-disable-fault-tolerance">enable or disable this
backup
feature</a>
for a state store.</p>
<p>By default, persistent key-value stores are fault-tolerant. They are
backed by a
<a class="reference external" href="https://kafka.apache.org/documentation.html#compaction">compacted</a>
changelog topic. The purpose of compacting this topic is to prevent the
topic from growing indefinitely, to reduce the storage consumed in the
associated Kafka cluster, and to minimize recovery time if a state store
needs to be restored from its changelog topic.</p>
<p>Similarly, persistent window stores are fault-tolerant. They are backed
by a topic that uses both compaction and deletion. Because of the
structure of the message keys that are being sent to the changelog
topics, this combination of deletion and compaction is required for the
changelog topics of window stores. For window stores, the message keys
are composite keys that include the “normal” key and window timestamps.
For these types of composite keys it would not be sufficient to only
enable compaction to prevent a changelog topic from growing out of
bounds. With deletion enabled, old windows that have expired will be
cleaned up by Kafka’s log cleaner as the log segments expire. The
default retention setting is <code class="docutils literal"><span class="pre">Windows#maintainMs()</span></code> + 1 day. You can
override this setting by specifying
<code class="docutils literal"><span class="pre">StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG</span></code>
in the <code class="docutils literal"><span class="pre">StreamsConfig</span></code>.</p>
<p>When you open an <code class="docutils literal"><span class="pre">Iterator</span></code> from a state store you must call
<code class="docutils literal"><span class="pre">close()</span></code> on the iterator when you are done working with it to reclaim
resources; or you can use the iterator from within a try-with-resources
statement. If you do not close an iterator, you may encounter an OOM
error.</p>
</div>
<div class="section" id="enable-or-disable-fault-tolerance-of-state-stores-store-changelogs">
<h2><a class="reference external" href="#enable-or-disable-fault-tolerance-of-state-stores-store-changelogs">Enable or Disable Fault Tolerance of State Stores (Store Changelogs)</a><a class="headerlink" href="#enable-or-disable-fault-tolerance-of-state-stores-store-changelogs" title="Permalink to this headline">¶</a></h2>
<p>You can enable or disable fault tolerance for a state store by enabling
or disabling the change logging of the store through <code class="docutils literal"><span class="pre">enableLogging()</span></code>
and <code class="docutils literal"><span class="pre">disableLogging()</span></code>. You can also fine-tune the associated topic’s
configuration if needed.</p>
<p>Example for disabling fault-tolerance:</p>
<div class="code java highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.kafka.streams.state.StoreBuilder</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.streams.state.Stores</span><span class="p">;</span>

<span class="n">StoreBuilder</span><span class="o">&lt;</span><span class="n">KeyValueStore</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">countStoreSupplier</span> <span class="o">=</span> <span class="n">Stores</span><span class="o">.</span><span class="n">keyValueStoreBuilder</span><span class="p">(</span>
  <span class="n">Stores</span><span class="o">.</span><span class="n">persistentKeyValueStore</span><span class="p">(</span><span class="s2">&quot;Counts&quot;</span><span class="p">),</span>
    <span class="n">Serdes</span><span class="o">.</span><span class="n">String</span><span class="p">(),</span>
    <span class="n">Serdes</span><span class="o">.</span><span class="n">Long</span><span class="p">())</span>
  <span class="o">.</span><span class="n">withLoggingDisabled</span><span class="p">();</span> <span class="o">//</span> <span class="n">disable</span> <span class="n">backing</span> <span class="n">up</span> <span class="n">the</span> <span class="n">store</span> <span class="n">to</span> <span class="n">a</span> <span class="n">changelog</span> <span class="n">topic</span>
</pre></div>
</div>
<div class="admonition attention">
<p class="first admonition-title">Attention</p>
<p class="last">If the changelog is disabled then the attached state store is no longer
fault tolerant and it can’t have any <a class="reference external" href="config-streams.html#streams-developer-guide-standby-replicas">standby
replicas</a>.</p>
</div>
<p>Here is an example for enabling fault tolerance, with additional
changelog-topic configuration: You can add any log config from
<a class="reference external" href="https://github.com/apache/kafka/blob/1.0/core/src/main/scala/kafka/log/LogConfig.scala#L61">kafka.log.LogConfig</a>.
Unrecognized configs will be ignored.</p>
<div class="code java highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.kafka.streams.state.StoreBuilder</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.apache.kafka.streams.state.Stores</span><span class="p">;</span>

<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">changelogConfig</span> <span class="o">=</span> <span class="n">new</span> <span class="n">HashMap</span><span class="p">();</span>
<span class="o">//</span> <span class="n">override</span> <span class="nb">min</span><span class="o">.</span><span class="n">insync</span><span class="o">.</span><span class="n">replicas</span>
<span class="n">changelogConfig</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;min.insyc.replicas&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>

<span class="n">StoreBuilder</span><span class="o">&lt;</span><span class="n">KeyValueStore</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">countStoreSupplier</span> <span class="o">=</span> <span class="n">Stores</span><span class="o">.</span><span class="n">keyValueStoreBuilder</span><span class="p">(</span>
  <span class="n">Stores</span><span class="o">.</span><span class="n">persistentKeyValueStore</span><span class="p">(</span><span class="s2">&quot;Counts&quot;</span><span class="p">),</span>
    <span class="n">Serdes</span><span class="o">.</span><span class="n">String</span><span class="p">(),</span>
    <span class="n">Serdes</span><span class="o">.</span><span class="n">Long</span><span class="p">())</span>
  <span class="o">.</span><span class="n">withLoggingEnabled</span><span class="p">(</span><span class="n">changlogConfig</span><span class="p">);</span> <span class="o">//</span> <span class="n">enable</span> <span class="n">changelogging</span><span class="p">,</span> <span class="k">with</span> <span class="n">custom</span> <span class="n">changelog</span> <span class="n">settings</span>
</pre></div>
</div>
</div>
<div class="section" id="implementing-custom-state-stores">
<h2><a class="reference external" href="#implementing-custom-state-stores">Implementing Custom State Stores</a><a class="headerlink" href="#implementing-custom-state-stores" title="Permalink to this headline">¶</a></h2>
<p>You can use the <a class="reference external" href="#streams-developer-guide-state-store-defining">built-in state store
types</a> or implement
your own. The primary interface to implement for the store is
<code class="docutils literal"><span class="pre">org.apache.kafka.streams.processor.StateStore</span></code>. Kafka Streams also
has a few extended interfaces such as <code class="docutils literal"><span class="pre">KeyValueStore</span></code>.</p>
<p>You also need to provide a “factory” for the store by implementing the
<code class="docutils literal"><span class="pre">org.apache.kafka.streams.processor.StateStoreSupplier</span></code> interface,
which Kafka Streams uses to create instances of your store.</p>
</div>
<div class="section" id="connecting-processors-and-state-stores">
<h2><a class="reference external" href="#connecting-processors-and-state-stores">Connecting Processors and State Stores</a><a class="headerlink" href="#connecting-processors-and-state-stores" title="Permalink to this headline">¶</a></h2>
<p>Now that a <a class="reference external" href="#streams-developer-guide-stream-processor">processor</a>
(WordCountProcessor) and the state stores have been defined, you can
construct the processor topology by connecting these processors and
state stores together by using the <code class="docutils literal"><span class="pre">Topology</span></code> instance. In addition,
you can add source processors with the specified Kafka topics to
generate input data streams into the topology, and sink processors with
the specified Kafka topics to generate output data streams out of the
topology.</p>
<p>Here is an example implementation:</p>
<div class="code java highlight-default"><div class="highlight"><pre><span></span><span class="n">Topology</span> <span class="n">builder</span> <span class="o">=</span> <span class="n">new</span> <span class="n">Topology</span><span class="p">();</span>

<span class="o">//</span> <span class="n">add</span> <span class="n">the</span> <span class="n">source</span> <span class="n">processor</span> <span class="n">node</span> <span class="n">that</span> <span class="n">takes</span> <span class="n">Kafka</span> <span class="n">topic</span> <span class="s2">&quot;source-topic&quot;</span> <span class="k">as</span> <span class="nb">input</span>
<span class="n">builder</span><span class="o">.</span><span class="n">addSource</span><span class="p">(</span><span class="s2">&quot;Source&quot;</span><span class="p">,</span> <span class="s2">&quot;source-topic&quot;</span><span class="p">)</span>

    <span class="o">//</span> <span class="n">add</span> <span class="n">the</span> <span class="n">WordCountProcessor</span> <span class="n">node</span> <span class="n">which</span> <span class="n">takes</span> <span class="n">the</span> <span class="n">source</span> <span class="n">processor</span> <span class="k">as</span> <span class="n">its</span> <span class="n">upstream</span> <span class="n">processor</span>
    <span class="o">.</span><span class="n">addProcessor</span><span class="p">(</span><span class="s2">&quot;Process&quot;</span><span class="p">,</span> <span class="p">()</span> <span class="o">-&gt;</span> <span class="n">new</span> <span class="n">WordCountProcessor</span><span class="p">(),</span> <span class="s2">&quot;Source&quot;</span><span class="p">)</span>

    <span class="o">//</span> <span class="n">add</span> <span class="n">the</span> <span class="n">count</span> <span class="n">store</span> <span class="n">associated</span> <span class="k">with</span> <span class="n">the</span> <span class="n">WordCountProcessor</span> <span class="n">processor</span>
    <span class="o">.</span><span class="n">addStateStore</span><span class="p">(</span><span class="n">countStoreBuilder</span><span class="p">,</span> <span class="s2">&quot;Process&quot;</span><span class="p">)</span>

    <span class="o">//</span> <span class="n">add</span> <span class="n">the</span> <span class="n">sink</span> <span class="n">processor</span> <span class="n">node</span> <span class="n">that</span> <span class="n">takes</span> <span class="n">Kafka</span> <span class="n">topic</span> <span class="s2">&quot;sink-topic&quot;</span> <span class="k">as</span> <span class="n">output</span>
    <span class="o">//</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">WordCountProcessor</span> <span class="n">node</span> <span class="k">as</span> <span class="n">its</span> <span class="n">upstream</span> <span class="n">processor</span>
    <span class="o">.</span><span class="n">addSink</span><span class="p">(</span><span class="s2">&quot;Sink&quot;</span><span class="p">,</span> <span class="s2">&quot;sink-topic&quot;</span><span class="p">,</span> <span class="s2">&quot;Process&quot;</span><span class="p">);</span>
</pre></div>
</div>
<p>Here is a quick explanation of this example:</p>
<ul class="simple">
<li>A source processor node named <code class="docutils literal"><span class="pre">&quot;Source&quot;</span></code> is added to the topology
using the <code class="docutils literal"><span class="pre">addSource</span></code> method, with one Kafka topic
<code class="docutils literal"><span class="pre">&quot;source-topic&quot;</span></code> fed to it.</li>
<li>A processor node named <code class="docutils literal"><span class="pre">&quot;Process&quot;</span></code> with the pre-defined
<code class="docutils literal"><span class="pre">WordCountProcessor</span></code> logic is then added as the downstream
processor of the <code class="docutils literal"><span class="pre">&quot;Source&quot;</span></code> node using the <code class="docutils literal"><span class="pre">addProcessor</span></code> method.</li>
<li>A predefined persistent key-value state store is created and
associated with the <code class="docutils literal"><span class="pre">&quot;Process&quot;</span></code> node, using <code class="docutils literal"><span class="pre">countStoreBuilder</span></code>.</li>
<li>A sink processor node is then added to complete the topology using
the <code class="docutils literal"><span class="pre">addSink</span></code> method, taking the <code class="docutils literal"><span class="pre">&quot;Process&quot;</span></code> node as its upstream
processor and writing to a separate <code class="docutils literal"><span class="pre">&quot;sink-topic&quot;</span></code> Kafka topic.</li>
</ul>
<p>In this topology, the <code class="docutils literal"><span class="pre">&quot;Process&quot;</span></code> stream processor node is considered
a downstream processor of the <code class="docutils literal"><span class="pre">&quot;Source&quot;</span></code> node, and an upstream
processor of the <code class="docutils literal"><span class="pre">&quot;Sink&quot;</span></code> node. As a result, whenever the <code class="docutils literal"><span class="pre">&quot;Source&quot;</span></code>
node forwards a newly fetched record from Kafka to its downstream
<code class="docutils literal"><span class="pre">&quot;Process&quot;</span></code> node, the <code class="docutils literal"><span class="pre">WordCountProcessor#process()</span></code> method is
triggered to process the record and update the associated state store.
Whenever <code class="docutils literal"><span class="pre">context#forward()</span></code> is called in the
<code class="docutils literal"><span class="pre">WordCountProcessor#punctuate()</span></code> method, the aggregate key-value pair
will be sent via the <code class="docutils literal"><span class="pre">&quot;Sink&quot;</span></code> processor node to the Kafka topic
<code class="docutils literal"><span class="pre">&quot;sink-topic&quot;</span></code>. Note that in the <code class="docutils literal"><span class="pre">WordCountProcessor</span></code>
implementation, you must refer to the same store name <code class="docutils literal"><span class="pre">&quot;Counts&quot;</span></code> when
accessing the key-value store, otherwise an exception will be thrown at
runtime, indicating that the state store cannot be found. If the state
store is not associated with the processor in the <code class="docutils literal"><span class="pre">Topology</span></code> code,
accessing it in the processor’s <code class="docutils literal"><span class="pre">init()</span></code> method will also throw an
exception at runtime, indicating the state store is not accessible from
this processor.</p>
<p>Now that you have fully defined your processor topology in your
application, you can proceed to <a class="reference external" href="running-app.html#streams-developer-guide-execution">running the Kafka Streams
application</a>.</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="datatypes.html" class="btn btn-neutral float-right" title="Data Types and Serialization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="dsl-api.html" class="btn btn-neutral" title="Streams DSL" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Apache Software Foundation.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'4.0.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: ''
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>