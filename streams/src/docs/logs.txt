/usr/lib/jvm/java-1.11.0-openjdk-amd64/bin/java -ea -Didea.test.cyclic.buffer.size=1048576 -javaagent:/opt/idea-IU-201.7223.91/lib/idea_rt.jar=41811:/opt/idea-IU-201.7223.91/bin -Dfile.encoding=UTF-8 -classpath /home/martin/.m2/repository/org/junit/platform/junit-platform-launcher/1.7.1/junit-platform-launcher-1.7.1.jar:/home/martin/.m2/repository/org/apiguardian/apiguardian-api/1.1.0/apiguardian-api-1.1.0.jar:/home/martin/.m2/repository/org/junit/platform/junit-platform-engine/1.7.1/junit-platform-engine-1.7.1.jar:/home/martin/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/martin/.m2/repository/org/junit/platform/junit-platform-commons/1.7.1/junit-platform-commons-1.7.1.jar:/home/martin/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.7.1/junit-jupiter-engine-5.7.1.jar:/home/martin/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.7.1/junit-jupiter-api-5.7.1.jar:/opt/idea-IU-201.7223.91/lib/idea_rt.jar:/opt/idea-IU-201.7223.91/plugins/junit/lib/junit5-rt.jar:/opt/idea-IU-201.7223.91/plugins/junit/lib/junit-rt.jar:/home/martin/projects/kafka/streams/build/classes/java/test:/home/martin/projects/kafka/streams/out/test/resources:/home/martin/projects/kafka/clients/build/classes/java/test:/home/martin/projects/kafka/clients/out/test/resources:/home/martin/projects/kafka/core/build/classes/java/test:/home/martin/projects/kafka/core/out/test/resources:/home/martin/projects/kafka/streams/test-utils/build/classes/java/main:/home/martin/projects/kafka/core/build/classes/java/main:/home/martin/projects/kafka/core/out/production/resources:/home/martin/projects/kafka/clients/build/classes/java/main:/home/martin/projects/kafka/clients/out/production/resources:/home/martin/.gradle/caches/modules-2/files-2.1/org.rocksdb/rocksdbjni/6.22.1.1/c9cdf28e714bc93a3e7b6c57d583d3508568a606/rocksdbjni-6.22.1.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.36/6c62681a2f655b49963a5983b8b0950a6120ae14/slf4j-api-1.7.36.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.12.6.1/df01cc0c2d4acb913d73d587274986a12e3dec8c/jackson-databind-2.12.6.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.12.6/9487231edd6b0b1f14692c9cba9e0462809215d1/jackson-annotations-2.12.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/ch.qos.reload4j/reload4j/1.2.19/4eae9978468c5e885a6fb44df7e2bbc07a20e6ce/reload4j-1.2.19.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.junit.vintage/junit-vintage-engine/5.7.1/8184800e1a38965b3fb62a104458678835311e94/junit-vintage-engine-5.7.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.junit.jupiter/junit-jupiter-api/5.7.1/a7261dff44e64aea7f621842eac5977fd6d2412d/junit-jupiter-api-5.7.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-api-easymock/2.0.9/ace3f16a82c0f1f4edbb810699b76705a1a50b6c/powermock-api-easymock-2.0.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.easymock/easymock/4.3/b0dbe2df1a71b8115835561f46a8f06cb168a94f/easymock-4.3.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-module-junit4/2.0.9/9f13da80a3d75cc9579b55389e919f661ec42f0/powermock-module-junit4-2.0.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.bouncycastle/bcpkix-jdk15on/1.66/86cca2c1a32775abe92316d9628b7ee50b6f19ad/bcpkix-jdk15on-1.66.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest/2.2/1820c0968dba3a11a1b30669bb1f01978a91dedc/hamcrest-2.2.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-inline/3.12.4/3d1dffee9a8a1998ec782383ca2f818848f2d5f1/mockito-inline-3.12.4.jar:/home/martin/projects/kafka/streams/build/classes/java/main:/home/martin/projects/kafka/streams/out/production/resources:/home/martin/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.13.6/ed7a2f528c7389ea65746c22a01031613d98ab3d/scala-library-2.13.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.12.6/5bf206c0b5982cfcd868b3d9349dc5190db8bab5/jackson-core-2.12.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.junit.platform/junit-platform-engine/1.7.1/d276a968c57f5d60a421dedd1f8b6ca2fae09e86/junit-platform-engine-1.7.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.apiguardian/apiguardian-api/1.1.0/fc9dff4bb36d627bdc553de77e1f17efd790876c/apiguardian-api-1.1.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/junit/junit/4.13.1/cdd00374f1fee76b11e2a9d127405aa3f6be5b6a/junit-4.13.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.junit.platform/junit-platform-commons/1.7.1/7c49f0074842d07f4335de2389d624a7437d1407/junit-platform-commons-1.7.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.opentest4j/opentest4j/1.2.0/28c11eb91f9b6d8e200631d46e20a7f407f2a046/opentest4j-1.2.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-api-support/2.0.9/65deba8a4207715b7d8fa6c1b8d8cac06e6ecb00/powermock-api-support-2.0.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/cglib/cglib-nodep/3.2.9/27ca91ebc2b82f844e62a7ba8c2c1fdf9b84fa80/cglib-nodep-3.2.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/3.2/7fadf57620c8b8abdf7519533e5527367cb51f09/objenesis-3.2.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-module-junit4-common/2.0.9/661b819ad3e8b5cab72bea3816ba2602d82d7f00/powermock-module-junit4-common-2.0.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.bouncycastle/bcprov-jdk15on/1.66/ed564ade61defca27e26fb1378a70b22831fc5c1/bcprov-jdk15on-1.66.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/3.12.4/f9cdc14ea4a3573c0c0366d47d5ca960be24ddb6/mockito-core-3.12.4.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-core/2.0.9/50e5d2652fd311ee9c33919dfadd44504a582210/powermock-core-2.0.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.powermock/powermock-reflect/2.0.9/4bb9ed43e5221926fb86cae44b445de110a51d05/powermock-reflect-2.0.9.jar:/home/martin/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy/1.11.13/a85d4d74de5ce7a4dd5cbbd337ced6af2740acd/byte-buddy-1.11.13.jar:/home/martin/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy-agent/1.11.13/8c7aaa0ef9863fa89a711bfc5d8e2e0affa0d67f/byte-buddy-agent-1.11.13.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.javassist/javassist/3.27.0-GA/f63e6aa899e15eca8fdaa402a79af4c417252213/javassist-3.27.0-GA.jar:/home/martin/projects/kafka/metadata/build/classes/java/main:/home/martin/projects/kafka/metadata/out/production/resources:/home/martin/projects/kafka/raft/build/classes/java/main:/home/martin/projects/kafka/raft/out/production/resources:/home/martin/projects/kafka/storage/build/classes/java/main:/home/martin/projects/kafka/storage/out/production/resources:/home/martin/projects/kafka/server-common/build/classes/java/main:/home/martin/.gradle/caches/modules-2/files-2.1/org.bitbucket.b_c/jose4j/0.7.8/34b47db4364d1916c78c3e26e419e8acbff57d80/jose4j-0.7.8.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.typesafe.scala-logging/scala-logging_2.13/3.9.3/d97c3bcdcf6179e110af8ad2a64ca276843395c1/scala-logging_2.13-3.9.3.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.dropwizard.metrics/metrics-core/4.1.12.1/cb2f351bf4463751201f43bb99865235d5ba07ca/metrics-core-4.1.12.1.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.6.3/a6e74f826db85ff8c51c15ef0fa2ea0b462aef25/zookeeper-3.6.3.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-scala_2.13/2.12.6/c4f39a4f86529789f380fb5868017c1d9f869145/jackson-module-scala_2.13-2.12.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.dataformat/jackson-dataformat-csv/2.12.6/1b941309128a942055c807bf8c69a8d4d59388a5/jackson-dataformat-csv-2.12.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jdk8/2.12.6/ccbbe6e72e3665e7ad9d0eee4613e1d8a09b81ae/jackson-datatype-jdk8-2.12.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-collection-compat_2.13/2.4.4/9cb262981ba1fac1f25c0e7e2b285d536ec8923b/scala-collection-compat_2.13-2.4.4.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.scala-lang.modules/scala-java8-compat_2.13/1.0.0/8ffac68615b438933fe27506e755d790a68b8bab/scala-java8-compat_2.13-1.0.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-reflect/2.13.6/bb523e56c63746a5752dece28fcd702c54fd3a11/scala-reflect-2.13.6.jar:/home/martin/.gradle/caches/modules-2/files-2.1/net.sourceforge.argparse4j/argparse4j/0.7.0/6f0621d0c3888de39e0f06d01f37ba53a798e657/argparse4j-0.7.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.4/4fdac2fbe92dfad86aa6e9301736f6b4342a3f5c/jopt-simple-5.0.4.jar:/home/martin/.gradle/caches/modules-2/files-2.1/commons-cli/commons-cli/1.4/c51c00206bb913cd8612b24abd9fa98ae89719b1/commons-cli-1.4.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.github.luben/zstd-jni/1.5.0-4/338d83645fb93afc9e8b38a12d9d16d41d0819b3/zstd-jni-1.5.0-4.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.8.0/4b986a99445e49ea5fbf5d149c4b63f6ed6c6780/lz4-java-1.8.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.8.4/66f0d56454509f6e36175f2331572e250e04a6cc/snappy-java-1.1.8.4.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-reload4j/1.7.36/db708f7d959dee1857ac524636e85ecf2e1781c1/slf4j-reload4j-1.7.36.jar:/home/martin/projects/kafka/storage/api/build/classes/java/main:/home/martin/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper-jute/3.6.3/8990d19ec3db01f45f82d4011a11b085db66de05/zookeeper-jute-3.6.3.jar:/home/martin/.gradle/caches/modules-2/files-2.1/org.apache.yetus/audience-annotations/0.5.0/55762d3191a8d6610ef46d11e8cb70c7667342a3/audience-annotations-0.5.0.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-handler/4.1.73.Final/1a2231c0074f88254865c3769a4b5842939ea04d/netty-handler-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-native-epoll/4.1.73.Final/763cf37f7475764113ba2764f08dbadd5356d23b/netty-transport-native-epoll-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/com.thoughtworks.paranamer/paranamer/2.8/619eba74c19ccf1da8ebec97a2d7f8ba05773dd6/paranamer-2.8.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-codec/4.1.73.Final/9496a30a349863a4c6fa10d5c36b4f3b495d3a31/netty-codec-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport/4.1.73.Final/abb155ddff196ccedfe85b810d4b9375ef85fcfa/netty-transport-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-resolver/4.1.73.Final/bfe83710f0c1739019613e81a06101020ca65def/netty-resolver-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-buffer/4.1.73.Final/244a569c9aae973f6f485ac9801d79c1eca36daa/netty-buffer-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-common/4.1.73.Final/27731b58d741b6faa6a00fa3285e7a55cc47be01/netty-common-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-tcnative-classes/2.0.46.Final/9937a832d9c19861822d345b48ced388b645aa5f/netty-tcnative-classes-2.0.46.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-classes-epoll/4.1.73.Final/2a5682520fc756efc921da78b0f00c35196b6708/netty-transport-classes-epoll-4.1.73.Final.jar:/home/martin/.gradle/caches/modules-2/files-2.1/io.netty/netty-transport-native-unix-common/4.1.73.Final/4701063d36f390e02da6da85c13e32a0e78349d2/netty-transport-native-unix-common-4.1.73.Final.jar com.intellij.rt.junit.JUnitStarter -ideVersion5 -junit5 org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest
[2022-08-19 10:40:22,103] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$:31)
[2022-08-19 10:40:22,780] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-11065391410224176982/log4982904532998605577
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:22,924] INFO starting (kafka.server.KafkaServer:66)
[2022-08-19 10:40:22,925] INFO Connecting to zookeeper on 127.0.0.1:44769 (kafka.server.KafkaServer:66)
[2022-08-19 10:40:22,943] INFO [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:44769. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:22,972] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:23,021] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:23,159] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread:66)
[2022-08-19 10:40:23,177] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener:66)
[2022-08-19 10:40:23,177] INFO Cleared cache (kafka.server.FinalizedFeatureCache:66)
[2022-08-19 10:40:23,440] INFO Cluster ID = GMuBBtlyTqiFb9pwhLlhvw (kafka.server.KafkaServer:66)
[2022-08-19 10:40:23,444] WARN No meta.properties file under dir /tmp/kafka-11065391410224176982/log4982904532998605577/meta.properties (kafka.server.BrokerMetadataCheckpoint:70)
[2022-08-19 10:40:23,507] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-11065391410224176982/log4982904532998605577
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:23,527] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-11065391410224176982/log4982904532998605577
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:23,578] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:23,579] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:23,581] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:23,584] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:23,633] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-11065391410224176982/log4982904532998605577) (kafka.log.LogManager:66)
[2022-08-19 10:40:23,640] INFO Attempting recovery for all logs in /tmp/kafka-11065391410224176982/log4982904532998605577 since no clean shutdown file was found (kafka.log.LogManager:66)
[2022-08-19 10:40:23,649] INFO Loaded 0 logs in 0ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:23,651] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:23,656] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:23,677] INFO Starting the log cleaner (kafka.log.LogCleaner:66)
[2022-08-19 10:40:23,695] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner:66)
[2022-08-19 10:40:24,153] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:24,549] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas:66)
[2022-08-19 10:40:24,556] INFO Awaiting socket connections on localhost:39849. (kafka.network.Acceptor:66)
[2022-08-19 10:40:24,618] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer:66)
[2022-08-19 10:40:24,636] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:24,682] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:24,685] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:24,688] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:24,690] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:24,723] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler:66)
[2022-08-19 10:40:24,795] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:24,838] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1660898424822,1660898424822,1,0,0,72058109826170880,204,0,25
 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:24,840] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:39849, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,013] INFO [ControllerEventThread controllerId=0] Starting (kafka.controller.ControllerEventManager$ControllerEventThread:66)
[2022-08-19 10:40:25,031] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,042] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,044] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,046] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,061] INFO [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,069] INFO [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(Enabled,Features{}) (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,073] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener:66)
[2022-08-19 10:40:25,077] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:25,087] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:25,121] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:25,128] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager:66)
[2022-08-19 10:40:25,128] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:25,145] INFO [Controller id=0] Registering handlers (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,145] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache:66)
[2022-08-19 10:40:25,152] INFO [Controller id=0] Deleting log dir event notifications (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,157] INFO [Controller id=0] Deleting isr change notifications (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,161] INFO [Controller id=0] Initializing controller context (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,183] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,187] INFO [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25) (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,221] INFO [RequestSendThread controllerId=0] Starting (kafka.controller.RequestSendThread:66)
[2022-08-19 10:40:25,221] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread:66)
[2022-08-19 10:40:25,225] INFO [Controller id=0] Currently active brokers in the cluster: Set(0) (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,226] INFO [Controller id=0] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,227] INFO [Controller id=0] Current list of topics in the cluster: HashSet() (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,228] INFO [Controller id=0] Fetching topic deletions in progress (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,235] INFO [Controller id=0] List of topics to be deleted:  (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,235] INFO [Controller id=0] List of topics ineligible for deletion:  (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,236] INFO [Controller id=0] Initializing topic deletion manager (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,238] INFO [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager:66)
[2022-08-19 10:40:25,240] INFO [Controller id=0] Sending update metadata request (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,244] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,249] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:25,255] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,256] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,261] INFO [KafkaServer id=0] started (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,264] INFO [ReplicaStateMachine controllerId=0] Initializing replica state (kafka.controller.ZkReplicaStateMachine:66)
[2022-08-19 10:40:25,266] INFO [ReplicaStateMachine controllerId=0] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine:66)
[2022-08-19 10:40:25,268] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-15053032471154295762/log4777233435427826506
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:25,274] INFO [ReplicaStateMachine controllerId=0] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine:66)
[2022-08-19 10:40:25,275] INFO starting (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,276] INFO Connecting to zookeeper on 127.0.0.1:44769 (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,276] INFO [PartitionStateMachine controllerId=0] Initializing partition state (kafka.controller.ZkPartitionStateMachine:66)
[2022-08-19 10:40:25,278] INFO [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:44769. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:25,278] INFO [PartitionStateMachine controllerId=0] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine:66)
[2022-08-19 10:40:25,279] INFO [RequestSendThread controllerId=0] Controller 0 connected to localhost:39849 (id: 0 rack: null) for sending state change requests (kafka.controller.RequestSendThread:66)
[2022-08-19 10:40:25,280] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:25,288] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:25,291] INFO [Controller id=0] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,304] INFO [Controller id=0] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,305] INFO [Controller id=0] Partitions that completed preferred replica election:  (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,306] INFO [Controller id=0] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,307] INFO [Controller id=0] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,309] INFO [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,332] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread:66)
[2022-08-19 10:40:25,333] INFO [Controller id=0] Starting the controller scheduler (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,338] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache:66)
[2022-08-19 10:40:25,344] INFO Cluster ID = GMuBBtlyTqiFb9pwhLlhvw (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,345] WARN No meta.properties file under dir /tmp/kafka-15053032471154295762/log4777233435427826506/meta.properties (kafka.server.BrokerMetadataCheckpoint:70)
[2022-08-19 10:40:25,355] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-15053032471154295762/log4777233435427826506
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:25,367] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-15053032471154295762/log4777233435427826506
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:25,376] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker localhost:39849 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,406] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,407] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,408] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,409] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,414] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-15053032471154295762/log4777233435427826506) (kafka.log.LogManager:66)
[2022-08-19 10:40:25,414] INFO Attempting recovery for all logs in /tmp/kafka-15053032471154295762/log4777233435427826506 since no clean shutdown file was found (kafka.log.LogManager:66)
[2022-08-19 10:40:25,415] INFO Loaded 0 logs in 0ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:25,416] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:25,416] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:25,419] INFO Starting the log cleaner (kafka.log.LogCleaner:66)
[2022-08-19 10:40:25,424] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner:66)
[2022-08-19 10:40:25,430] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,441] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker localhost:39849 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,480] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas:66)
[2022-08-19 10:40:25,482] INFO Awaiting socket connections on localhost:45197. (kafka.network.Acceptor:66)
[2022-08-19 10:40:25,497] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,502] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,504] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,505] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,507] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,508] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,511] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler:66)
[2022-08-19 10:40:25,526] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,530] INFO Stat of the created znode at /brokers/ids/1 is: 45,45,1660898425527,1660898425527,1,0,0,72058109826170881,204,0,45
 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,530] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://localhost:45197, czxid (broker epoch): 45 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,543] INFO [Controller id=0] Newly added brokers: 1, deleted brokers: , bounced brokers: , all live brokers: 0,1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,549] INFO [RequestSendThread controllerId=0] Starting (kafka.controller.RequestSendThread:66)
[2022-08-19 10:40:25,551] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread:66)
[2022-08-19 10:40:25,554] INFO [Controller id=0] New broker startup callback for 1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,555] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,556] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,558] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:25,560] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:25,561] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:25,564] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,565] INFO [RequestSendThread controllerId=0] Controller 0 connected to localhost:45197 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread:66)
[2022-08-19 10:40:25,565] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:25,570] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:25,572] INFO [Controller id=0] Updated broker epochs cache: HashMap(0 -> 25, 1 -> 45) (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,574] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:25,574] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager:66)
[2022-08-19 10:40:25,577] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,582] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread:66)
[2022-08-19 10:40:25,594] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,597] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,598] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,600] INFO [KafkaServer id=1] started (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,608] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-11287445166503993913/log7234199461537369559
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:25,614] INFO starting (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,615] INFO Connecting to zookeeper on 127.0.0.1:44769 (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,616] INFO [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:44769. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:25,618] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:25,621] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient:66)
[2022-08-19 10:40:25,631] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker localhost:39849 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,655] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread:66)
[2022-08-19 10:40:25,660] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache:66)
[2022-08-19 10:40:25,663] INFO Cluster ID = GMuBBtlyTqiFb9pwhLlhvw (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,664] WARN No meta.properties file under dir /tmp/kafka-11287445166503993913/log7234199461537369559/meta.properties (kafka.server.BrokerMetadataCheckpoint:70)
[2022-08-19 10:40:25,674] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-11287445166503993913/log7234199461537369559
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:25,683] INFO KafkaConfig values:
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 0
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-11287445166503993913/log7234199461537369559
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000000
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 5
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:44769
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 10000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig:376)
[2022-08-19 10:40:25,705] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker localhost:39849 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,718] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,719] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,720] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,721] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper:66)
[2022-08-19 10:40:25,726] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-11287445166503993913/log7234199461537369559) (kafka.log.LogManager:66)
[2022-08-19 10:40:25,726] INFO Attempting recovery for all logs in /tmp/kafka-11287445166503993913/log7234199461537369559 since no clean shutdown file was found (kafka.log.LogManager:66)
[2022-08-19 10:40:25,728] INFO Loaded 0 logs in 0ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:25,728] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:25,730] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager:66)
[2022-08-19 10:40:25,734] INFO Starting the log cleaner (kafka.log.LogCleaner:66)
[2022-08-19 10:40:25,740] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner:66)
[2022-08-19 10:40:25,746] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,781] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas:66)
[2022-08-19 10:40:25,781] INFO Awaiting socket connections on localhost:45019. (kafka.network.Acceptor:66)
[2022-08-19 10:40:25,792] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,797] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,798] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,799] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,800] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,803] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,806] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler:66)
[2022-08-19 10:40:25,816] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,820] INFO Stat of the created znode at /brokers/ids/2 is: 61,61,1660898425818,1660898425818,1,0,0,72058109826170882,204,0,61
 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,821] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://localhost:45019, czxid (broker epoch): 61 (kafka.zk.KafkaZkClient:66)
[2022-08-19 10:40:25,829] INFO [Controller id=0] Newly added brokers: 2, deleted brokers: , bounced brokers: , all live brokers: 0,1,2 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,833] INFO [ControllerEventThread controllerId=2] Starting (kafka.controller.ControllerEventManager$ControllerEventThread:66)
[2022-08-19 10:40:25,834] INFO [Controller id=0] New broker startup callback for 2 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,835] INFO [RequestSendThread controllerId=0] Starting (kafka.controller.RequestSendThread:66)
[2022-08-19 10:40:25,837] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1) for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:25,837] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,837] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,838] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(2) for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:25,842] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,843] INFO [Controller id=0] Updated broker epochs cache: HashMap(0 -> 25, 1 -> 45, 2 -> 61) (kafka.controller.KafkaController:66)
[2022-08-19 10:40:25,844] INFO [RequestSendThread controllerId=0] Controller 0 connected to localhost:45019 (id: 2 rack: null) for sending state change requests (kafka.controller.RequestSendThread:66)
[2022-08-19 10:40:25,845] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:25,848] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:25,852] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:25,855] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:25,856] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager:66)
[2022-08-19 10:40:25,858] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper:66)
[2022-08-19 10:40:25,862] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread:66)
[2022-08-19 10:40:25,873] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,876] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,877] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer:66)
[2022-08-19 10:40:25,881] INFO [KafkaServer id=2] started (kafka.server.KafkaServer:66)
[2022-08-19 10:40:25,898] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker localhost:39849 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:25,948] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker localhost:39849 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread:66)
[2022-08-19 10:40:26,184] INFO Creating topic input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 0, 2), 1 -> ArrayBuffer(0, 2, 1), 2 -> ArrayBuffer(2, 1, 0), 3 -> ArrayBuffer(1, 2, 0), 4 -> ArrayBuffer(0, 1, 2), 5 -> ArrayBuffer(2, 0, 1), 6 -> ArrayBuffer(1, 0, 2), 7 -> ArrayBuffer(0, 2, 1), 8 -> ArrayBuffer(2, 1, 0), 9 -> ArrayBuffer(1, 2, 0), 10 -> ArrayBuffer(0, 1, 2), 11 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:26,226] INFO [Controller id=0] New topics: [Set(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74,Some(8FPANa6LS8iOY8HNEW_L-w),HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 -> ReplicaAssignment(replicas=0,2,1, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 -> ReplicaAssignment(replicas=2,0,1, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 -> ReplicaAssignment(replicas=0,2,1, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 -> ReplicaAssignment(replicas=1,0,2, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 -> ReplicaAssignment(replicas=0,1,2, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 -> ReplicaAssignment(replicas=1,0,2, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 -> ReplicaAssignment(replicas=1,2,0, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 -> ReplicaAssignment(replicas=2,1,0, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 -> ReplicaAssignment(replicas=2,1,0, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 -> ReplicaAssignment(replicas=1,2,0, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 -> ReplicaAssignment(replicas=0,1,2, addingReplicas=, removingReplicas=), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 -> ReplicaAssignment(replicas=2,0,1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController:66)
[2022-08-19 10:40:26,228] INFO [Controller id=0] New partition creation callback for input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4,input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:26,234] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger:66)
[2022-08-19 10:40:26,235] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger:66)
[2022-08-19 10:40:26,235] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger:66)
[2022-08-19 10:40:26,235] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger:66)
[2022-08-19 10:40:26,235] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger:66)
[2022-08-19 10:40:26,235] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger:66)
[2022-08-19 10:40:26,236] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:26,246] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:26,345] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 2, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,345] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 0, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,345] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 2, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,346] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 0, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,346] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 1, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,346] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 0, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,346] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,346] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,346] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,347] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,347] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 1, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,347] INFO [Controller id=0 epoch=1] Changed partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 0, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:26,352] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 4 become-leader and 8 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:26,356] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 1 with 4 become-leader and 8 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:26,357] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 2 with 4 become-leader and 8 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:26,358] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1, 2) for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,362] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:26,370] INFO [Broker id=2] Handling LeaderAndIsr request correlationId 1 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,370] INFO [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,370] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 2 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,438] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,438] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,438] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,446] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 2 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:26,446] INFO [Broker id=2] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:26,447] INFO [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:26,592] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,592] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,592] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,630] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,631] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,630] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,635] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,635] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,635] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,639] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,639] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,639] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,644] INFO [Broker id=2] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,0,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,644] INFO [Broker id=0] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,1,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,644] INFO [Broker id=1] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,2,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,675] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,675] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,675] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,677] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,677] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,677] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,678] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,677] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,678] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,678] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,678] INFO [Broker id=1] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,0,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,678] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,679] INFO [Broker id=2] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,1,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,679] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,679] INFO [Broker id=0] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,2,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,698] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,698] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,700] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,701] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,701] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,701] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,701] INFO [Broker id=1] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,2,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,701] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,702] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,702] INFO [Broker id=2] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,0,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,705] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,706] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,707] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,707] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,707] INFO [Broker id=0] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,1,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,721] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,721] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,723] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,723] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,723] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,723] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,723] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,724] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,724] INFO [Broker id=1] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,0,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,724] INFO [Broker id=2] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,1,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,728] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,730] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,731] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,731] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,731] INFO [Broker id=0] Leader input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,2,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,753] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,753] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,753] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,754] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,754] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,755] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,755] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,755] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,755] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,755] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,755] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,756] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,757] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,757] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,757] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,763] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,763] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,763] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,765] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,765] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,765] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,765] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,765] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,765] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,765] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,766] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,765] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,766] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,766] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,766] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,772] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,772] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,772] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,774] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,774] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,774] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,774] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,774] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,775] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,774] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,774] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,775] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,775] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,775] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,776] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,781] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,781] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,782] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,783] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,783] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,784] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,784] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,784] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,784] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,784] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,784] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,785] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,785] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,785] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,785] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,791] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,791] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,792] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,792] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,792] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,792] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,793] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,793] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,793] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,793] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,794] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,793] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,794] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,794] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,794] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,799] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,799] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,799] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,801] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,801] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,801] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,801] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,802] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,802] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,801] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,802] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,802] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,803] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,803] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,803] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,809] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,809] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,810] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,811] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,811] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,811] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,811] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,811] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,812] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,812] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,812] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,812] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,813] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,813] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,813] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,818] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,819] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,819] INFO [LogLoader partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:26,820] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 in /tmp/kafka-15053032471154295762/log4777233435427826506/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,821] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 in /tmp/kafka-11065391410224176982/log4982904532998605577/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,820] INFO Created log for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 in /tmp/kafka-11287445166503993913/log7234199461537369559/input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:26,821] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=0] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,821] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=1] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,821] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=0] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,821] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=2] No checkpointed highwatermark is found for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,822] INFO [Broker id=0] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,821] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=1] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,822] INFO [Partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=2] Log loaded for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:26,822] INFO [Broker id=1] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,822] INFO [Broker id=2] Follower input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:26,823] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,823] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,823] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,825] INFO [Broker id=0] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 3 for 8 partitions (state.change.logger:66)
[2022-08-19 10:40:26,825] INFO [Broker id=2] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 1 for 8 partitions (state.change.logger:66)
[2022-08-19 10:40:26,825] INFO [Broker id=1] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 2 for 8 partitions (state.change.logger:66)
[2022-08-19 10:40:26,873] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,874] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,873] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,879] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,879] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,879] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=0, host=localhost:39849),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,884] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,884] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,884] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,889] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,890] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,890] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,890] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,891] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,890] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,893] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,894] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,894] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,892] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,892] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=2, host=localhost:45019),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,895] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions HashMap(input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0), input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 -> InitialFetchState(Some(8FPANa6LS8iOY8HNEW_L-w),BrokerEndPoint(id=1, host=localhost:45197),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:26,897] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,897] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,899] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,896] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,900] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,900] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,896] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,900] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,900] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,900] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,901] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,899] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,899] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,898] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,901] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,901] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,900] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,902] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,902] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,901] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,903] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,903] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,900] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,904] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,902] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,901] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,901] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,905] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,905] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,905] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,905] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,904] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,904] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,904] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,905] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,906] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,905] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:26,905] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,908] INFO [UnifiedLog partition=input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:26,932] INFO [Broker id=2] Finished LeaderAndIsr request in 0ms correlationId 1 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,932] INFO [Broker id=0] Finished LeaderAndIsr request in 0ms correlationId 3 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,934] INFO [Broker id=1] Finished LeaderAndIsr request in 0ms correlationId 2 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:26,959] INFO [Broker id=0] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4 (state.change.logger:66)
[2022-08-19 10:40:26,959] INFO [Broker id=1] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 3 (state.change.logger:66)
[2022-08-19 10:40:26,959] INFO [Broker id=2] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2 (state.change.logger:66)
[2022-08-19 10:40:27,022] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,022] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,022] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,023] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,023] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,023] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,023] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,023] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,025] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,026] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,026] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,026] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,022] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,028] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,028] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,028] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,022] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,022] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,032] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,032] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,032] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,032] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,032] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,032] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,052] INFO Creating topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 0, 2), 1 -> ArrayBuffer(0, 2, 1), 2 -> ArrayBuffer(2, 1, 0), 3 -> ArrayBuffer(1, 2, 0), 4 -> ArrayBuffer(0, 1, 2), 5 -> ArrayBuffer(2, 0, 1), 6 -> ArrayBuffer(1, 0, 2), 7 -> ArrayBuffer(0, 2, 1), 8 -> ArrayBuffer(2, 1, 0), 9 -> ArrayBuffer(1, 2, 0), 10 -> ArrayBuffer(0, 1, 2), 11 -> ArrayBuffer(2, 0, 1)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:27,067] INFO [Controller id=0] New topics: [Set(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74,Some(U7ug5puOQWmeL-k0mAx2Gw),HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 -> ReplicaAssignment(replicas=2,0,1, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 -> ReplicaAssignment(replicas=1,2,0, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 -> ReplicaAssignment(replicas=0,2,1, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 -> ReplicaAssignment(replicas=2,0,1, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 -> ReplicaAssignment(replicas=1,0,2, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 -> ReplicaAssignment(replicas=2,1,0, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 -> ReplicaAssignment(replicas=0,1,2, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 -> ReplicaAssignment(replicas=1,2,0, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 -> ReplicaAssignment(replicas=0,2,1, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 -> ReplicaAssignment(replicas=2,1,0, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 -> ReplicaAssignment(replicas=0,1,2, addingReplicas=, removingReplicas=), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 -> ReplicaAssignment(replicas=1,0,2, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController:66)
[2022-08-19 10:40:27,068] INFO [Controller id=0] New partition creation callback for output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10,output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:27,069] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger:66)
[2022-08-19 10:40:27,069] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger:66)
[2022-08-19 10:40:27,069] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger:66)
[2022-08-19 10:40:27,097] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger:66)
[2022-08-19 10:40:27,098] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger:66)
[2022-08-19 10:40:27,098] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger:66)
[2022-08-19 10:40:27,098] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger:66)
[2022-08-19 10:40:27,098] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger:66)
[2022-08-19 10:40:27,098] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger:66)
[2022-08-19 10:40:27,099] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 state from NonExistentPartition to NewPartition with assigned replicas 2,1,0 (state.change.logger:66)
[2022-08-19 10:40:27,099] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger:66)
[2022-08-19 10:40:27,099] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger:66)
[2022-08-19 10:40:27,099] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:27,103] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:27,142] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 0, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,142] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,143] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 2, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,143] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 0, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,143] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 0, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,143] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,143] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 1, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,143] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,144] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 2, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,144] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 1, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,144] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 1, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,144] INFO [Controller id=0 epoch=1] Changed partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 0, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:27,144] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 4 become-leader and 8 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:27,145] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 1 with 4 become-leader and 8 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:27,146] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 2 with 4 become-leader and 8 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:27,147] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1, 2) for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,147] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 4 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,151] INFO [Broker id=0] Handling LeaderAndIsr request correlationId 5 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,152] INFO [Broker id=2] Handling LeaderAndIsr request correlationId 3 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,155] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:27,167] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,167] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,167] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,167] INFO [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:27,167] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 4 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:27,168] INFO [Broker id=2] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:27,174] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,175] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,175] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,176] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,176] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,176] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,178] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,178] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,178] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,178] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,178] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,178] INFO [Broker id=1] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,2,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,178] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,179] INFO [Broker id=0] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,1,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,179] INFO [Broker id=2] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,0,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,200] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,202] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,202] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,202] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,202] INFO [Broker id=1] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,0,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,203] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,203] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,205] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,205] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,205] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,205] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,206] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,206] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,206] INFO [Broker id=2] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,1,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,206] INFO [Broker id=0] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,2,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,222] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,224] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,224] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,224] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,224] INFO [Broker id=1] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,2,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,225] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,226] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,227] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,227] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,228] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,228] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,228] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,229] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,229] INFO [Broker id=0] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,1,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,229] INFO [Broker id=2] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,0,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,245] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,248] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,248] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,249] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,249] INFO [Broker id=1] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,0,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,249] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,249] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,251] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,251] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,251] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,252] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,252] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,252] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,252] INFO [Broker id=0] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,2,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,252] INFO [Broker id=2] Leader output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,1,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,268] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,271] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,271] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,271] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,272] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,273] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,274] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,275] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,276] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,276] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,277] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,277] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,277] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,278] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,278] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,280] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,281] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,282] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,282] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,282] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,284] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,284] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,287] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,287] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,287] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,287] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,287] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,288] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,288] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,288] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,289] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,290] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,291] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,291] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,291] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,294] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,295] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,296] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,296] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,296] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,297] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,297] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,297] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,297] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,297] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,297] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,299] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,299] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,299] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,299] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,303] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,303] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,304] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,304] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,304] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,304] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,305] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,305] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,305] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,305] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,305] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,307] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,307] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,307] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,307] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,310] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,311] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,312] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,312] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,312] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,313] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,313] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,313] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,313] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,313] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,314] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,315] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,315] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,315] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,315] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,320] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,321] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,322] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,323] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,323] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,323] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,324] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,324] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,324] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,325] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,325] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,325] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,325] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,326] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,326] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,332] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,332] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,332] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,333] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,333] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,333] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,334] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 in /tmp/kafka-15053032471154295762/log4777233435427826506/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,334] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,334] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=1] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,334] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,335] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 broker=1] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,335] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,335] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,335] INFO [Broker id=1] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,335] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,337] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,337] INFO [Broker id=1] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 4 for 8 partitions (state.change.logger:66)
[2022-08-19 10:40:27,339] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,339] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,340] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,341] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,341] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,342] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,342] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,342] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,342] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,342] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,342] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,343] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,343] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,345] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,343] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,343] INFO [LogLoader partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:27,346] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,346] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,347] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,347] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 in /tmp/kafka-11065391410224176982/log4982904532998605577/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,343] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,347] INFO Created log for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 in /tmp/kafka-11287445166503993913/log7234199461537369559/output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with properties {} (kafka.log.LogManager:66)
[2022-08-19 10:40:27,347] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=0] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,347] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=2] No checkpointed highwatermark is found for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,349] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=2] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,349] INFO [Broker id=2] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,349] INFO [Partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 broker=0] Log loaded for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:27,350] INFO [Broker id=0] Follower output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:27,350] INFO [Broker id=1] Finished LeaderAndIsr request in 0ms correlationId 4 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,350] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,350] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,350] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,350] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,351] INFO [Broker id=2] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 3 for 8 partitions (state.change.logger:66)
[2022-08-19 10:40:27,350] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,353] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,353] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,350] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,353] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,367] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,367] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=0, host=localhost:39849),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,353] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,368] INFO [Broker id=1] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 5 (state.change.logger:66)
[2022-08-19 10:40:27,367] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,354] INFO [Broker id=0] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 5 for 8 partitions (state.change.logger:66)
[2022-08-19 10:40:27,370] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,370] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,369] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,371] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,369] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,372] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,372] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,371] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,370] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,373] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,373] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,373] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,372] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=1, host=localhost:45197),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,373] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,373] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,373] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,375] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,375] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,376] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,376] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,375] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,375] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,376] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,377] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,377] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,377] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,377] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,377] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,376] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,378] INFO [Broker id=2] Finished LeaderAndIsr request in 0ms correlationId 3 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,376] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions HashMap(output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0), output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 -> InitialFetchState(Some(U7ug5puOQWmeL-k0mAx2Gw),BrokerEndPoint(id=2, host=localhost:45019),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:27,378] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:27,378] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,378] INFO [UnifiedLog partition=output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:27,381] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,382] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,382] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,382] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,383] INFO [Broker id=0] Finished LeaderAndIsr request in 0ms correlationId 5 from controller 0 for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:27,385] INFO [Broker id=2] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4 (state.change.logger:66)
[2022-08-19 10:40:27,386] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,386] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,386] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,386] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread:70)
[2022-08-19 10:40:27,390] INFO [Broker id=0] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 6 (state.change.logger:66)
[2022-08-19 10:40:27,526] INFO [Controller id=0] Acquired new producerId block ProducerIdsBlock{brokerId=0, producerIdStart=0, producerIdLen=1000} by writing to Zk with path version 1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:28,707] INFO StreamsConfig values:
	acceptable.recovery.lag = 100000
	application.id = app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74
	application.server =
	bootstrap.servers = [localhost:39849]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 10485760
	client.id =
	commit.interval.ms = 100
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$IntegerSerde
	default.list.key.serde.inner = null
	default.list.key.serde.type = null
	default.list.value.serde.inner = null
	default.list.value.serde.type = null
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$IntegerSerde
	max.task.idle.ms = 0
	max.warmup.replicas = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 1
	num.stream.threads = 4
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = exactly_once_v2
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = -1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b749455828311830722698-1
	task.timeout.ms = 300000
	topology.optimization = none
	upgrade.from = null
	window.size.ms = null
	windowed.inner.class.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
 (org.apache.kafka.streams.StreamsConfig:376)
[2022-08-19 10:40:28,748] WARN Using an OS temp directory in the state.dir property can cause failures with writing the checkpoint file due to the fact that this directory can be cleared by the OS. Resolved state.dir: [/tmp/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b749455828311830722698-1] (org.apache.kafka.streams.processor.internals.StateDirectory:138)
[2022-08-19 10:40:28,751] INFO No process id found on disk, got fresh process id 4099381e-a0be-433f-a0ce-efeff2e03df9 (org.apache.kafka.streams.processor.internals.StateDirectory:212)
[2022-08-19 10:40:28,796] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] Kafka Streams version: test-version (org.apache.kafka.streams.KafkaStreams:888)
[2022-08-19 10:40:28,796] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] Kafka Streams commit ID: test-commit-ID (org.apache.kafka.streams.KafkaStreams:889)
[2022-08-19 10:40:28,810] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:28,844] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:28,854] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:28,871] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:28,892] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:28,927] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:28,932] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:28,933] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:28,939] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:28,945] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:28,950] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:28,954] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:28,955] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:28,959] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:28,964] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:28,968] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:28,972] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:28,973] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:28,979] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:28,983] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:28,989] INFO StreamsConfig values:
	acceptable.recovery.lag = 100000
	application.id = app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74
	application.server =
	bootstrap.servers = [localhost:39849]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 10485760
	client.id =
	commit.interval.ms = 100
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$IntegerSerde
	default.list.key.serde.inner = null
	default.list.key.serde.type = null
	default.list.value.serde.inner = null
	default.list.value.serde.type = null
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$IntegerSerde
	max.task.idle.ms = 0
	max.warmup.replicas = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 1
	num.stream.threads = 4
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = exactly_once_v2
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = -1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b749455828311830722698-2
	task.timeout.ms = 300000
	topology.optimization = none
	upgrade.from = null
	window.size.ms = null
	windowed.inner.class.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
 (org.apache.kafka.streams.StreamsConfig:376)
[2022-08-19 10:40:28,990] WARN Using an OS temp directory in the state.dir property can cause failures with writing the checkpoint file due to the fact that this directory can be cleared by the OS. Resolved state.dir: [/tmp/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b749455828311830722698-2] (org.apache.kafka.streams.processor.internals.StateDirectory:138)
[2022-08-19 10:40:28,991] INFO No process id found on disk, got fresh process id 852a7c8a-a1b5-42a5-bdb4-468104a868f6 (org.apache.kafka.streams.processor.internals.StateDirectory:212)
[2022-08-19 10:40:28,996] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] Kafka Streams version: test-version (org.apache.kafka.streams.KafkaStreams:888)
[2022-08-19 10:40:28,996] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] Kafka Streams commit ID: test-commit-ID (org.apache.kafka.streams.KafkaStreams:889)
[2022-08-19 10:40:28,997] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,001] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,002] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,007] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,011] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,015] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,018] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,019] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,024] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,028] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,032] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,036] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,037] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,042] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,047] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,050] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,054] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,054] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,059] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,063] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,067] INFO StreamsConfig values:
	acceptable.recovery.lag = 100000
	application.id = app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74
	application.server =
	bootstrap.servers = [localhost:39849]
	buffered.records.per.partition = 1000
	built.in.metrics.version = latest
	cache.max.bytes.buffering = 10485760
	client.id =
	commit.interval.ms = 100
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$IntegerSerde
	default.list.key.serde.inner = null
	default.list.key.serde.type = null
	default.list.value.serde.inner = null
	default.list.value.serde.type = null
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$IntegerSerde
	max.task.idle.ms = 0
	max.warmup.replicas = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 1
	num.stream.threads = 4
	poll.ms = 100
	probing.rebalance.interval.ms = 600000
	processing.guarantee = exactly_once_v2
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = -1
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b749455828311830722698-3
	task.timeout.ms = 300000
	topology.optimization = none
	upgrade.from = null
	window.size.ms = null
	windowed.inner.class.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
 (org.apache.kafka.streams.StreamsConfig:376)
[2022-08-19 10:40:29,067] WARN Using an OS temp directory in the state.dir property can cause failures with writing the checkpoint file due to the fact that this directory can be cleared by the OS. Resolved state.dir: [/tmp/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b749455828311830722698-3] (org.apache.kafka.streams.processor.internals.StateDirectory:138)
[2022-08-19 10:40:29,068] INFO No process id found on disk, got fresh process id e4c78f95-7131-4046-a257-77f4390ca80f (org.apache.kafka.streams.processor.internals.StateDirectory:212)
[2022-08-19 10:40:29,072] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] Kafka Streams version: test-version (org.apache.kafka.streams.KafkaStreams:888)
[2022-08-19 10:40:29,072] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] Kafka Streams commit ID: test-commit-ID (org.apache.kafka.streams.KafkaStreams:889)
[2022-08-19 10:40:29,074] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,079] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,079] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,086] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,092] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,096] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,099] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,100] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,105] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,109] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,113] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,116] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,117] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,122] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,126] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,130] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Creating restore consumer client (org.apache.kafka.streams.processor.internals.StreamThread:341)
[2022-08-19 10:40:29,134] WARN The configuration 'internal.throw.on.fetch.stable.offset.unsupported' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:384)
[2022-08-19 10:40:29,135] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Creating thread producer client (org.apache.kafka.streams.processor.internals.StreamThread:102)
[2022-08-19 10:40:29,140] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Creating consumer client (org.apache.kafka.streams.processor.internals.StreamThread:393)
[2022-08-19 10:40:29,145] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer] Cooperative rebalancing protocol is enabled now (org.apache.kafka.streams.processor.internals.assignment.AssignorConfiguration:124)
[2022-08-19 10:40:29,149] INFO start first instance and wait for completed processing (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:183)
[2022-08-19 10:40:29,152] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:29,153] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:29,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:29,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:29,153] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:29,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,177] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(2), 1 -> ArrayBuffer(1), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(2), 4 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:29,185] INFO [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(bLGkAlb8QA6ioUOfDseayw),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,186] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,187] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,197] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,197] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,198] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,198] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,198] INFO [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,198] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,198] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 1 with 2 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,199] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 2 with 2 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,199] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1, 2) for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,199] INFO [Broker id=0] Handling LeaderAndIsr request correlationId 7 from controller 0 for 1 partitions (state.change.logger:66)
[2022-08-19 10:40:29,199] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 6 from controller 0 for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,200] INFO [Broker id=2] Handling LeaderAndIsr request correlationId 5 from controller 0 for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,201] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,201] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-2) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,201] INFO [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 7 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions (state.change.logger:66)
[2022-08-19 10:40:29,202] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-4, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,202] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 6 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,203] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-3, __consumer_offsets-0) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,203] INFO [Broker id=2] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,208] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,208] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,208] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,209] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-11287445166503993913/log7234199461537369559/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,209] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-11065391410224176982/log4982904532998605577/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,209] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-15053032471154295762/log4777233435427826506/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,210] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,210] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,210] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,210] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,210] INFO [Broker id=2] Leader __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,210] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,210] INFO [Broker id=0] Leader __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,210] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,211] INFO [Broker id=1] Leader __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,226] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,232] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,232] INFO [Broker id=0] Finished LeaderAndIsr request in 0ms correlationId 7 from controller 0 for 1 partitions (state.change.logger:66)
[2022-08-19 10:40:29,232] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,235] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-11287445166503993913/log7234199461537369559/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,235] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-15053032471154295762/log4777233435427826506/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,235] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,235] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,235] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,235] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,235] INFO [Broker id=2] Leader __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,235] INFO [Broker id=1] Leader __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,236] INFO [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 8 (state.change.logger:66)
[2022-08-19 10:40:29,244] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 13 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,248] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,249] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,250] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,250] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,250] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,250] INFO [Broker id=1] Finished LeaderAndIsr request in 0ms correlationId 6 from controller 0 for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,250] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,250] INFO [Broker id=2] Finished LeaderAndIsr request in 0ms correlationId 5 from controller 0 for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,251] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,251] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager:66)
[2022-08-19 10:40:29,252] INFO [Broker id=1] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 7 (state.change.logger:66)
[2022-08-19 10:40:29,252] INFO [Broker id=2] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 6 (state.change.logger:66)
[2022-08-19 10:40:29,267] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:29,267] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:29,267] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:29,267] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:29,317] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Empty state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,323] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Empty state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,324] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Empty state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,325] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Empty state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,333] INFO [GroupCoordinator 1]: Preparing to rebalance group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in state PreparingRebalance with old generation 0 (__consumer_offsets-4) (reason: Adding new member app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf with group instance id None) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,346] INFO [GroupCoordinator 1]: Stabilized group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 generation 1 (__consumer_offsets-4) with 4 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,385] INFO Creating topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog with configuration {cleanup.policy=compact, message.timestamp.type=CreateTime} and initial partition assignment HashMap(0 -> ArrayBuffer(1), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(2), 3 -> ArrayBuffer(1), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(2), 6 -> ArrayBuffer(1), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(2), 9 -> ArrayBuffer(1), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:29,393] INFO [Controller id=0] New topics: [Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog,Some(HDm3TxzDRVyPxrSgmEe4mw),HashMap(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0] New partition creation callback for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,394] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,395] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,395] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,395] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,395] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,395] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,396] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,399] INFO Creating topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog with configuration {cleanup.policy=compact, message.timestamp.type=CreateTime} and initial partition assignment HashMap(0 -> ArrayBuffer(2), 1 -> ArrayBuffer(1), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(2), 4 -> ArrayBuffer(1), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(2), 7 -> ArrayBuffer(1), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(2), 10 -> ArrayBuffer(1), 11 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,416] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,417] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,417] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,417] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,417] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 4 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,417] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 1 with 4 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,418] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 2 with 4 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,418] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1, 2) for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:29,418] INFO [Broker id=0] Handling LeaderAndIsr request correlationId 9 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,419] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 8 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,419] INFO [Broker id=2] Handling LeaderAndIsr request correlationId 7 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,419] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,422] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,422] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,422] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,423] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 8 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,422] INFO [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 9 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,422] INFO [Broker id=2] Stopped fetchers as part of LeaderAndIsr request correlationId 7 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,425] INFO [Controller id=0] New topics: [HashSet(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog,Some(FobjTX6wTqKii9DcJK26nQ),HashMap(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,426] INFO [Controller id=0] New partition creation callback for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6,app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,427] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,427] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,427] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,428] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,428] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,429] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,429] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,429] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,429] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,430] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,431] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,431] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger:66)
[2022-08-19 10:40:29,431] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 state from NonExistentPartition to NewPartition with assigned replicas 1 (state.change.logger:66)
[2022-08-19 10:40:29,431] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,431] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,431] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,431] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,431] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 state from NonExistentPartition to NewPartition with assigned replicas 2 (state.change.logger:66)
[2022-08-19 10:40:29,432] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,432] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,432] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,432] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,432] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,432] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,432] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,432] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,432] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,432] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,433] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,449] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,449] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,449] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,449] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,449] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,450] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,450] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,450] INFO [Controller id=0 epoch=1] Changed partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,451] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 4 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,451] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,451] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,451] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,451] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 1 with 4 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,452] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,452] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,452] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,452] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 2 with 4 become-leader and 0 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,452] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,452] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,452] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,452] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,452] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,452] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1, 2) for 12 partitions (state.change.logger:66)
[2022-08-19 10:40:29,453] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,454] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,469] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,469] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,469] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,470] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,470] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,470] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,470] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,471] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,470] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,471] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,470] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,471] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,471] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,471] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,471] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,487] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,487] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,487] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,488] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,488] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,488] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,488] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,488] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,488] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,488] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,488] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,488] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,489] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,489] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,489] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,501] INFO [Broker id=1] Finished LeaderAndIsr request in 0ms correlationId 8 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,501] INFO [Broker id=2] Finished LeaderAndIsr request in 0ms correlationId 7 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,501] INFO [Broker id=0] Finished LeaderAndIsr request in 0ms correlationId 9 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,504] INFO [Broker id=0] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 10 (state.change.logger:66)
[2022-08-19 10:40:29,504] INFO [Broker id=2] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 8 (state.change.logger:66)
[2022-08-19 10:40:29,504] INFO [Broker id=1] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 9 (state.change.logger:66)
[2022-08-19 10:40:29,505] INFO [Broker id=2] Handling LeaderAndIsr request correlationId 9 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,505] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 10 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,506] INFO [Broker id=0] Handling LeaderAndIsr request correlationId 11 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,508] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,508] INFO [Broker id=2] Stopped fetchers as part of LeaderAndIsr request correlationId 9 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,509] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,509] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 10 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,510] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,510] INFO [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 11 from controller 0 epoch 1 as part of the become-leader transition for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,513] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,520] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,520] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,520] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,521] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,521] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,521] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,521] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,521] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,522] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,522] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,522] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,522] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,522] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,522] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,538] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,538] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,538] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,540] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,540] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,540] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,540] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,540] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,541] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,541] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,541] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,541] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,541] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,541] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,541] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,558] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,558] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,558] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,559] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,559] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,559] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,560] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,559] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,560] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,560] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,560] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,560] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,560] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,560] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,560] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,576] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,576] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,576] INFO [LogLoader partition=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,577] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 in /tmp/kafka-11065391410224176982/log4982904532998605577/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,577] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 in /tmp/kafka-15053032471154295762/log4777233435427826506/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,577] INFO Created log for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 in /tmp/kafka-11287445166503993913/log7234199461537369559/app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 with properties {cleanup.policy=compact, message.timestamp.type="CreateTime"} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,578] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 broker=1] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,578] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 broker=0] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,578] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 broker=1] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,578] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 broker=2] No checkpointed highwatermark is found for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,578] INFO [Broker id=1] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,578] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 broker=0] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,578] INFO [Partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 broker=2] Log loaded for partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,578] INFO [Broker id=0] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,578] INFO [Broker id=2] Leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,591] INFO [Broker id=0] Finished LeaderAndIsr request in 0ms correlationId 11 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,591] INFO [Broker id=1] Finished LeaderAndIsr request in 0ms correlationId 10 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,594] INFO [Broker id=0] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 12 (state.change.logger:66)
[2022-08-19 10:40:29,594] INFO [Broker id=1] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 11 (state.change.logger:66)
[2022-08-19 10:40:29,600] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] All members participating in this rebalance:
4099381e-a0be-433f-a0ce-efeff2e03df9: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:600)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_0]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_1]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_2]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_3]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_4]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_5]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_6]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_7]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_8]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_9]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_10]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,604] WARN Unable to assign 1 of 1 standby tasks for task [0_11]. There is not enough available capacity. You should increase the number of application instances to maintain the requested number of standby replicas. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:147)
[2022-08-19 10:40:29,609] INFO Decided on assignment: {4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9, 0_10, 0_11]) standbyTasks: ([]) prevActiveTasks: ([]) prevStandbyTasks: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([0_0=0, 0_1=0, 0_2=0, 0_3=0, 0_4=0, 0_5=0, 0_6=0, 0_7=0, 0_8=0, 0_9=0, 0_10=0, 0_11=0]) capacity: 4 assigned: 12]} with no followup probing rebalance. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:95)
[2022-08-19 10:40:29,609] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Assigned tasks [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] including stateful [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] to clients as:
4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9, 0_10, 0_11]) standbyTasks: ([])]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:618)
[2022-08-19 10:40:29,614] INFO [Broker id=2] Finished LeaderAndIsr request in 0ms correlationId 9 from controller 0 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,616] INFO [Broker id=2] Add 12 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 10 (state.change.logger:66)
[2022-08-19 10:40:29,616] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 4099381e-a0be-433f-a0ce-efeff2e03df9 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_8, 0_4, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_5, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_6, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11, 0_7, 0_3]}
	revoking active {}
	assigned standby {}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:29,616] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:846)
[2022-08-19 10:40:29,625] INFO [GroupCoordinator 1]: Assignment received from leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf for group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for generation 1. The group has 4 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:29,642] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:29,643] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:29,643] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:29,644] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:29,645] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Handle new assignment with:
	New active tasks: [0_10, 0_6, 0_2]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:29,647] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Handle new assignment with:
	New active tasks: [0_9, 0_5, 0_1]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:29,647] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Handle new assignment with:
	New active tasks: [0_8, 0_4, 0_0]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:29,645] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Handle new assignment with:
	New active tasks: [0_11, 0_7, 0_3]
	New standby tasks: []
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:29,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:29,712] INFO Creating topic __transaction_state with configuration {compression.type=uncompressed, cleanup.policy=compact, min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 2, 0), 1 -> ArrayBuffer(0, 1, 2), 2 -> ArrayBuffer(2, 0, 1), 3 -> ArrayBuffer(1, 0, 2), 4 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:29,712] INFO Creating topic __transaction_state with configuration {compression.type=uncompressed, cleanup.policy=compact, min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 0, 2), 1 -> ArrayBuffer(0, 2, 1), 2 -> ArrayBuffer(2, 1, 0), 3 -> ArrayBuffer(1, 2, 0), 4 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient:66)
[2022-08-19 10:40:29,721] INFO [Controller id=0] New topics: [HashSet(__transaction_state)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__transaction_state,Some(vo6WtocpQCyjbhz5YY0bcQ),HashMap(__transaction_state-2 -> ReplicaAssignment(replicas=2,0,1, addingReplicas=, removingReplicas=), __transaction_state-0 -> ReplicaAssignment(replicas=1,2,0, addingReplicas=, removingReplicas=), __transaction_state-3 -> ReplicaAssignment(replicas=1,0,2, addingReplicas=, removingReplicas=), __transaction_state-4 -> ReplicaAssignment(replicas=0,2,1, addingReplicas=, removingReplicas=), __transaction_state-1 -> ReplicaAssignment(replicas=0,1,2, addingReplicas=, removingReplicas=))))] (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,721] INFO [Controller id=0] New partition creation callback for __transaction_state-2,__transaction_state-0,__transaction_state-3,__transaction_state-4,__transaction_state-1 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:29,721] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-2 state from NonExistentPartition to NewPartition with assigned replicas 2,0,1 (state.change.logger:66)
[2022-08-19 10:40:29,721] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-0 state from NonExistentPartition to NewPartition with assigned replicas 1,2,0 (state.change.logger:66)
[2022-08-19 10:40:29,722] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-3 state from NonExistentPartition to NewPartition with assigned replicas 1,0,2 (state.change.logger:66)
[2022-08-19 10:40:29,722] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-4 state from NonExistentPartition to NewPartition with assigned replicas 0,2,1 (state.change.logger:66)
[2022-08-19 10:40:29,722] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-1 state from NonExistentPartition to NewPartition with assigned replicas 0,1,2 (state.change.logger:66)
[2022-08-19 10:40:29,722] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,723] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,737] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=2, leaderEpoch=0, isr=List(2, 0, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,737] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 2, 0), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,737] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=1, leaderEpoch=0, isr=List(1, 0, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,737] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 2, 1), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,737] INFO [Controller id=0 epoch=1] Changed partition __transaction_state-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0, 1, 2), zkVersion=0) (state.change.logger:66)
[2022-08-19 10:40:29,737] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 2 become-leader and 3 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,738] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 1 with 2 become-leader and 3 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,738] INFO [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 2 with 1 become-leader and 4 become-follower partitions (state.change.logger:66)
[2022-08-19 10:40:29,739] INFO [Broker id=0] Handling LeaderAndIsr request correlationId 13 from controller 0 for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,739] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0, 1, 2) for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,739] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 12 from controller 0 for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,739] INFO [Broker id=2] Handling LeaderAndIsr request correlationId 11 from controller 0 for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,740] INFO [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger:66)
[2022-08-19 10:40:29,742] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__transaction_state-3, __transaction_state-0) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,742] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__transaction_state-4, __transaction_state-1) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,742] INFO [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 13 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,742] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__transaction_state-2) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,742] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 12 from controller 0 epoch 1 as part of the become-leader transition for 2 partitions (state.change.logger:66)
[2022-08-19 10:40:29,742] INFO [Broker id=2] Stopped fetchers as part of LeaderAndIsr request correlationId 11 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions (state.change.logger:66)
[2022-08-19 10:40:29,746] INFO [LogLoader partition=__transaction_state-3, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,746] INFO [LogLoader partition=__transaction_state-2, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,746] INFO [LogLoader partition=__transaction_state-4, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,748] INFO Created log for partition __transaction_state-3 in /tmp/kafka-15053032471154295762/log4777233435427826506/__transaction_state-3 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,748] INFO Created log for partition __transaction_state-2 in /tmp/kafka-11287445166503993913/log7234199461537369559/__transaction_state-2 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,748] INFO Created log for partition __transaction_state-4 in /tmp/kafka-11065391410224176982/log4982904532998605577/__transaction_state-4 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,748] INFO [Partition __transaction_state-3 broker=1] No checkpointed highwatermark is found for partition __transaction_state-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,748] INFO [Partition __transaction_state-2 broker=2] No checkpointed highwatermark is found for partition __transaction_state-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,748] INFO [Partition __transaction_state-4 broker=0] No checkpointed highwatermark is found for partition __transaction_state-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,748] INFO [Partition __transaction_state-3 broker=1] Log loaded for partition __transaction_state-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,748] INFO [Partition __transaction_state-4 broker=0] Log loaded for partition __transaction_state-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,749] INFO [Broker id=1] Leader __transaction_state-3 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,0,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,748] INFO [Partition __transaction_state-2 broker=2] Log loaded for partition __transaction_state-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,749] INFO [Broker id=0] Leader __transaction_state-4 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,2,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,749] INFO [Broker id=2] Leader __transaction_state-2 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [2,0,1] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,768] INFO [LogLoader partition=__transaction_state-4, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,768] INFO [LogLoader partition=__transaction_state-1, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,768] INFO [LogLoader partition=__transaction_state-0, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,769] INFO Created log for partition __transaction_state-4 in /tmp/kafka-11287445166503993913/log7234199461537369559/__transaction_state-4 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,769] INFO Created log for partition __transaction_state-1 in /tmp/kafka-11065391410224176982/log4982904532998605577/__transaction_state-1 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,769] INFO [Partition __transaction_state-4 broker=2] No checkpointed highwatermark is found for partition __transaction_state-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,769] INFO [Partition __transaction_state-1 broker=0] No checkpointed highwatermark is found for partition __transaction_state-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,770] INFO [Partition __transaction_state-4 broker=2] Log loaded for partition __transaction_state-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,770] INFO [Partition __transaction_state-1 broker=0] Log loaded for partition __transaction_state-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,770] INFO [Broker id=2] Follower __transaction_state-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,770] INFO [Broker id=0] Leader __transaction_state-1 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [0,1,2] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,770] INFO Created log for partition __transaction_state-0 in /tmp/kafka-15053032471154295762/log4777233435427826506/__transaction_state-0 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,771] INFO [Partition __transaction_state-0 broker=1] No checkpointed highwatermark is found for partition __transaction_state-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,771] INFO [Partition __transaction_state-0 broker=1] Log loaded for partition __transaction_state-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,771] INFO [Broker id=1] Leader __transaction_state-0 starts at leader epoch 0 from offset 0 with high watermark 0 ISR [1,2,0] addingReplicas [] removingReplicas []. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,774] INFO [LogLoader partition=__transaction_state-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,775] INFO Created log for partition __transaction_state-3 in /tmp/kafka-11287445166503993913/log7234199461537369559/__transaction_state-3 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,775] INFO [Partition __transaction_state-3 broker=2] No checkpointed highwatermark is found for partition __transaction_state-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,775] INFO [Partition __transaction_state-3 broker=2] Log loaded for partition __transaction_state-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,775] INFO [Broker id=2] Follower __transaction_state-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,779] INFO [LogLoader partition=__transaction_state-1, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,780] INFO Created log for partition __transaction_state-1 in /tmp/kafka-11287445166503993913/log7234199461537369559/__transaction_state-1 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,781] INFO [Partition __transaction_state-1 broker=2] No checkpointed highwatermark is found for partition __transaction_state-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,781] INFO [Partition __transaction_state-1 broker=2] Log loaded for partition __transaction_state-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,781] INFO [Broker id=2] Follower __transaction_state-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,785] INFO [LogLoader partition=__transaction_state-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,787] INFO Created log for partition __transaction_state-0 in /tmp/kafka-11287445166503993913/log7234199461537369559/__transaction_state-0 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,787] INFO [Partition __transaction_state-0 broker=2] No checkpointed highwatermark is found for partition __transaction_state-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,788] INFO [Partition __transaction_state-0 broker=2] Log loaded for partition __transaction_state-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,788] INFO [Broker id=2] Follower __transaction_state-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,788] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__transaction_state-0, __transaction_state-1, __transaction_state-3, __transaction_state-4) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,788] INFO [Broker id=2] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 11 for 4 partitions (state.change.logger:66)
[2022-08-19 10:40:29,789] INFO [LogLoader partition=__transaction_state-3, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,789] INFO [LogLoader partition=__transaction_state-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,789] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(__transaction_state-1 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=0, host=localhost:39849),0,0), __transaction_state-4 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=0, host=localhost:39849),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,790] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(__transaction_state-3 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=1, host=localhost:45197),0,0), __transaction_state-0 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=1, host=localhost:45197),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,790] INFO Created log for partition __transaction_state-3 in /tmp/kafka-11065391410224176982/log4982904532998605577/__transaction_state-3 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,791] INFO [Partition __transaction_state-3 broker=0] No checkpointed highwatermark is found for partition __transaction_state-3 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,791] INFO [Partition __transaction_state-3 broker=0] Log loaded for partition __transaction_state-3 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,790] INFO Created log for partition __transaction_state-4 in /tmp/kafka-15053032471154295762/log4777233435427826506/__transaction_state-4 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,791] INFO [Broker id=0] Follower __transaction_state-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,792] INFO [Partition __transaction_state-4 broker=1] No checkpointed highwatermark is found for partition __transaction_state-4 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,792] INFO [Partition __transaction_state-4 broker=1] Log loaded for partition __transaction_state-4 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,792] INFO [Broker id=1] Follower __transaction_state-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,792] INFO [TransactionCoordinator id=2] Elected as the txn coordinator for partition 2 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,797] INFO [LogLoader partition=__transaction_state-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,797] INFO [LogLoader partition=__transaction_state-2, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,799] INFO Created log for partition __transaction_state-2 in /tmp/kafka-11065391410224176982/log4982904532998605577/__transaction_state-2 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,799] INFO Created log for partition __transaction_state-2 in /tmp/kafka-15053032471154295762/log4777233435427826506/__transaction_state-2 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,799] INFO [Partition __transaction_state-2 broker=0] No checkpointed highwatermark is found for partition __transaction_state-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,799] INFO [Partition __transaction_state-2 broker=1] No checkpointed highwatermark is found for partition __transaction_state-2 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,799] INFO [Partition __transaction_state-2 broker=0] Log loaded for partition __transaction_state-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,800] INFO [Partition __transaction_state-2 broker=1] Log loaded for partition __transaction_state-2 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,800] INFO [Broker id=0] Follower __transaction_state-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,800] INFO [Broker id=1] Follower __transaction_state-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,802] INFO [TransactionCoordinator id=2] Resigned as the txn coordinator for partition 4 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,802] INFO [Transaction State Manager 2]: Loading transaction metadata from __transaction_state-2 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,803] INFO [Transaction State Manager 2]: No cached transaction metadata found for __transaction_state-4 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,804] INFO [TransactionCoordinator id=2] Resigned as the txn coordinator for partition 3 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,804] INFO [Transaction State Manager 2]: No cached transaction metadata found for __transaction_state-3 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,805] INFO [TransactionCoordinator id=2] Resigned as the txn coordinator for partition 1 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,805] INFO [Transaction State Manager 2]: No cached transaction metadata found for __transaction_state-1 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,805] INFO [TransactionCoordinator id=2] Resigned as the txn coordinator for partition 0 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,805] INFO [Transaction State Manager 2]: No cached transaction metadata found for __transaction_state-0 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,805] INFO [Broker id=2] Finished LeaderAndIsr request in 0ms correlationId 11 from controller 0 for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,807] INFO [LogLoader partition=__transaction_state-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,807] INFO [LogLoader partition=__transaction_state-0, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$:1722)
[2022-08-19 10:40:29,808] INFO Created log for partition __transaction_state-1 in /tmp/kafka-15053032471154295762/log4777233435427826506/__transaction_state-1 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,809] INFO [Transaction State Manager 2]: Finished loading 0 transaction metadata from __transaction_state-2 in 8 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,809] INFO [Partition __transaction_state-1 broker=1] No checkpointed highwatermark is found for partition __transaction_state-1 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,809] INFO [Partition __transaction_state-1 broker=1] Log loaded for partition __transaction_state-1 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,809] INFO [Broker id=2] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 12 (state.change.logger:66)
[2022-08-19 10:40:29,809] INFO [Broker id=1] Follower __transaction_state-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,809] INFO Created log for partition __transaction_state-0 in /tmp/kafka-11065391410224176982/log4982904532998605577/__transaction_state-0 with properties {cleanup.policy=compact, compression.type="uncompressed", min.insync.replicas=2, segment.bytes=104857600, unclean.leader.election.enable=false} (kafka.log.LogManager:66)
[2022-08-19 10:40:29,809] INFO [Partition __transaction_state-0 broker=0] No checkpointed highwatermark is found for partition __transaction_state-0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,810] INFO [Partition __transaction_state-0 broker=0] Log loaded for partition __transaction_state-0 with initial high watermark 0 (kafka.cluster.Partition:66)
[2022-08-19 10:40:29,809] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__transaction_state-1, __transaction_state-2, __transaction_state-4) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,810] INFO [Broker id=0] Follower __transaction_state-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (state.change.logger:66)
[2022-08-19 10:40:29,810] INFO [Broker id=1] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 12 for 3 partitions (state.change.logger:66)
[2022-08-19 10:40:29,810] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__transaction_state-0, __transaction_state-2, __transaction_state-3) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,811] INFO [Broker id=0] Stopped fetchers as part of become-follower request from controller 0 epoch 1 with correlation id 13 for 3 partitions (state.change.logger:66)
[2022-08-19 10:40:29,811] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(__transaction_state-1 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=0, host=localhost:39849),0,0), __transaction_state-4 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=0, host=localhost:39849),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,811] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(__transaction_state-3 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=1, host=localhost:45197),0,0), __transaction_state-0 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=1, host=localhost:45197),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,811] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(__transaction_state-2 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=2, host=localhost:45019),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,812] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(__transaction_state-2 -> InitialFetchState(Some(vo6WtocpQCyjbhz5YY0bcQ),BrokerEndPoint(id=2, host=localhost:45019),0,0)) (kafka.server.ReplicaFetcherManager:66)
[2022-08-19 10:40:29,812] INFO [TransactionCoordinator id=1] Elected as the txn coordinator for partition 3 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,816] INFO [TransactionCoordinator id=0] Elected as the txn coordinator for partition 4 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,817] INFO [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-3 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,817] INFO [TransactionCoordinator id=1] Elected as the txn coordinator for partition 0 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,817] INFO [Transaction State Manager 0]: Loading transaction metadata from __transaction_state-4 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,817] INFO [TransactionCoordinator id=1] Resigned as the txn coordinator for partition 4 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,818] INFO [Transaction State Manager 1]: No cached transaction metadata found for __transaction_state-4 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,818] INFO [TransactionCoordinator id=1] Resigned as the txn coordinator for partition 2 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,818] INFO [Transaction State Manager 1]: No cached transaction metadata found for __transaction_state-2 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,818] INFO [TransactionCoordinator id=1] Resigned as the txn coordinator for partition 1 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,818] INFO [Transaction State Manager 1]: No cached transaction metadata found for __transaction_state-1 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,817] INFO [TransactionCoordinator id=0] Elected as the txn coordinator for partition 1 at epoch 0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,818] INFO [Broker id=1] Finished LeaderAndIsr request in 0ms correlationId 12 from controller 0 for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,819] INFO [TransactionCoordinator id=0] Resigned as the txn coordinator for partition 3 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,819] INFO [Transaction State Manager 0]: No cached transaction metadata found for __transaction_state-3 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,819] INFO [TransactionCoordinator id=0] Resigned as the txn coordinator for partition 2 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,819] INFO [Transaction State Manager 0]: No cached transaction metadata found for __transaction_state-2 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,819] INFO [TransactionCoordinator id=0] Resigned as the txn coordinator for partition 0 at epoch Some(0) (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:29,819] INFO [Transaction State Manager 0]: Finished loading 0 transaction metadata from __transaction_state-4 in 2 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,819] INFO [Transaction State Manager 1]: Finished loading 0 transaction metadata from __transaction_state-3 in 3 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,819] INFO [Transaction State Manager 0]: No cached transaction metadata found for __transaction_state-0 during become-follower transition (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,819] INFO [Transaction State Manager 2]: Completed loading transaction metadata from __transaction_state-2 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,820] INFO [Transaction State Manager 1]: Completed loading transaction metadata from __transaction_state-3 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,820] INFO [Broker id=0] Finished LeaderAndIsr request in 0ms correlationId 13 from controller 0 for 5 partitions (state.change.logger:66)
[2022-08-19 10:40:29,820] INFO [Transaction State Manager 1]: Loading transaction metadata from __transaction_state-0 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,820] INFO [Transaction State Manager 0]: Completed loading transaction metadata from __transaction_state-4 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,820] INFO [Transaction State Manager 0]: Loading transaction metadata from __transaction_state-1 at epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,821] INFO [Broker id=1] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 13 (state.change.logger:66)
[2022-08-19 10:40:29,821] INFO [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 14 (state.change.logger:66)
[2022-08-19 10:40:29,822] INFO [Transaction State Manager 1]: Finished loading 0 transaction metadata from __transaction_state-0 in 5 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,822] INFO [Transaction State Manager 1]: Completed loading transaction metadata from __transaction_state-0 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,822] INFO [Transaction State Manager 0]: Finished loading 0 transaction metadata from __transaction_state-1 in 3 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,823] INFO [Transaction State Manager 0]: Completed loading transaction metadata from __transaction_state-1 for coordinator epoch 0 (kafka.coordinator.transaction.TransactionStateManager:66)
[2022-08-19 10:40:29,959] INFO [Controller id=0] Acquired new producerId block ProducerIdsBlock{brokerId=1, producerIdStart=1000, producerIdLen=1000} by writing to Zk with path version 2 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:30,084] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __transaction_state-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,085] INFO [UnifiedLog partition=__transaction_state-2, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,088] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition __transaction_state-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,088] INFO [UnifiedLog partition=__transaction_state-2, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,088] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __transaction_state-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,089] INFO [UnifiedLog partition=__transaction_state-1, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,089] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __transaction_state-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,089] INFO [UnifiedLog partition=__transaction_state-4, dir=/tmp/kafka-15053032471154295762/log4777233435427826506] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,095] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition __transaction_state-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,095] INFO [UnifiedLog partition=__transaction_state-1, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,095] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition __transaction_state-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,095] INFO [UnifiedLog partition=__transaction_state-4, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,122] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4 with producerId 2 and producer epoch 0 on partition __transaction_state-1 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:30,124] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2 with producerId 1 and producer epoch 0 on partition __transaction_state-4 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:30,148] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __transaction_state-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,148] INFO [UnifiedLog partition=__transaction_state-0, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,149] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition __transaction_state-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,149] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition __transaction_state-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,149] INFO [UnifiedLog partition=__transaction_state-0, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,149] INFO [UnifiedLog partition=__transaction_state-3, dir=/tmp/kafka-11287445166503993913/log7234199461537369559] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,149] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition __transaction_state-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread:66)
[2022-08-19 10:40:30,149] INFO [UnifiedLog partition=__transaction_state-3, dir=/tmp/kafka-11065391410224176982/log4982904532998605577] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog:66)
[2022-08-19 10:40:30,168] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3 with producerId 1001 and producer epoch 0 on partition __transaction_state-0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:30,169] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1 with producerId 1000 and producer epoch 0 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:30,334] INFO [Controller id=0] Processing automatic preferred replica leader election (kafka.controller.KafkaController:66)
[2022-08-19 10:40:30,379] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,380] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,380] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,383] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,489] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,489] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,489] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,516] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,517] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,602] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,602] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,602] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,652] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,652] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:30,652] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:30,731] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,731] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,731] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,731] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,731] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,732] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,737] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,739] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,741] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,741] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Restoration took 1051 ms for all tasks [0_1, 0_5, 0_9] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:30,741] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:30,770] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,770] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,771] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,771] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,771] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,771] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,773] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,773] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,773] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,773] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,773] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,774] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:30,777] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,777] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,779] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,779] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Restoration took 1089 ms for all tasks [0_2, 0_6, 0_10] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:30,779] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:30,780] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,780] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Restoration took 1090 ms for all tasks [0_0, 0_4, 0_8] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:30,780] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:30,780] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,783] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:30,784] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Restoration took 1094 ms for all tasks [0_3, 0_7, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:30,784] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:30,784] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:30,822] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group cfa22b6d-f007-41ee-a904-d9065c3df71e in Empty state. Created a new member id consumer-cfa22b6d-f007-41ee-a904-d9065c3df71e-1-6d5917ff-bb91-42ae-a881-de291e36f740 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:30,825] INFO [GroupCoordinator 1]: Preparing to rebalance group cfa22b6d-f007-41ee-a904-d9065c3df71e in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-cfa22b6d-f007-41ee-a904-d9065c3df71e-1-6d5917ff-bb91-42ae-a881-de291e36f740 with group instance id None) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:30,826] INFO [GroupCoordinator 1]: Stabilized group cfa22b6d-f007-41ee-a904-d9065c3df71e generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:30,833] INFO [GroupCoordinator 1]: Assignment received from leader consumer-cfa22b6d-f007-41ee-a904-d9065c3df71e-1-6d5917ff-bb91-42ae-a881-de291e36f740 for group cfa22b6d-f007-41ee-a904-d9065c3df71e for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,305] INFO [GroupCoordinator 1]: Preparing to rebalance group cfa22b6d-f007-41ee-a904-d9065c3df71e in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-cfa22b6d-f007-41ee-a904-d9065c3df71e-1-6d5917ff-bb91-42ae-a881-de291e36f740 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,306] INFO [GroupCoordinator 1]: Group cfa22b6d-f007-41ee-a904-d9065c3df71e with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,308] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-cfa22b6d-f007-41ee-a904-d9065c3df71e-1-6d5917ff-bb91-42ae-a881-de291e36f740, groupInstanceId=None, clientId=consumer-cfa22b6d-f007-41ee-a904-d9065c3df71e-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group cfa22b6d-f007-41ee-a904-d9065c3df71e through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,311] INFO Finished reading the initial bulk (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:196)
[2022-08-19 10:40:31,312] INFO start second instance and wait for standby replication (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:198)
[2022-08-19 10:40:31,312] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:31,312] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:31,312] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:31,313] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:31,313] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:31,313] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:31,313] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:31,313] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:31,314] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:31,321] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,322] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,322] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,323] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,323] INFO [GroupCoordinator 1]: Preparing to rebalance group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: Adding new member app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 with group instance id None) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:31,414] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:31,414] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:31,414] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:31,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:32,356] INFO [GroupCoordinator 1]: Stabilized group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 generation 2 (__consumer_offsets-4) with 8 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:32,364] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] All members participating in this rebalance:
852a7c8a-a1b5-42a5-bdb4-468104a868f6: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e]
4099381e-a0be-433f-a0ce-efeff2e03df9: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:600)
[2022-08-19 10:40:32,365] INFO Decided on assignment: {852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) standbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) prevActiveTasks: ([]) prevStandbyTasks: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([0_0=268, 0_1=280, 0_2=236, 0_3=258, 0_4=273, 0_5=248, 0_6=264, 0_7=235, 0_8=253, 0_9=243, 0_10=290, 0_11=215]) capacity: 4 assigned: 12], 4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) standbyTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) prevActiveTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9, 0_10, 0_11]) prevStandbyTasks: ([]) changelogOffsetTotalsByTask: ([0_0=-2, 0_1=-2, 0_2=-2, 0_3=-2, 0_4=-2, 0_5=-2, 0_6=-2, 0_7=-2, 0_8=-2, 0_9=-2, 0_10=-2, 0_11=-2]) taskLagTotals: ([0_0=-2, 0_1=-2, 0_2=-2, 0_3=-2, 0_4=-2, 0_5=-2, 0_6=-2, 0_7=-2, 0_8=-2, 0_9=-2, 0_10=-2, 0_11=-2]) capacity: 4 assigned: 12]} with no followup probing rebalance. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:95)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Assigned tasks [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] including stateful [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] to clients as:
852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) standbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11])]
4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) standbyTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10])]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:618)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_0 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_8 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_0 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_8 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_2 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,365] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_10 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_2 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_10 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_4 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_4 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_6 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_6 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 852a7c8a-a1b5-42a5-bdb4-468104a868f6 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_6]}
	revoking active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_6]}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_9, 0_8, 0_1, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_11, 0_10, 0_3, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_5, 0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_7, 0_6]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_5 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_5 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_7 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_7 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:32,366] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:32,367] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 4099381e-a0be-433f-a0ce-efeff2e03df9 per-consumer assignment:
	prev owned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_8, 0_4, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_5, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_6, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11, 0_7, 0_3]}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11, 0_3]}
	revoking active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_7]}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_8, 0_5, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_7, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_6]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:32,367] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Finished unstable assignment of tasks, a followup rebalance will be scheduled. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:843)
[2022-08-19 10:40:32,368] INFO [GroupCoordinator 1]: Assignment received from leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf for group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for generation 2. The group has 8 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:32,369] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,370] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:32,370] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:32,369] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from RUNNING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,370] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_9, 0_1, 0_8, 0_0]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,370] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_7, 0_6]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,370] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:32,370] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from RUNNING to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:32,371] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_11, 0_3, 0_10, 0_2]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,370] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from RUNNING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,371] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from RUNNING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,371] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:32,371] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_5, 0_4]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,373] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,373] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,374] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,374] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] partition revocation took 41 ms. (org.apache.kafka.streams.processor.internals.StreamThread:97)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] partition revocation took 41 ms. (org.apache.kafka.streams.processor.internals.StreamThread:97)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Handle new assignment with:
	New active tasks: [0_9, 0_1]
	New standby tasks: [0_4]
	Existing active tasks: [0_9, 0_5, 0_1]
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,412] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Handle new assignment with:
	New active tasks: [0_11, 0_3]
	New standby tasks: [0_6]
	Existing active tasks: [0_11, 0_7, 0_3]
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:40:32,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_7] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:40:32,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,418] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,420] INFO [GroupCoordinator 1]: Preparing to rebalance group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in state PreparingRebalance with old generation 2 (__consumer_offsets-4) (reason: Updating metadata for member app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d during Stable) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] partition revocation took 151 ms. (org.apache.kafka.streams.processor.internals.StreamThread:97)
[2022-08-19 10:40:32,522] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:32,523] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_5, 0_8, 0_0]
	Existing active tasks: [0_8, 0_4, 0_0]
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,526] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,526] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_4] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:40:32,527] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,527] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_0] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StreamTask:566)
[2022-08-19 10:40:32,528] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,528] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StreamTask:566)
[2022-08-19 10:40:32,528] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,528] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,528] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] partition revocation took 157 ms. (org.apache.kafka.streams.processor.internals.StreamThread:97)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:32,529] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_7, 0_10, 0_2]
	Existing active tasks: [0_10, 0_6, 0_2]
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,531] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_0] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,531] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_8] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,534] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,534] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_6] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:40:32,534] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,535] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StreamTask:566)
[2022-08-19 10:40:32,535] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:40:32,535] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_10] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StreamTask:566)
[2022-08-19 10:40:32,535] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,537] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_2] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,538] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_10] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,543] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_4] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,543] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_4] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,543] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_4] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_0] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_0] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_0] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_6] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_6] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_6] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,546] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:32,639] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:32,639] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] standby-task [0_4] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,639] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Restoration took 221 ms for all tasks [0_1, 0_4, 0_9] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,639] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,642] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_6] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,643] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Restoration took 225 ms for all tasks [0_3, 0_6, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,643] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,663] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_5] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,663] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_5] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,663] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_5] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,663] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Restoration took 290 ms for all tasks [0_4, 0_5] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,663] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,664] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:32,669] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_3] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,669] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_3] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,669] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_1] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,670] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_1] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,669] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_3] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,670] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_1] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_7] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_7] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_7] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Restoration took 299 ms for all tasks [0_6, 0_7] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,675] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:32,785] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_8] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,785] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_8] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,785] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_8] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,788] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_10] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,788] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_10] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,788] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_10] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,897] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_9] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,897] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_9] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,897] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_9] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,898] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Restoration took 524 ms for all tasks [0_0, 0_1, 0_8, 0_9] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,898] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,899] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:32,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_11] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_11] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:32,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_11] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:32,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Restoration took 531 ms for all tasks [0_2, 0_3, 0_10, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,905] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:32,906] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:32,907] INFO [GroupCoordinator 1]: Stabilized group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 generation 3 (__consumer_offsets-4) with 8 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:32,937] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] All members participating in this rebalance:
852a7c8a-a1b5-42a5-bdb4-468104a868f6: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e]
4099381e-a0be-433f-a0ce-efeff2e03df9: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:600)
[2022-08-19 10:40:32,938] INFO Decided on assignment: {852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) standbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) prevActiveTasks: ([]) prevStandbyTasks: ([0_0, 0_1, 0_2, 0_3, 0_4, 0_5, 0_6, 0_7, 0_8, 0_9, 0_10, 0_11]) changelogOffsetTotalsByTask: ([0_0=0, 0_1=0, 0_2=0, 0_3=0, 0_4=0, 0_5=0, 0_6=0, 0_7=0, 0_8=0, 0_9=0, 0_10=0, 0_11=0]) taskLagTotals: ([0_0=268, 0_1=280, 0_2=236, 0_3=258, 0_4=273, 0_5=248, 0_6=264, 0_7=235, 0_8=253, 0_9=243, 0_10=290, 0_11=215]) capacity: 4 assigned: 12], 4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) standbyTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) prevActiveTasks: ([0_1, 0_3, 0_9, 0_11]) prevStandbyTasks: ([0_0, 0_2, 0_4, 0_5, 0_7, 0_8, 0_10]) changelogOffsetTotalsByTask: ([0_0=264, 0_1=-2, 0_2=232, 0_3=-2, 0_4=269, 0_5=244, 0_7=231, 0_8=249, 0_9=-2, 0_10=286, 0_11=-2]) taskLagTotals: ([0_0=4, 0_1=-2, 0_2=4, 0_3=-2, 0_4=4, 0_5=4, 0_6=264, 0_7=4, 0_8=4, 0_9=-2, 0_10=4, 0_11=-2]) capacity: 4 assigned: 12]} with no followup probing rebalance. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:95)
[2022-08-19 10:40:32,938] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Assigned tasks [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] including stateful [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] to clients as:
852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) standbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11])]
4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) standbyTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10])]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:618)
[2022-08-19 10:40:32,938] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 852a7c8a-a1b5-42a5-bdb4-468104a868f6 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_9, 0_8, 0_1, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_11, 0_10, 0_3, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_5, 0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_7, 0_6]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_6]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_11, 0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_7]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:32,939] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 4099381e-a0be-433f-a0ce-efeff2e03df9 per-consumer assignment:
	prev owned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11, 0_3]}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_8, 0_5, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_7, 0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_7, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_5]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11, 0_3]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_6]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:32,939] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:846)
[2022-08-19 10:40:32,939] INFO [GroupCoordinator 1]: Assignment received from leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf for group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for generation 3. The group has 8 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Handle new assignment with:
	New active tasks: [0_6]
	New standby tasks: [0_7]
	Existing active tasks: []
	Existing standby tasks: [0_7, 0_6] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Handle new assignment with:
	New active tasks: [0_9, 0_1]
	New standby tasks: [0_4]
	Existing active tasks: [0_9, 0_1]
	Existing standby tasks: [0_4] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Handle new assignment with:
	New active tasks: [0_4]
	New standby tasks: [0_5]
	Existing active tasks: []
	Existing standby tasks: [0_5, 0_4] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Handle new assignment with:
	New active tasks: [0_10, 0_2]
	New standby tasks: [0_11, 0_3]
	Existing active tasks: []
	Existing standby tasks: [0_11, 0_10, 0_3, 0_2] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Handle new assignment with:
	New active tasks: [0_8, 0_0]
	New standby tasks: [0_9, 0_1]
	Existing active tasks: []
	Existing standby tasks: [0_9, 0_8, 0_1, 0_0] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,941] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:32,942] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Handle new assignment with:
	New active tasks: [0_11, 0_3]
	New standby tasks: [0_6]
	Existing active tasks: [0_11, 0_3]
	Existing standby tasks: [0_6] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:32,942] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_6] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:40:32,942] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,942] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_4] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:40:32,942] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_0] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:40:32,942] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:40:32,944] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Restoration took 2 ms for all tasks [0_1, 0_4, 0_9] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,944] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,948] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Restoration took 6 ms for all tasks [0_3, 0_6, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:32,948] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,953] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_6] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:32,953] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_4] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:32,954] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,954] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from RUNNING to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:32,954] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,956] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_10] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:40:32,956] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_8] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:40:32,964] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:32,964] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_0] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:32,965] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_10] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:32,965] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_8] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:32,965] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:32,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,040] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:33,040] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Handle new assignment with:
	New active tasks: [0_5]
	New standby tasks: [0_8, 0_0]
	Existing active tasks: []
	Existing standby tasks: [0_8, 0_5, 0_0] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:33,040] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_5] Suspended created (org.apache.kafka.streams.processor.internals.StandbyTask:122)
[2022-08-19 10:40:33,040] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_5] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:33,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:40:33,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PARTITIONS_ASSIGNED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Handle new assignment with:
	New active tasks: [0_7]
	New standby tasks: [0_10, 0_2]
	Existing active tasks: []
	Existing standby tasks: [0_10, 0_7, 0_2] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:33,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_7] Suspended created (org.apache.kafka.streams.processor.internals.StandbyTask:122)
[2022-08-19 10:40:33,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_7] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:40:33,042] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from PARTITIONS_ASSIGNED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,071] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3 with producerId 1002 and producer epoch 0 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:33,072] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,083] INFO [Controller id=0] Acquired new producerId block ProducerIdsBlock{brokerId=2, producerIdStart=2000, producerIdLen=1000} by writing to Zk with path version 3 (kafka.controller.KafkaController:66)
[2022-08-19 10:40:33,087] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 267 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,087] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 2 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,088] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,088] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Restoration took 134 ms for all tasks [0_4, 0_5] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:33,088] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,097] INFO [TransactionCoordinator id=2] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4 with producerId 2000 and producer epoch 0 on partition __transaction_state-2 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:33,098] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,104] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1 with producerId 1003 and producer epoch 0 on partition __transaction_state-0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:33,105] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,106] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,113] INFO Second stream have some data in the state store (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:210)
[2022-08-19 10:40:33,113] INFO Produce the second bulk (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:213)
[2022-08-19 10:40:33,113] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 2 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,116] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 258 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,116] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2 with producerId 3 and producer epoch 0 on partition __transaction_state-4 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:33,149] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,150] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,150] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_10] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,151] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Restoration took 197 ms for all tasks [0_6, 0_7] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:33,151] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,151] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,159] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 262 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,159] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Restoration in progress for 3 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0: position=0, end=4, totalRestored=0} {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8: position=0, end=251, totalRestored=0} {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8: position=0, end=2, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:40:33,161] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 2 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,162] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 250 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,164] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,165] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 1 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,166] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,166] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Restoration took 200 ms for all tasks [0_0, 0_1, 0_8, 0_9] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:33,167] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,168] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 1 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,169] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 233 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,170] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:40:33,170] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 284 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,170] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Restoration in progress for 1 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10: position=0, end=4, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:40:33,173] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,174] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 2 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_10] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Restoration took 212 ms for all tasks [0_2, 0_3, 0_10, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:33,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,177] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:33,255] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,255] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,257] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,257] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Restoration took 216 ms for all tasks [0_0, 0_5, 0_8] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:33,257] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,274] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,274] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:40:33,278] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:40:33,278] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Restoration took 236 ms for all tasks [0_2, 0_7, 0_10] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:33,278] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:33,278] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:33,504] INFO Allow for some processing of messages by stream one and two and some catching up of standby tasks (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:226)
[2022-08-19 10:40:38,505] INFO Start stream three which will introduce a re-balancing event and hopefully some redistribution of tasks. (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:229)
[2022-08-19 10:40:38,505] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] State transition from CREATED to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:38,506] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:38,506] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:38,506] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:38,508] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:38,508] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:38,508] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Starting (org.apache.kafka.streams.processor.internals.StreamThread:569)
[2022-08-19 10:40:38,508] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:38,510] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from CREATED to STARTING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:38,579] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:38,580] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:38,580] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:38,580] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in Stable state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:38,580] INFO [GroupCoordinator 1]: Preparing to rebalance group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in state PreparingRebalance with old generation 3 (__consumer_offsets-4) (reason: Adding new member app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755 with group instance id None) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:38,610] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:38,611] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:38,617] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:38,621] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Processed 0 total records, ran 0 punctuators, and committed 0 total tasks since the last update (org.apache.kafka.streams.processor.internals.StreamThread:858)
[2022-08-19 10:40:49,507] INFO [GroupCoordinator 1]: Stabilized group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 generation 4 (__consumer_offsets-4) with 12 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:55,141] INFO [TransactionCoordinator id=0] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:55,141] INFO [TransactionCoordinator id=0] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:55,142] INFO [TransactionCoordinator id=0] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:55,153] ERROR [ReplicaManager broker=2] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 3 at offset 2563 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,161] ERROR [ReplicaManager broker=2] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 3 at offset 2563 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,162] ERROR [ReplicaManager broker=1] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 2 at offset 2485 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,162] ERROR [ReplicaManager broker=1] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 2 at offset 2485 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,167] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_2 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,167] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_3 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,169] ERROR [ReplicaManager broker=1] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1 at offset 1863 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,169] ERROR [ReplicaManager broker=1] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1 at offset 1863 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,170] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_9 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,171] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Failed to process stream task 0_2 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:40:55,171] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Failed to process stream task 0_9 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:40:55,171] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Failed to process stream task 0_3 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:40:55,171] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_9 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,171] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_2 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,173] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_9 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2' and ProducerIdAndEpoch(producerId=1, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2' and ProducerIdAndEpoch(producerId=1, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,171] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_3 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,173] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_2 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2' and ProducerIdAndEpoch(producerId=3, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2' and ProducerIdAndEpoch(producerId=3, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,175] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_3 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4' and ProducerIdAndEpoch(producerId=2, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4' and ProducerIdAndEpoch(producerId=2, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,175] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Error flushing caches of dirty task 0_2  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_2 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2' and ProducerIdAndEpoch(producerId=3, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2' and ProducerIdAndEpoch(producerId=3, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,175] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Error flushing caches of dirty task 0_9  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_9 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2' and ProducerIdAndEpoch(producerId=1, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2' and ProducerIdAndEpoch(producerId=1, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,176] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,175] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Error flushing caches of dirty task 0_3  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_3 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4' and ProducerIdAndEpoch(producerId=2, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4' and ProducerIdAndEpoch(producerId=2, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,176] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,214] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,215] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_3] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,216] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,216] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,216] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,216] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_9] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,216] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Failed to flush cache of store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74:  (org.apache.kafka.streams.processor.internals.ProcessorStateManager:506)
org.apache.kafka.streams.errors.TaskMigratedException: Producer got fenced trying to begin a new transaction [stream-thread [main]]; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.StreamsProducer.maybeBeginTransaction(StreamsProducer.java:238)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:252)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2' and ProducerIdAndEpoch(producerId=1, epoch=0) has been fenced by another producer with the same transactionalId
[2022-08-19 10:40:55,217] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,217] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Error flushing caches of dirty task 0_1  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Producer got fenced trying to begin a new transaction [stream-thread [main]]; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.StreamsProducer.maybeBeginTransaction(StreamsProducer.java:238)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:252)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.ProducerFencedException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2' and ProducerIdAndEpoch(producerId=1, epoch=0) has been fenced by another producer with the same transactionalId
[2022-08-19 10:40:55,217] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,217] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_2] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,217] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,217] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_10] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,218] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_10] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,243] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,243] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,247] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,247] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_1] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,248] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_10] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,248] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_10] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,251] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-3, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-11] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_6]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:40:55,253] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-1, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-9] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_4]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:40:55,255] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-2, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-10] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_11, 0_3]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:40:55,257] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] partitions lost took 6 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:40:55,262] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] partitions lost took 9 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:40:55,262] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] partitions lost took 7 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:40:55,617] INFO [TransactionCoordinator id=1] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:55,617] INFO [TransactionCoordinator id=1] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:55,647] ERROR [ReplicaManager broker=0] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1002 at offset 3009 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,647] ERROR [ReplicaManager broker=0] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1002 at offset 3009 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,648] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_4 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,648] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Failed to process stream task 0_4 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:40:55,648] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_4 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,649] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_4 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3' and ProducerIdAndEpoch(producerId=1002, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3' and ProducerIdAndEpoch(producerId=1002, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,649] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Error flushing caches of dirty task 0_4  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_4 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3' and ProducerIdAndEpoch(producerId=1002, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3' and ProducerIdAndEpoch(producerId=1002, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,649] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,660] ERROR [ReplicaManager broker=1] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1003 at offset 823 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,660] ERROR [ReplicaManager broker=1] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1003 at offset 823 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,660] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_0 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,660] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_8 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,661] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Failed to process stream task 0_8 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:40:55,661] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_8 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.abort(ProducerBatch.java:161)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortUndrainedBatches(RecordAccumulator.java:793)
	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:431)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:316)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,661] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_8 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1' and ProducerIdAndEpoch(producerId=1003, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1' and ProducerIdAndEpoch(producerId=1003, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,662] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Error flushing caches of dirty task 0_8  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_8 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1' and ProducerIdAndEpoch(producerId=1003, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1' and ProducerIdAndEpoch(producerId=1003, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,662] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,662] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,686] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,687] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_4] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_8] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,690] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_5]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:40:55,691] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Failed to flush cache of store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74:  (org.apache.kafka.streams.processor.internals.ProcessorStateManager:506)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_0 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,691] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Error flushing caches of dirty task 0_0  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_0 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,691] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,691] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,693] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] partitions lost took 2 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:40:55,710] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,710] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_0] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,716] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-0, input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-8] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_9, 0_1]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:40:55,723] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] partitions lost took 7 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:40:55,913] INFO [TransactionCoordinator id=2] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:40:55,921] ERROR [ReplicaManager broker=1] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 2000 at offset 3106 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,921] ERROR [ReplicaManager broker=1] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 2000 at offset 3106 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:40:55,922] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_6 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,922] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Failed to process stream task 0_6 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:40:55,922] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_6 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:40:55,923] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_6 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4' and ProducerIdAndEpoch(producerId=2000, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4' and ProducerIdAndEpoch(producerId=2000, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,923] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Error flushing caches of dirty task 0_6  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_6 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4' and ProducerIdAndEpoch(producerId=2000, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4' and ProducerIdAndEpoch(producerId=2000, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:40:55,924] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:40:55,924] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:40:55,950] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:40:55,951] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:40:55,954] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-6] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_7]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:40:55,958] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] partitions lost took 4 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:40:56,628] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] All members participating in this rebalance:
e4c78f95-7131-4046-a257-77f4390ca80f: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755]
852a7c8a-a1b5-42a5-bdb4-468104a868f6: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e]
4099381e-a0be-433f-a0ce-efeff2e03df9: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:600)
[2022-08-19 10:40:56,631] INFO Decided on assignment: {852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_3, 0_6, 0_9]) standbyTasks: ([0_1, 0_2, 0_7, 0_8]) prevActiveTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) prevStandbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) changelogOffsetTotalsByTask: ([0_0=-2, 0_1=0, 0_2=-2, 0_3=0, 0_4=-2, 0_5=243, 0_6=-2, 0_7=230, 0_8=-2, 0_9=0, 0_10=-2, 0_11=0]) taskLagTotals: ([0_0=-2, 0_1=2001, 0_2=-2, 0_3=2641, 0_4=-2, 0_5=3071, 0_6=-2, 0_7=3135, 0_8=-2, 0_9=1981, 0_10=-2, 0_11=1496]) capacity: 4 assigned: 8], e4c78f95-7131-4046-a257-77f4390ca80f=[activeTasks: ([0_1, 0_4, 0_7, 0_10]) standbyTasks: ([0_0, 0_5, 0_6, 0_11]) prevActiveTasks: ([]) prevStandbyTasks: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([0_0=831, 0_1=2001, 0_2=2629, 0_3=2641, 0_4=3093, 0_5=3314, 0_6=3248, 0_7=3365, 0_8=3146, 0_9=1981, 0_10=1328, 0_11=1496]) capacity: 4 assigned: 8], 4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_2, 0_5, 0_8, 0_11]) standbyTasks: ([0_3, 0_4, 0_9, 0_10]) prevActiveTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) prevStandbyTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) changelogOffsetTotalsByTask: ([0_0=824, 0_1=-2, 0_2=984, 0_3=-2, 0_4=271, 0_5=-2, 0_6=543, 0_7=-2, 0_8=251, 0_9=-2, 0_10=288, 0_11=-2]) taskLagTotals: ([0_0=7, 0_1=-2, 0_2=1645, 0_3=-2, 0_4=2822, 0_5=-2, 0_6=2705, 0_7=-2, 0_8=2895, 0_9=-2, 0_10=1040, 0_11=-2]) capacity: 4 assigned: 8]} with no followup probing rebalance. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:95)
[2022-08-19 10:40:56,631] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Assigned tasks [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] including stateful [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] to clients as:
e4c78f95-7131-4046-a257-77f4390ca80f=[activeTasks: ([0_1, 0_4, 0_7, 0_10]) standbyTasks: ([0_0, 0_5, 0_6, 0_11])]
852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_3, 0_6, 0_9]) standbyTasks: ([0_1, 0_2, 0_7, 0_8])]
4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_2, 0_5, 0_8, 0_11]) standbyTasks: ([0_3, 0_4, 0_9, 0_10])]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:618)
[2022-08-19 10:40:56,631] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_1 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,631] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_1 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_4 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_4 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_7 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_7 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_10 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_10 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client e4c78f95-7131-4046-a257-77f4390ca80f per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_10]}
	revoking active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_10]}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_1, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_5, 0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_7, 0_6], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_11, 0_10]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_3 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_3 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,632] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_9 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_9 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 852a7c8a-a1b5-42a5-bdb4-468104a868f6 per-consumer assignment:
	prev owned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_6]}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_11, 0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_7]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_9], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_6]}
	revoking active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_9]}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914=[0_8], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26=[0_3, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e=[0_7]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_8 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_8 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Removing task 0_2 from app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 active assignment until it is safely revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:964)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Adding removed stateful active task 0_2 as a standby for app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 before it is revoked in followup rebalance (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1016)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Requesting followup rebalance be scheduled immediately by app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3 due to tasks changing ownership. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:912)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Client 4099381e-a0be-433f-a0ce-efeff2e03df9 per-consumer assignment:
	prev owned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11, 0_3]}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_6]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_8], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_11]}
	revoking active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_8], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_2]}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906=[0_9, 0_8], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d=[0_3]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:40:56,633] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] Finished unstable assignment of tasks, a followup rebalance will be scheduled. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:843)
[2022-08-19 10:40:56,634] INFO [GroupCoordinator 1]: Assignment received from leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf for group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for generation 4. The group has 12 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,635] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:56,636] INFO [GroupCoordinator 1]: Preparing to rebalance group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in state PreparingRebalance with old generation 4 (__consumer_offsets-4) (reason: Removing member app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:56,636] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-fa0cd285-1a8d-4c31-bfd1-39bfe7237914, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer] Requested to schedule immediate rebalance for new tasks to be safely revoked from current owner. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1319)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_7, 0_6]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:56,637] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-a6ec49c2-1b73-4cfd-bdeb-8ba91dec7e8e, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_5, 0_4]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_11, 0_10]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:56,636] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Handle new assignment with:
	New active tasks: []
	New standby tasks: [0_1, 0_0]
	Existing active tasks: []
	Existing standby tasks: [] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:40:56,637] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-455d4165-91f0-45c7-af48-5ea615faf47d, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,637] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,638] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,638] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,638] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,638] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from STARTING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,638] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-c9db460f-7542-4e77-9fff-29f74f67ca26, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,638] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-4db2bfe2-615d-4f2c-a49d-54be7c4df906, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,639] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,639] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,639] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,639] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,640] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-757d166a-38ee-484e-a57b-bc610335381a, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,640] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,793] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_0] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,794] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_0] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,793] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_10] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,794] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_0] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,794] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_10] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,794] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_10] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,797] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_4] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,797] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_4] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,797] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_6] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,797] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_6] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,797] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_4] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,797] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_6] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_1] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_11] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_11] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_1] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_11] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_1] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Restoration took 272 ms for all tasks [0_10, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:56,911] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,910] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Restoration took 272 ms for all tasks [0_0, 0_1] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:56,911] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,912] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:56,912] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_5] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_7] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_5] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_7] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_5] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_7] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Restoration took 276 ms for all tasks [0_4, 0_5] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Restoration took 276 ms for all tasks [0_6, 0_7] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,914] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:40:56,914] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:40:56,914] INFO Wait for the processing to be completed (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:232)
[2022-08-19 10:40:56,916] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:56,916] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Triggering the followup rebalance scheduled for 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:606)
[2022-08-19 10:40:56,920] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group db5e8e4a-136e-48d8-8bf4-94facff42e19 in Empty state. Created a new member id consumer-db5e8e4a-136e-48d8-8bf4-94facff42e19-2-f2cafaa4-4f40-4d13-a701-cf263e9eead8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,920] INFO [GroupCoordinator 1]: Preparing to rebalance group db5e8e4a-136e-48d8-8bf4-94facff42e19 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-db5e8e4a-136e-48d8-8bf4-94facff42e19-2-f2cafaa4-4f40-4d13-a701-cf263e9eead8 with group instance id None) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,921] INFO [GroupCoordinator 1]: Stabilized group db5e8e4a-136e-48d8-8bf4-94facff42e19 generation 1 (__consumer_offsets-1) with 1 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:40:56,922] INFO [GroupCoordinator 1]: Assignment received from leader consumer-db5e8e4a-136e-48d8-8bf4-94facff42e19-2-f2cafaa4-4f40-4d13-a701-cf263e9eead8 for group db5e8e4a-136e-48d8-8bf4-94facff42e19 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,574] INFO [TransactionCoordinator id=1] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,574] INFO [TransactionCoordinator id=1] Completed rollback of ongoing transaction for transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3 due to timeout (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,618] ERROR [ReplicaManager broker=0] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1001 at offset 4016 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:41:05,618] ERROR [ReplicaManager broker=0] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1001 at offset 4016 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:41:05,619] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_7 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:41:05,621] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Failed to process stream task 0_7 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:41:05,622] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for task 0_7 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:41:05,623] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_7 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3' and ProducerIdAndEpoch(producerId=1001, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3' and ProducerIdAndEpoch(producerId=1001, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:41:05,623] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Error flushing caches of dirty task 0_7  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_7 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3' and ProducerIdAndEpoch(producerId=1001, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3' and ProducerIdAndEpoch(producerId=1001, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:41:05,623] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:41:05,624] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:41:05,653] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:41:05,653] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_7] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:41:05,656] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] at state RUNNING: partitions [input-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-7] lost due to missed rebalance.
	lost active tasks: []
	lost assigned standby tasks: [0_10, 0_2]
 (org.apache.kafka.streams.processor.internals.StreamThread:104)
[2022-08-19 10:41:05,660] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] partitions lost took 4 ms. (org.apache.kafka.streams.processor.internals.StreamThread:117)
[2022-08-19 10:41:05,661] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-50e7b172-3289-40d1-a7dc-ea42e19fa6a3, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,661] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in PreparingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,670] ERROR [ReplicaManager broker=2] Error processing append operation on partition app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1000 at offset 4007 in app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:41:05,670] ERROR [ReplicaManager broker=2] Error processing append operation on partition output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 (kafka.server.ReplicaManager:76)
org.apache.kafka.common.errors.InvalidProducerEpochException: Epoch of producer 1000 at offset 4007 in output-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-5 is 0, which is smaller than the last seen epoch 1
[2022-08-19 10:41:05,670] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_5 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:41:05,672] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Failed to process stream task 0_5 since it got migrated to another thread already. Will trigger a new rebalance and close all tasks as zombies together. (org.apache.kafka.streams.processor.internals.TaskManager:1309)
[2022-08-19 10:41:05,672] WARN stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Detected that the thread is being fenced. This implies that this thread missed a rebalance and dropped out of the consumer group. Will close out all assigned tasks and rejoin the consumer group. (org.apache.kafka.streams.processor.internals.StreamThread:707)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_5 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:273)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:234)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeExceptionally(ProducerBatch.java:198)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:758)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:743)
	at org.apache.kafka.clients.producer.internals.Sender.failBatch(Sender.java:695)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:634)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$1(Sender.java:575)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$handleProduceResponse$2(Sender.java:562)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:562)
	at org.apache.kafka.clients.producer.internals.Sender.lambda$sendProduceRequest$5(Sender.java:836)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:583)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:575)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer attempted to produce with an old epoch.
[2022-08-19 10:41:05,672] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_5 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1' and ProducerIdAndEpoch(producerId=1000, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:234)
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1' and ProducerIdAndEpoch(producerId=1000, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:41:05,673] ERROR stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Error flushing caches of dirty task 0_5  (org.apache.kafka.streams.processor.internals.TaskManager:796)
org.apache.kafka.streams.errors.TaskMigratedException: Error encountered sending record to topic app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog for task 0_5 due to:
org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1' and ProducerIdAndEpoch(producerId=1000, epoch=0) attempted to produce with an old epoch
Written offsets would not be recorded and no more records would be sent since the producer is fenced, indicating the task may be migrated out; it means all tasks belonging to this thread should be migrated.
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError(RecordCollectorImpl.java:215)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.lambda$send$0(RecordCollectorImpl.java:196)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1411)
	at org.apache.kafka.clients.producer.KafkaProducer.doSend(KafkaProducer.java:1023)
	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:914)
	at org.apache.kafka.streams.processor.internals.StreamsProducer.send(StreamsProducer.java:254)
	at org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send(RecordCollectorImpl.java:182)
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.logChange(ProcessorContextImpl.java:119)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.log(ChangeLoggingKeyValueBytesStore.java:143)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:79)
	at org.apache.kafka.streams.state.internals.ChangeLoggingKeyValueBytesStore.put(ChangeLoggingKeyValueBytesStore.java:33)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.putAndMaybeForward(CachingKeyValueStore.java:117)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.lambda$initInternal$0(CachingKeyValueStore.java:87)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:151)
	at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:109)
	at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:136)
	at org.apache.kafka.streams.state.internals.CachingKeyValueStore.flushCache(CachingKeyValueStore.java:345)
	at org.apache.kafka.streams.state.internals.WrappedStateStore.flushCache(WrappedStateStore.java:71)
	at org.apache.kafka.streams.processor.internals.ProcessorStateManager.flushCache(ProcessorStateManager.java:491)
	at org.apache.kafka.streams.processor.internals.StreamTask.prepareCommit(StreamTask.java:402)
	at org.apache.kafka.streams.processor.internals.TaskManager.closeTaskDirty(TaskManager.java:794)
	at org.apache.kafka.streams.processor.internals.TaskManager.handleLostAll(TaskManager.java:657)
	at org.apache.kafka.streams.processor.internals.StreamThread.handleTaskMigrated(StreamThread.java:711)
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:625)
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576)
Caused by: org.apache.kafka.common.errors.InvalidProducerEpochException: Producer with transactionalId 'app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1' and ProducerIdAndEpoch(producerId=1000, epoch=0) attempted to produce with an old epoch
[2022-08-19 10:41:05,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:41:05,673] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:41:05,692] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Closing record collector dirty (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:283)
[2022-08-19 10:41:05,692] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_5] Closed dirty (org.apache.kafka.streams.processor.internals.StreamTask:532)
[2022-08-19 10:41:05,695] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,695] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from RUNNING to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:41:05,695] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] partition revocation took 0 ms. (org.apache.kafka.streams.processor.internals.StreamThread:97)
[2022-08-19 10:41:05,696] INFO [GroupCoordinator 1]: Stabilized group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 generation 5 (__consumer_offsets-4) with 11 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,697] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-45811bc5-643f-43dc-91a0-c6e0042c77bf, groupInstanceId=None, clientId=app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(stream)) has left group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,698] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in CompletingRebalance state. Created a new member id app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-1ccba743-45b5-40ec-a7df-6c7399621a46 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,700] INFO [GroupCoordinator 1]: Preparing to rebalance group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 in state PreparingRebalance with old generation 5 (__consumer_offsets-4) (reason: Adding new member app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-1ccba743-45b5-40ec-a7df-6c7399621a46 with group instance id None) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,702] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] All members participating in this rebalance:
e4c78f95-7131-4046-a257-77f4390ca80f: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755]
852a7c8a-a1b5-42a5-bdb4-468104a868f6: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0]
4099381e-a0be-433f-a0ce-efeff2e03df9: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:600)
[2022-08-19 10:41:05,703] INFO Decided on assignment: {852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_3, 0_6, 0_9]) standbyTasks: ([0_1, 0_2, 0_5, 0_8, 0_10]) prevActiveTasks: ([]) prevStandbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) changelogOffsetTotalsByTask: ([0_1=808, 0_3=1589, 0_5=2312, 0_7=2673, 0_9=1827, 0_11=1494]) taskLagTotals: ([0_0=831, 0_1=1193, 0_2=2629, 0_3=1052, 0_4=3093, 0_5=1871, 0_6=3248, 0_7=1563, 0_8=3146, 0_9=154, 0_10=1328, 0_11=2]) capacity: 4 assigned: 9], e4c78f95-7131-4046-a257-77f4390ca80f=[activeTasks: ([0_1, 0_4, 0_7, 0_10]) standbyTasks: ([0_0, 0_3, 0_6, 0_9, 0_11]) prevActiveTasks: ([]) prevStandbyTasks: ([]) changelogOffsetTotalsByTask: ([]) taskLagTotals: ([0_0=831, 0_1=2001, 0_2=2629, 0_3=2641, 0_4=3093, 0_5=4183, 0_6=3248, 0_7=4236, 0_8=3146, 0_9=1981, 0_10=1328, 0_11=1496]) capacity: 4 assigned: 9], 4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_2, 0_5, 0_8, 0_11]) standbyTasks: ([0_4, 0_7]) prevActiveTasks: ([]) prevStandbyTasks: ([0_2, 0_4, 0_6, 0_10]) changelogOffsetTotalsByTask: ([0_2=1087, 0_4=1511, 0_6=2056, 0_10=1326]) taskLagTotals: ([0_0=831, 0_1=2001, 0_2=1542, 0_3=2641, 0_4=1582, 0_5=4183, 0_6=1192, 0_7=4236, 0_8=3146, 0_9=1981, 0_10=2, 0_11=1496]) capacity: 3 assigned: 6]} with no followup probing rebalance. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:95)
[2022-08-19 10:41:05,703] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Assigned tasks [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] including stateful [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] to clients as:
e4c78f95-7131-4046-a257-77f4390ca80f=[activeTasks: ([0_1, 0_4, 0_7, 0_10]) standbyTasks: ([0_0, 0_3, 0_6, 0_9, 0_11])]
852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_3, 0_6, 0_9]) standbyTasks: ([0_1, 0_2, 0_5, 0_8, 0_10])]
4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_2, 0_5, 0_8, 0_11]) standbyTasks: ([0_4, 0_7])]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:618)
[2022-08-19 10:41:05,703] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Client e4c78f95-7131-4046-a257-77f4390ca80f per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_10]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_11, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_6], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_9]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:41:05,704] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Client 852a7c8a-a1b5-42a5-bdb4-468104a868f6 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540=[0_11, 0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0=[0_7]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1=[0_9], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540=[0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150=[0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0=[0_6]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1=[0_10, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540=[0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0=[0_8]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:41:05,704] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Client 4099381e-a0be-433f-a0ce-efeff2e03df9 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0=[0_6]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a=[0_11, 0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f=[0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0=[0_8]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f=[0_7]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:41:05,704] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:846)
[2022-08-19 10:41:05,705] INFO [GroupCoordinator 1]: Stabilized group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 generation 6 (__consumer_offsets-4) with 12 members (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,708] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] All members participating in this rebalance:
e4c78f95-7131-4046-a257-77f4390ca80f: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755]
852a7c8a-a1b5-42a5-bdb4-468104a868f6: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0]
4099381e-a0be-433f-a0ce-efeff2e03df9: [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-1ccba743-45b5-40ec-a7df-6c7399621a46, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f, app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:600)
[2022-08-19 10:41:05,709] INFO Decided on assignment: {852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_3, 0_6, 0_9]) standbyTasks: ([0_1, 0_2, 0_7, 0_8]) prevActiveTasks: ([]) prevStandbyTasks: ([0_1, 0_3, 0_5, 0_7, 0_9, 0_11]) changelogOffsetTotalsByTask: ([0_1=808, 0_3=1589, 0_5=2312, 0_7=2673, 0_9=1827, 0_11=1494]) taskLagTotals: ([0_0=831, 0_1=1193, 0_2=2629, 0_3=1052, 0_4=3093, 0_5=1871, 0_6=3248, 0_7=1563, 0_8=3146, 0_9=154, 0_10=1328, 0_11=2]) capacity: 4 assigned: 8], e4c78f95-7131-4046-a257-77f4390ca80f=[activeTasks: ([0_1, 0_4, 0_7, 0_10]) standbyTasks: ([0_0, 0_5, 0_6, 0_11]) prevActiveTasks: ([]) prevStandbyTasks: ([0_0, 0_1, 0_4, 0_5, 0_6, 0_7, 0_10, 0_11]) changelogOffsetTotalsByTask: ([0_0=828, 0_1=808, 0_4=1511, 0_5=2312, 0_6=2056, 0_7=2673, 0_10=1326, 0_11=1494]) taskLagTotals: ([0_0=3, 0_1=1193, 0_2=2629, 0_3=2641, 0_4=1582, 0_5=1871, 0_6=1192, 0_7=1563, 0_8=3146, 0_9=1981, 0_10=2, 0_11=2]) capacity: 4 assigned: 8], 4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_2, 0_5, 0_8, 0_11]) standbyTasks: ([0_3, 0_4, 0_9, 0_10]) prevActiveTasks: ([]) prevStandbyTasks: ([0_0, 0_2, 0_4, 0_6, 0_8, 0_10]) changelogOffsetTotalsByTask: ([0_0=828, 0_2=1087, 0_4=1511, 0_6=2056, 0_8=2135, 0_10=1326]) taskLagTotals: ([0_0=3, 0_1=2001, 0_2=1542, 0_3=2641, 0_4=1582, 0_5=4183, 0_6=1192, 0_7=4236, 0_8=1011, 0_9=1981, 0_10=2, 0_11=1496]) capacity: 4 assigned: 8]} with no followup probing rebalance. (org.apache.kafka.streams.processor.internals.assignment.HighAvailabilityTaskAssignor:95)
[2022-08-19 10:41:05,709] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Assigned tasks [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] including stateful [0_11, 0_10, 0_9, 0_8, 0_7, 0_6, 0_5, 0_4, 0_3, 0_2, 0_1, 0_0] to clients as:
e4c78f95-7131-4046-a257-77f4390ca80f=[activeTasks: ([0_1, 0_4, 0_7, 0_10]) standbyTasks: ([0_0, 0_5, 0_6, 0_11])]
852a7c8a-a1b5-42a5-bdb4-468104a868f6=[activeTasks: ([0_0, 0_3, 0_6, 0_9]) standbyTasks: ([0_1, 0_2, 0_7, 0_8])]
4099381e-a0be-433f-a0ce-efeff2e03df9=[activeTasks: ([0_2, 0_5, 0_8, 0_11]) standbyTasks: ([0_3, 0_4, 0_9, 0_10])]. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:618)
[2022-08-19 10:41:05,709] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Client e4c78f95-7131-4046-a257-77f4390ca80f per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_1, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_5, 0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_7, 0_6], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_11, 0_10]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_7], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_10]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3=[0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer-426371f1-8453-4980-be18-be20da5ddd21=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer-0659c711-537e-4f41-8a77-3da52c18bbc3=[0_6], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer-b3d49c60-fa52-4c75-ab44-57696b4bd755=[0_11]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:41:05,710] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Client 852a7c8a-a1b5-42a5-bdb4-468104a868f6 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1=[0_9, 0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540=[0_11, 0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0=[0_7]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1=[0_9], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540=[0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150=[0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0=[0_6]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer-9ab9dcf4-08b6-4501-af0e-30ae21e50da1=[0_1], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer-ad21fac2-1718-4790-a267-120732ed1540=[0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer-66a13596-9ba7-4247-a4b9-0e652aeeb150=[0_8], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer-888ad00c-387f-4a59-9c68-d4f33c2598d0=[0_7]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:41:05,710] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Client 4099381e-a0be-433f-a0ce-efeff2e03df9 per-consumer assignment:
	prev owned active {}
	prev owned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-1ccba743-45b5-40ec-a7df-6c7399621a46=[0_8, 0_0], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f=[0_10, 0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0=[0_6]}
	assigned active {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-1ccba743-45b5-40ec-a7df-6c7399621a46=[0_8], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a=[0_5], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f=[0_2], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0=[0_11]}
	revoking active {}
	assigned standby {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer-1ccba743-45b5-40ec-a7df-6c7399621a46=[0_3], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer-0ab0fe65-ef77-403e-9aaa-eddcd895495a=[0_4], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer-abe5c9eb-5764-4b56-a328-0fee10ac0a4f=[0_10], app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer-2fce8fe2-38a6-4421-b69b-b50448b68ee0=[0_9]}
 (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:827)
[2022-08-19 10:41:05,710] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] Finished stable assignment of tasks, no followup rebalances required. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:846)
[2022-08-19 10:41:05,711] INFO [GroupCoordinator 1]: Assignment received from leader app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer-d90a57cb-2e54-4b00-8c83-b635da362dc3 for group app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 for generation 6. The group has 12 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Handle new assignment with:
	New active tasks: [0_8]
	New standby tasks: [0_3]
	Existing active tasks: []
	Existing standby tasks: [0_8, 0_0] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Handle new assignment with:
	New active tasks: [0_10]
	New standby tasks: [0_11]
	Existing active tasks: []
	Existing standby tasks: [0_11, 0_10] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_10] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Handle new assignment with:
	New active tasks: [0_1]
	New standby tasks: [0_0]
	Existing active tasks: []
	Existing standby tasks: [0_1, 0_0] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Handle new assignment with:
	New active tasks: [0_4]
	New standby tasks: [0_5]
	Existing active tasks: []
	Existing standby tasks: [0_5, 0_4] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_4] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_1] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Handle new assignment with:
	New active tasks: [0_0]
	New standby tasks: [0_8]
	Existing active tasks: []
	Existing standby tasks: [0_5] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Handle new assignment with:
	New active tasks: [0_11]
	New standby tasks: [0_9]
	Existing active tasks: []
	Existing standby tasks: [0_6] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Handle new assignment with:
	New active tasks: [0_7]
	New standby tasks: [0_6]
	Existing active tasks: []
	Existing standby tasks: [0_7, 0_6] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_7] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_0] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Handle new assignment with:
	New active tasks: [0_2]
	New standby tasks: [0_10]
	Existing active tasks: []
	Existing standby tasks: [0_10, 0_2] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_2] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4-consumer] No followup rebalance was requested, resetting the rebalance schedule. (org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor:1325)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Handle new assignment with:
	New active tasks: [0_3]
	New standby tasks: [0_2]
	Existing active tasks: []
	Existing standby tasks: [0_11, 0_3] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Handle new assignment with:
	New active tasks: [0_6]
	New standby tasks: [0_7]
	Existing active tasks: []
	Existing standby tasks: [0_7] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Handle new assignment with:
	New active tasks: [0_9]
	New standby tasks: [0_1]
	Existing active tasks: []
	Existing standby tasks: [0_9, 0_1] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_6] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_5] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Handle new assignment with:
	New active tasks: [0_5]
	New standby tasks: [0_4]
	Existing active tasks: []
	Existing standby tasks: [0_4] (org.apache.kafka.streams.processor.internals.TaskManager:276)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_9] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,713] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_11] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,714] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,714] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,714] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from RUNNING to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:41:05,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_4] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_10] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,779] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,779] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] State transition from RUNNING to REBALANCING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:41:05,779] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,789] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_1] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,790] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,792] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_7] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,792] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_2] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,793] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,793] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,808] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_8] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,812] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_9] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,813] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,814] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_6] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:41:05,815] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,830] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_5] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:41:05,831] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,832] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_3] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:41:05,856] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_0] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:41:05,856] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_8] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,857] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,874] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_11] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:41:05,874] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_3] Closed clean and recycled state (org.apache.kafka.streams.processor.internals.StandbyTask:233)
[2022-08-19 10:41:05,874] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from RUNNING to PARTITIONS_ASSIGNED (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,882] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-4 with producerId 1004 and producer epoch 0 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,882] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-2 with producerId 5 and producer epoch 0 on partition __transaction_state-1 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,882] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] task [0_10] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:05,883] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] task [0_4] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:05,892] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-1 with producerId 1005 and producer epoch 0 on partition __transaction_state-0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,893] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] task [0_1] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:05,897] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-3 with producerId 1001 and producer epoch 2 on partition __transaction_state-0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,897] INFO [TransactionCoordinator id=2] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-3 with producerId 2001 and producer epoch 0 on partition __transaction_state-2 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,897] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] task [0_7] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:05,897] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:05,906] INFO [TransactionCoordinator id=2] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-4 with producerId 2000 and producer epoch 2 on partition __transaction_state-2 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,914] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-2 with producerId 1 and producer epoch 2 on partition __transaction_state-4 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,916] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-1 with producerId 1003 and producer epoch 2 on partition __transaction_state-0 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,917] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_9] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:05,927] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_9] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:05,927] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_9] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:05,928] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_9] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:41:05,935] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-3 with producerId 1002 and producer epoch 2 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:05,984] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,984] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,984] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-10 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,984] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Restoration in progress for 1 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4: position=1428, end=3009, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:41:05,985] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] task [0_10] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:05,985] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Restoration took 206 ms for all tasks [0_10, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:05,985] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,995] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,995] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-1 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,995] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] task [0_1] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:05,996] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Restoration took 206 ms for all tasks [0_0, 0_1] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:05,996] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:05,999] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,999] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:05,999] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Restoration in progress for 1 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7: position=219, end=220, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:41:05,999] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,000] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,000] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Restoration took 207 ms for all tasks [0_2, 0_10] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,000] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,000] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_3] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,000] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_3] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,001] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_3] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:41:06,014] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,014] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-2 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,014] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:41:06,018] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,018] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Restoration in progress for 1 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9: position=1710, end=1863, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:41:06,031] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-4 with producerId 2 and producer epoch 2 on partition __transaction_state-1 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:06,051] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,051] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,051] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:06,053] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 71 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,054] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Restoration in progress for 1 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6: position=0, end=3106, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:41:06,054] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,054] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,054] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:06,056] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-6 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 1845 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,057] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 88 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,057] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Restoration in progress for 1 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5: position=0, end=4007, totalRestored=0} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:41:06,057] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,057] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Restoration took 343 ms for all tasks [0_6, 0_7] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,057] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,060] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-5 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 2050 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,061] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,061] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Restoration took 347 ms for all tasks [0_4, 0_5] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,061] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,077] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,077] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,077] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:06,103] INFO [TransactionCoordinator id=1] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-1 with producerId 1000 and producer epoch 2 on partition __transaction_state-3 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:06,104] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:06,118] INFO [TransactionCoordinator id=0] Initialized transactionalId app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-2 with producerId 3 and producer epoch 2 on partition __transaction_state-4 (kafka.coordinator.transaction.TransactionCoordinator:66)
[2022-08-19 10:41:06,119] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_3] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:06,119] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-9 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,120] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_9] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,120] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Restoration took 307 ms for all tasks [0_1, 0_9] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,120] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,155] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Initialized (org.apache.kafka.streams.processor.internals.StreamTask:240)
[2022-08-19 10:41:06,160] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Restoration in progress for 2 partitions. {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11: position=0, end=148, totalRestored=0} {app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11: position=1028, end=1348, totalRestored=1000} (org.apache.kafka.streams.processor.internals.StoreChangelogReader:502)
[2022-08-19 10:41:06,161] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 1274 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,161] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-11 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 74 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,162] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,162] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Restoration took 347 ms for all tasks [0_9, 0_11] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,162] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_8] State store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_8] State store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 did not find checkpoint offset, hence would default to the starting offset at changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 (org.apache.kafka.streams.processor.internals.ProcessorStateManager:260)
[2022-08-19 10:41:06,177] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_8] Initialized (org.apache.kafka.streams.processor.internals.StandbyTask:107)
[2022-08-19 10:41:06,181] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 818 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,182] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-0 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 4 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,182] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,183] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Restoration took 352 ms for all tasks [0_0, 0_8] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,183] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,184] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-4 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,185] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] task [0_4] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,185] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Restoration took 406 ms for all tasks [0_4, 0_5] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,185] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,200] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-7 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,201] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] task [0_7] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,201] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Restoration took 408 ms for all tasks [0_6, 0_7] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,201] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,202] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:41:06,205] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,206] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-8 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,206] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,207] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Restoration took 349 ms for all tasks [0_3, 0_8] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,207] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,207] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:41:06,220] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 to store store-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,220] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Finished restoring changelog app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-changelog-3 to store counter-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74 with a total number of 0 records (org.apache.kafka.streams.processor.internals.StoreChangelogReader:609)
[2022-08-19 10:41:06,221] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_3] Restored and ready to run (org.apache.kafka.streams.processor.internals.StreamTask:265)
[2022-08-19 10:41:06,221] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Restoration took 347 ms for all tasks [0_2, 0_3] (org.apache.kafka.streams.processor.internals.StreamThread:882)
[2022-08-19 10:41:06,222] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from PARTITIONS_ASSIGNED to RUNNING (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:41:06,222] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from REBALANCING to RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:14,552] INFO [GroupCoordinator 1]: Preparing to rebalance group db5e8e4a-136e-48d8-8bf4-94facff42e19 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-db5e8e4a-136e-48d8-8bf4-94facff42e19-2-f2cafaa4-4f40-4d13-a701-cf263e9eead8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:42:14,553] INFO [GroupCoordinator 1]: Group db5e8e4a-136e-48d8-8bf4-94facff42e19 with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:42:14,553] INFO [GroupCoordinator 1]: Member MemberMetadata(memberId=consumer-db5e8e4a-136e-48d8-8bf4-94facff42e19-2-f2cafaa4-4f40-4d13-a701-cf263e9eead8, groupInstanceId=None, clientId=consumer-db5e8e4a-136e-48d8-8bf4-94facff42e19-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group db5e8e4a-136e-48d8-8bf4-94facff42e19 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator:66)
[2022-08-19 10:42:14,557] INFO Processing completed (org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest:245)
[2022-08-19 10:42:14,617] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,618] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,637] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,668] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,668] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,670] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,670] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] task [0_2] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,678] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,679] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,702] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,702] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_10] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,704] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] standby-task [0_10] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,708] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,708] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-3] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,712] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,714] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,714] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] task [0_11] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,723] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,724] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,725] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,725] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] task [0_8] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,737] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,738] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,740] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,740] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] task [0_5] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,750] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_9] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,752] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] standby-task [0_9] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,755] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,756] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-4] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,764] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_3] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,767] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] standby-task [0_3] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,771] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,771] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-1] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,772] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] standby-task [0_4] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,773] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] standby-task [0_4] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,776] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,776] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9-StreamThread-2] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,778] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] State transition from PENDING_SHUTDOWN to NOT_RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:14,778] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-4099381e-a0be-433f-a0ce-efeff2e03df9] Streams client stopped completely (org.apache.kafka.streams.KafkaStreams:1403)
[2022-08-19 10:42:14,778] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,778] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,795] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,815] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,823] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,823] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,824] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,824] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] task [0_6] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,849] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_3] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,850] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_3] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,851] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_3] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,851] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] task [0_3] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,860] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_7] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,861] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] standby-task [0_7] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,864] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,864] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-4] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,865] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,878] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,889] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,891] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] standby-task [0_2] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,893] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,894] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-2] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,904] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_9] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,904] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_9] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_9] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,905] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] task [0_9] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,917] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:14,917] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:14,923] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:14,923] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] task [0_0] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:14,949] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_1] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,950] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] standby-task [0_1] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,953] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,953] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-1] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,956] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_8] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:14,958] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] standby-task [0_8] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:14,962] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,962] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6-StreamThread-3] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:14,964] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] State transition from PENDING_SHUTDOWN to NOT_RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:14,965] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-852a7c8a-a1b5-42a5-bdb4-468104a868f6] Streams client stopped completely (org.apache.kafka.streams.KafkaStreams:1403)
[2022-08-19 10:42:14,965] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Informed to shut down (org.apache.kafka.streams.processor.internals.StreamThread:1117)
[2022-08-19 10:42:14,966] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from RUNNING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:14,979] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:14,998] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:15,022] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] task [0_4] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:15,022] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] task [0_4] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:15,023] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] task [0_4] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:15,023] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] task [0_4] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:15,027] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:15,039] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] task [0_1] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:15,039] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] task [0_1] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:15,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] task [0_1] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:15,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] task [0_1] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:15,041] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Shutting down (org.apache.kafka.streams.processor.internals.StreamThread:1131)
[2022-08-19 10:42:15,063] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_5] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:15,065] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] standby-task [0_5] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:15,068] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:15,068] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-2] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:15,084] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] task [0_10] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:15,084] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] task [0_10] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:15,085] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] task [0_10] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:15,085] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] task [0_10] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:15,087] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_0] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:15,088] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] standby-task [0_0] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:15,092] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:15,092] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-1] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:15,093] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] task [0_7] Suspended RUNNING (org.apache.kafka.streams.processor.internals.StreamTask:1218)
[2022-08-19 10:42:15,093] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] task [0_7] Suspended running (org.apache.kafka.streams.processor.internals.StreamTask:300)
[2022-08-19 10:42:15,095] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] task [0_7] Closing record collector clean (org.apache.kafka.streams.processor.internals.RecordCollectorImpl:268)
[2022-08-19 10:42:15,095] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] task [0_7] Closed clean (org.apache.kafka.streams.processor.internals.StreamTask:524)
[2022-08-19 10:42:15,122] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_11] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:15,123] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] standby-task [0_11] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:15,126] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:15,126] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-4] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:15,129] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_6] Suspended running (org.apache.kafka.streams.processor.internals.StandbyTask:128)
[2022-08-19 10:42:15,131] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] standby-task [0_6] Closed clean (org.apache.kafka.streams.processor.internals.StandbyTask:211)
[2022-08-19 10:42:15,133] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] State transition from PENDING_SHUTDOWN to DEAD (org.apache.kafka.streams.processor.internals.StreamThread:229)
[2022-08-19 10:42:15,134] INFO stream-thread [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f-StreamThread-3] Shutdown complete (org.apache.kafka.streams.processor.internals.StreamThread:1161)
[2022-08-19 10:42:15,135] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] State transition from PENDING_SHUTDOWN to NOT_RUNNING (org.apache.kafka.streams.KafkaStreams:332)
[2022-08-19 10:42:15,135] INFO stream-client [app-f7b71055-1d2e-4ba4-9df4-04e8fc0b4b74-e4c78f95-7131-4046-a257-77f4390ca80f] Streams client stopped completely (org.apache.kafka.streams.KafkaStreams:1403)

java.lang.AssertionError: Each output should correspond to one distinct value
Expected: is <63000L>
     but: was <60599L>
Expected :is <63000L>
Actual   :<60599L>
<Click to see difference>


	at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
	at org.apache.kafka.streams.integration.StandbyTaskEOSCachingAndAcceptableLagIntegrationTest.shouldHonorEOSWhenUsingCachingAndStandbyReplicas(StandbyTaskEOSCachingAndAcceptableLagIntegrationTest.java:249)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)
	at com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:71)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)
	at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)

